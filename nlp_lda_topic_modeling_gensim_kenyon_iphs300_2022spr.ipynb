{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LDA Topic Modeling with Gensim\n",
        "\n",
        "Heavily modified and expanded based upon Gensim tutorial\n",
        "\n",
        "By Jon Chun\n",
        "28 Mar 2022 Updated"
      ],
      "metadata": {
        "id": "r4WqLPGjiQvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Configuration"
      ],
      "metadata": {
        "id": "mgacJy4F2oPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyldavis"
      ],
      "metadata": {
        "id": "VNlvDgGYwXl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "_vga1QAOwbzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Jupyter Notebook"
      ],
      "metadata": {
        "id": "JhMpuuFmVsJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Configure Jupyter Notebook\n",
        "\n",
        "# Ignore warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Image\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "metadata": {
        "id": "FsUfs2XNVqiq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "8qCH0NT521pv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "U7MRHAaZgftt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vykhYcp47yD"
      },
      "source": [
        "## [INPUT] Connect Google gDrive to this Jupyter Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGSD0nWR47yD",
        "outputId": "5b7c3fa1-5b30-4438-e0f9-de5887462166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to attach your Google gDrive to this Colab Jupyter Notebook\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# [INPUT REQUIRED]: Authorize access to Google gDrive via popup windows\n",
        "\n",
        "# Connect this Notebook to your permanent Google Drive\n",
        "#   so all generated output is saved to permanent storage there\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "if IN_COLAB:\n",
        "  print(\"Attempting to attach your Google gDrive to this Colab Jupyter Notebook\")\n",
        "  drive.mount('/gdrive')\n",
        "else:\n",
        "  print(\"Your Google gDrive is attached to this Colab Jupyter Notebook\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "You have (2) ways to get data in this tutorial, but if you're following\n",
        "this tutorial just to learn about LDA I encourage you to consider picking a\n",
        "corpus on a subject that you are familiar with. Qualitatively evaluating the\n",
        "output of an LDA model is challenging and can require you to understand the\n",
        "subject matter of your corpus (depending on your goal with the model).\n",
        "\n",
        "Reference to Compare::\n",
        "\n",
        "    The NeurIPS corpus contains 1740 documents, and not particularly long ones.\n",
        "\n",
        "    `website <http://www.cs.nyu.edu/~roweis/data.html>`\n",
        "    \n",
        "    So keep in mind that this tutorial is not geared towards efficiency, and be\n",
        "    careful before applying the code to a large dataset.\n"
      ],
      "metadata": {
        "id": "T_hXCqqYl5H1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option (a): Put Text Datafile in your GDrive project directory\n",
        "\n",
        "If you have a Text Datafile ready to use, just copy it into your GDrive folder that is the project directory for this LDA exercise (listed below)"
      ],
      "metadata": {
        "id": "jRPvitp0l88h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Put your Textfile in the current project directory:\\n')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ctAppijl68t",
        "outputId": "afc6cd50-ba71-4f46-c630-c38607cbb444"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Put your Textfile in the current project directory:\n",
            "\n",
            "/gdrive/MyDrive/cdh/nlp_topic_modeling_lda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[SKIP] to next Section [LDA MODEL]**"
      ],
      "metadata": {
        "id": "IUTMhNmDmh87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd recent_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rgIoCZRu9QV",
        "outputId": "39250664-517e-4a44-8f8a-7f8727999eb0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/cdh/nlp_topic_modeling_lda/recent_texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr hpotter*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IydidQWOu9OE",
        "outputId": "2812cb86-5a74-44c8-cd8d-e5475741f699"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1146084 Mar  3 17:09 hpotter7_deathly_hollows_utf8.txt\n",
            "-rw------- 1 root root  991744 Mar  3 17:09 hpotter6_the_half_blood_prince_utf8.txt\n",
            "-rw------- 1 root root 1517476 Mar  3 17:09 hpotter5_order_of_the_phoenix_utf8.txt\n",
            "-rw------- 1 root root 1123157 Mar  3 17:09 hpotter4_the_goblet_of_fire_utf8.txt\n",
            "-rw------- 1 root root  624699 Mar  3 17:09 hpotter3_the_prisoner_of_azkaban_utf8.txt\n",
            "-rw------- 1 root root  498919 Mar  3 17:09 hpotter2_chamber_of_secrets_utf8.txt\n",
            "-rw------- 1 root root  448834 Mar  3 17:09 hpotter1_sorcerers_stone_utf8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat hpotter* > all_7hpotter_books_utf8.txt"
      ],
      "metadata": {
        "id": "_ZH_BUBgw5fR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option (b): Use 'wget' Command\n",
        "\n",
        "If you don't have a Textfile ready, let's just grab one to be able to continue learning about Gensim LDA.\n",
        "\n",
        "[wget] is a Unix utility that allows you to wEB GET and download most any publically available file on the Internet given the URL to it."
      ],
      "metadata": {
        "id": "1ObGFTQ-mnWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option (b)(i): If you have a URL to an open, freely available text document enter it in the next code cell below\n",
        "\n",
        "Option (b)(ii): If you don't have a URL, \n",
        "\n",
        "* goto https://www.gutenberg.org/\n",
        "\n",
        "* search for a longish novel (e.g. 'middlemarch' at https://www.gutenberg.org/ebooks/145)\n",
        "\n",
        "* Click on the 'Plain Text UTF-8' version to goto the plain text version of the novel, copy the URL and paste it in the next code cell below"
      ],
      "metadata": {
        "id": "lkpXsSTCnvXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the variable url to your link address\n",
        "#  (e.g. url = 'https://www.gutenberg.org/ebooks/145')\n",
        "\n",
        "url_text = 'https://www.gutenberg.org/files/145/145-0.txt'\n",
        "\n",
        "!wget $url_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xk7z0Ntl650",
        "outputId": "bf9d695a-3416-4e00-a725-ca3e391f9f31"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 18:06:09--  https://www.gutenberg.org/files/145/145-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1865681 (1.8M) [text/plain]\n",
            "Saving to: ‘145-0.txt.3’\n",
            "\n",
            "145-0.txt.3         100%[===================>]   1.78M  9.52MB/s    in 0.2s    \n",
            "\n",
            "2022-03-28 18:06:10 (9.52 MB/s) - ‘145-0.txt.3’ saved [1865681/1865681]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What filename was just downloaded\n",
        "#   (time sorted, so at top of list below)\n",
        "\n",
        "!ls -altr *145*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAuJcEATpBzL",
        "outputId": "6a9d9dd6-3ba5-4d99-a113-a9dca6242c9d"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1865681 Mar 31  2021 145-0.txt.3\n",
            "-rw------- 1 root root 1865681 Mar 31  2021 145-0.txt.2\n",
            "-rw------- 1 root root 1865681 Mar 31  2021 145-0.txt.1\n",
            "-rw------- 1 root root 1865681 Mar 31  2021 145-0.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [OPTIONAL]: Make your Textdata filename more user-friendly\n",
        "\n",
        "textfile_downloaded = '145-0.txt'\n",
        "textfile_name = 'middlemarch.txt'\n",
        "\n",
        "!mv $textfile_downloaded $textfile_name\n",
        "\n",
        "!ls -altr middle*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6ElCOaYnWVQ",
        "outputId": "73843717-1355-4709-93af-664dffcd0b65"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1865681 Mar 28 18:07 middlemarch.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS_9h1COgftx"
      },
      "source": [
        "\n",
        "# LDA Model\n",
        "\n",
        "Introduces Gensim's LDA model and demonstrates its use on the NIPS corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt_T3h4Sgft0"
      },
      "source": [
        "The purpose of this tutorial is to demonstrate how to train and tune an LDA model.\n",
        "\n",
        "In this tutorial we will:\n",
        "\n",
        "* Load input data.\n",
        "* Pre-process that data.\n",
        "* Transform documents into bag-of-words vectors.\n",
        "* Train an LDA model.\n",
        "\n",
        "This tutorial will **not**:\n",
        "\n",
        "* Explain how Latent Dirichlet Allocation works\n",
        "* Explain how the LDA model performs inference\n",
        "* Teach you all the parameters and options for Gensim's LDA implementation\n",
        "\n",
        "If you are not familiar with the LDA model or how to use it in Gensim, I (Olavur Mortensen)\n",
        "suggest you read up on that before continuing with this tutorial. Basic\n",
        "understanding of the LDA model should suffice. Examples:\n",
        "\n",
        "* `Introduction to Latent Dirichlet Allocation <http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation>`_\n",
        "* Gensim tutorial: `sphx_glr_auto_examples_core_run_topics_and_transformations.py`\n",
        "* Gensim's LDA model API docs: :py:class:`gensim.models.LdaModel`\n",
        "\n",
        "I would also encourage you to consider each step when applying the model to\n",
        "your data, instead of just blindly applying my solution. The different steps\n",
        "will depend on your data and possibly your goal with the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Textfile"
      ],
      "metadata": {
        "id": "7jjmPqPgJYiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge2CPut6u6Sc",
        "outputId": "955e958e-dbd9-4017-fb02-31c0729c8dd9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/cdh/nlp_topic_modeling_lda/recent_texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ..\n",
        "!ls *7concatenated.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRuG6LoAu7_n",
        "outputId": "6e27284d-6421-4feb-b401-2421ed609310"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "potter_7concatenated.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textfile_name = 'potter_7concatenated.txt'\n",
        "textfile_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_T3vE9NWuts7",
        "outputId": "fc29dc39-acd1-4ff2-896e-ac398c6b5f69"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'potter_7concatenated.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(textfile_name, 'r', encoding='ascii', errors='ignore') as f:\n",
        "    book_all_str = f.read()\n",
        "\n",
        "type(book_all_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWw6qXKujUys",
        "outputId": "5372cad6-56ac-4136-9fc1-3de935a3f46e"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get char count\n",
        "len(book_all_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeNI8PHHJeZR",
        "outputId": "a258581e-b2c2-4f72-9a63-47f069d3daf9"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6296045"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_all_str[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "eN-9efRcJeGi",
        "outputId": "6bba4885-9e6b-4c01-d48e-5d6403c43ba3"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Harry Potter and the Sorcerer's Stone\\nby J.K. Rowling\\n\\nCHAPTER ONE\\n\\nTHE BOY WHO LIVED\\n\\nMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\\nthat they were perfectly normal, thank you very much. They were the last\\npeople you'd expect to be involved in anything strange or mysterious,\\nbecause they just didn't hold with such nonsense.\\n\\nMr. Dursley was the director of a firm called Grunnings, which made\\ndrills. He was a big, beefy man with hardly any neck, although he did\\nhave a very large mustache. Mrs. Dursley was thin and blonde and had\\nnearly twice the usual amount of neck, which came in very useful as she\\nspent so much of her time craning over garden fences, spying on the\\nneighbors. The Dursleys had a small son called Dudley and in their\\nopinion there was no finer boy anywhere.\\n\\nThe Dursleys had everything they wanted, but they also had a secret, and\\ntheir greatest fear was that somebody would discover it. They didn't\\nthink they could bear it if anyone found out about \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Book/Corpus into Paragraphs/Documents"
      ],
      "metadata": {
        "id": "KFNBZmV0K-wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into paragraphs\n",
        "book_parags_ls = book_all_str.split('\\n\\n')\n",
        "\n",
        "# Replace stray/embedded /n with a space\n",
        "book_parags_clean_ls = []\n",
        "for aparag in book_parags_ls:\n",
        "  book_parags_clean_ls.append(aparag.replace('\\n',' '))\n",
        "\n",
        "book_parags_ls = book_parags_clean_ls\n",
        "book_parags_ls[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3FxV2LKKQrB",
        "outputId": "f026455f-7eec-425c-b747-f75a5d1bcc5e"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Harry Potter and the Sorcerer's Stone by J.K. Rowling\",\n",
              " 'CHAPTER ONE',\n",
              " 'THE BOY WHO LIVED',\n",
              " \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\",\n",
              " 'Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.']"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paragraph count\n",
        "len(book_parags_ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD76z1K4Lb2b",
        "outputId": "7b50d6b3-f860-4b69-fed3-8ecd2e92fe19"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40029"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify first paragraph (after title and chapter headings)\n",
        "\n",
        "book_parags_ls[3]\n",
        "print('\\n')\n",
        "# Paragraph char count\n",
        "len(book_parags_ls[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "KCXF860_MIpI",
        "outputId": "ce1f4ffe-35b7-4b17-ba2e-74b3e52ce6c1"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 201
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "262"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete any paragraphs shorter than MIN_LEN_PARAG\n",
        "\n",
        "MIN_LEN_PARAG = 5\n",
        "MIN_LEN_DOC = 1000\n",
        "\n",
        "# Delete any paragraphs shorter than MIN_LEN_PARAG\n",
        "book_parags_ls = [x for x in book_parags_ls if len(x) > MIN_LEN_PARAG]\n",
        "\n",
        "# Trim any leading/trailing/multiple embedded whitespaces\n",
        "book_parags_ls = [' '.join(x.split()) for x in book_parags_ls]\n",
        "\n",
        "len(book_parags_ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN7YcYK3KurS",
        "outputId": "9c6ecc7f-53d9-4b22-f13a-ef27ccf7eb2b"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39904"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agglomerate paragraphs into Documents of MIN_LEN_DOC=1000 chars\n",
        "\n",
        "parag_ct = len(book_parags_ls)\n",
        "\n",
        "doc_now_str = ''\n",
        "doc_now_len = 0\n",
        "docs = []\n",
        "\n",
        "for i in range(parag_ct):\n",
        "  # print(f'Processing Paragraph #{i}')\n",
        "  parag_now_str = book_parags_ls[i]\n",
        "  doc_now_str += parag_now_str\n",
        "  doc_now_len += len(parag_now_str)\n",
        "  if doc_now_len > MIN_LEN_DOC:\n",
        "    docs.append(doc_now_str)\n",
        "    doc_now_str = ''\n",
        "    doc_now_len = 0\n",
        "\n",
        "docs[-1] += doc_now_str\n",
        "\n",
        "print(f'There are now {len(docs)} Documents of {MIN_LEN_DOC} chars or more')"
      ],
      "metadata": {
        "id": "eeIM8FkjKupE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2432d6-9766-43a9-a253-40faec6334fb"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are now 5375 Documents of 1000 chars or more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 5 docs\n",
        "\n",
        "docs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gTq_SyWKunI",
        "outputId": "e7b6655c-e737-4d54-ab0a-e90f0ab68d84"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Harry Potter and the Sorcerer's Stone by J.K. RowlingCHAPTER ONETHE BOY WHO LIVEDMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, but they hadn't met for several years; in fact, Mrs. Dursley pretended she didn't have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn't want Dudley mixing with a child like that.\",\n",
              " 'When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.None of them noticed a large, tawny owl flutter past the window.At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs. Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got into his car and backed out of number four\\'s drive.It was on the corner of the street that he noticed the first sign of something peculiar -- a cat reading a map. For a second, Mr. Dursley didn\\'t realize what he had seen -- then he jerked his head around to look again. There was a tabby cat standing on the corner of Privet Drive, but there wasn\\'t a map in sight. What could he have been thinking of? It must have been a trick of the light. Mr. Dursley blinked and stared at the cat. It stared back. As Mr. Dursley drove around the corner and up the road, he watched the cat in his mirror. It was now reading the sign that said Privet Drive -- no, looking at the sign; cats couldn\\'t read maps or signs. Mr. Dursley gave himself a little shake and put the cat out of his mind. As he drove toward town he thought of nothing except a large order of drills he was hoping to get that day.',\n",
              " \"But on the edge of town, drills were driven out of his mind by something else. As he sat in the usual morning traffic jam, he couldn't help noticing that there seemed to be a lot of strangely dressed people about. People in cloaks. Mr. Dursley couldn't bear people who dressed in funny clothes -- the getups you saw on young people! He supposed this was some stupid new fashion. He drummed his fingers on the steering wheel and his eyes fell on a huddle of these weirdos standing quite close by. They were whispering excitedly together. Mr. Dursley was enraged to see that a couple of them weren't young at all; why, that man had to be older than he was, and wearing an emerald-green cloak! The nerve of him! But then it struck Mr. Dursley that this was probably some silly stunt -- these people were obviously collecting for something... yes, that would be it. The traffic moved on and a few minutes later, Mr. Dursley arrived in the Grunnings parking lot, his mind back on drills.Mr. Dursley always sat with his back to the window in his office on the ninth floor. If he hadn't, he might have found it harder to concentrate on drills that morning. He didn't see the owls swoop ing past in broad daylight, though people down in the street did; they pointed and gazed open- mouthed as owl after owl sped overhead. Most of them had never seen an owl even at nighttime. Mr. Dursley, however, had a perfectly normal, owl-free morning. He yelled at five different people. He made several important telephone calls and shouted a bit more. He was in a very good mood until lunchtime, when he thought he'd stretch his legs and walk across the road to buy himself a bun from the bakery.\",\n",
              " 'He\\'d forgotten all about the people in cloaks until he passed a group of them next to the baker\\'s. He eyed them angrily as he passed. He didn\\'t know why, but they made him uneasy. This bunch were whispering excitedly, too, and he couldn\\'t see a single collecting tin. It was on his way back past them, clutching a large doughnut in a bag, that he caught a few words of what they were saying.\"The Potters, that\\'s right, that\\'s what I heard yes, their son, Harry\"Mr. Dursley stopped dead. Fear flooded him. He looked back at the whisperers as if he wanted to say something to them, but thought better of it.He dashed back across the road, hurried up to his office, snapped at his secretary not to disturb him, seized his telephone, and had almost finished dialing his home number when he changed his mind. He put the receiver back down and stroked his mustache, thinking... no, he was being stupid. Potter wasn\\'t such an unusual name. He was sure there were lots of people called Potter who had a son called Harry. Come to think of it, he wasn\\'t even sure his nephew was called Harry. He\\'d never even seen the boy. It might have been Harvey. Or Harold. There was no point in worrying Mrs. Dursley; she always got so upset at any mention of her sister. He didn\\'t blame her -- if he\\'d had a sister like that... but all the same, those people in cloaks...',\n",
              " 'He found it a lot harder to concentrate on drills that afternoon and when he left the building at five o\\'clock, he was still so worried that he walked straight into someone just outside the door.\"Sorry,\" he grunted, as the tiny old man stumbled and almost fell. It was a few seconds before Mr. Dursley realized that the man was wearing a violet cloak. He didn\\'t seem at all upset at being almost knocked to the ground. On the contrary, his face split into a wide smile and he said in a squeaky voice that made passersby stare, \"Don\\'t be sorry, my dear sir, for nothing could upset me today! Rejoice, for You-Know-Who has gone at last! Even Muggles like yourself should be celebrating, this happy, happy day!\"And the old man hugged Mr. Dursley around the middle and walked off.Mr. Dursley stood rooted to the spot. He had been hugged by a complete stranger. He also thought he had been called a Muggle, whatever that was. He was rattled. He hurried to his car and set off for home, hoping he was imagining things, which he had never hoped before, because he didn\\'t approve of imagination.']"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 500 chars in the 50th doc\n",
        "\n",
        "docs[49][:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "pK59gJoVKuRk",
        "outputId": "97aaa002-c1a8-4f9c-bba4-52915ebf3b61"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Who on earth wants to talk to you this badly?\" Dudley asked Harry in amazement.On Sunday morning, Uncle Vernon sat down at the breakfast table looking tired and rather ill, but happy.\"No post on Sundays,\" he reminded them cheerfully as he spread marmalade on his newspapers, \"no damn letters today --\"Something came whizzing down the kitchen chimney as he spoke and caught him sharply on the back of the head. Next moment, thirty or forty letters came pelting out of the fireplace like bullets. The '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4jA-R3YCgft3",
        "outputId": "2bf5c1ba-d3df-49e9-c846-818b7787a33c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' scar on his forehead.I know he will.The scar had not pained Harry for nineteen years. All was well.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "# View the last 100 chars in the last doc\n",
        "\n",
        "docs[-1][-100:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzKW9vZgft4"
      },
      "source": [
        "## Pre-process and vectorize the documents\n",
        "\n",
        "As part of preprocessing, we will:\n",
        "\n",
        "* Expand Contractions\n",
        "* Tokenize (split the documents into tokens)\n",
        "* Define stopwords and filter out\n",
        "* Lemmatize the tokens.\n",
        "* Compute bigrams.\n",
        "* Compute a bag-of-words representation of the data.\n",
        "\n",
        "First we tokenize the text using a regular expression tokenizer from NLTK. We\n",
        "remove numeric tokens and tokens that are only a single character, as they\n",
        "don't tend to be useful, and the dataset contains a lot of them.\n",
        "\n",
        ".. Important::\n",
        "\n",
        "   This tutorial uses the nltk library for preprocessing, although you can\n",
        "   replace it with something else if you want.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expand Contractions"
      ],
      "metadata": {
        "id": "65I_UBaumu8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contractions (e.g. can't -> can not)\n",
        "\n",
        "import contractions\n",
        "\n",
        "# Test\n",
        "contractions.fix(\"yall're happy now\", slang=False) # default: true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "8mtC2FHRj9nJ",
        "outputId": "7de7f566-e45b-42cf-b7cb-0f2203143be6"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.68)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"yall're happy now\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand all Contractions paragraph by paragraph\n",
        "docs_clean_ls = []\n",
        "for adoc in docs:\n",
        "  docs_clean_ls.append(contractions.fix(adoc))\n",
        "\n",
        "docs = docs_clean_ls\n",
        "docs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-FDOfPGl-W2",
        "outputId": "7c970dd9-fc06-4ea9-a8b1-46d81fb7795f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Harry Potter and the Sorcerer's Stone by J.K. RowlingCHAPTER ONETHE BOY WHO LIVEDMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you would expect to be involved in anything strange or mysterious, because they just did not hold with such nonsense.Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They did not think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, but they had not met for several years; in fact, Mrs. Dursley pretended she did not have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they did not want Dudley mixing with a child like that.\",\n",
              " 'When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.None of them noticed a large, tawny owl flutter past the window.At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs. Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got into his car and backed out of number four\\'s drive.It was on the corner of the street that he noticed the first sign of something peculiar -- a cat reading a map. For a second, Mr. Dursley did not realize what he had seen -- then he jerked his head around to look again. There was a tabby cat standing on the corner of Privet Drive, but there was not a map in sight. What could he have been thinking of? It must have been a trick of the light. Mr. Dursley blinked and stared at the cat. It stared back. As Mr. Dursley drove around the corner and up the road, he watched the cat in his mirror. It was now reading the sign that said Privet Drive -- no, looking at the sign; cats could not read maps or signs. Mr. Dursley gave himself a little shake and put the cat out of his mind. As he drove toward town he thought of nothing except a large order of drills he was hoping to get that day.',\n",
              " 'But on the edge of town, drills were driven out of his mind by something else. As he sat in the usual morning traffic jam, he could not help noticing that there seemed to be a lot of strangely dressed people about. People in cloaks. Mr. Dursley could not bear people who dressed in funny clothes -- the getups you saw on young people! He supposed this was some stupid new fashion. He drummed his fingers on the steering wheel and his eyes fell on a huddle of these weirdos standing quite close by. They were whispering excitedly together. Mr. Dursley was enraged to see that a couple of them were not young at all; why, that man had to be older than he was, and wearing an emerald-green cloak! The nerve of him! But then it struck Mr. Dursley that this was probably some silly stunt -- these people were obviously collecting for something... yes, that would be it. The traffic moved on and a few minutes later, Mr. Dursley arrived in the Grunnings parking lot, his mind back on drills.Mr. Dursley always sat with his back to the window in his office on the ninth floor. If he had not, he might have found it harder to concentrate on drills that morning. He did not see the owls swoop ing past in broad daylight, though people down in the street did; they pointed and gazed open- mouthed as owl after owl sped overhead. Most of them had never seen an owl even at nighttime. Mr. Dursley, however, had a perfectly normal, owl-free morning. He yelled at five different people. He made several important telephone calls and shouted a bit more. He was in a very good mood until lunchtime, when he thought he would stretch his legs and walk across the road to buy himself a bun from the bakery.',\n",
              " 'He would forgotten all about the people in cloaks until he passed a group of them next to the baker\\'s. He eyed them angrily as he passed. He did not know why, but they made him uneasy. This bunch were whispering excitedly, too, and he could not see a single collecting tin. It was on his way back past them, clutching a large doughnut in a bag, that he caught a few words of what they were saying.\"The Potters, that is right, that is what I heard yes, their son, Harry\"Mr. Dursley stopped dead. Fear flooded him. He looked back at the whisperers as if he wanted to say something to them, but thought better of it.He dashed back across the road, hurried up to his office, snapped at his secretary not to disturb him, seized his telephone, and had almost finished dialing his home number when he changed his mind. He put the receiver back down and stroked his mustache, thinking... no, he was being stupid. Potter was not such an unusual name. He was sure there were lots of people called Potter who had a son called Harry. Come to think of it, he was not even sure his nephew was called Harry. He would never even seen the boy. It might have been Harvey. Or Harold. There was no point in worrying Mrs. Dursley; she always got so upset at any mention of her sister. He did not blame her -- if he would had a sister like that... but all the same, those people in cloaks...',\n",
              " 'He found it a lot harder to concentrate on drills that afternoon and when he left the building at five of the clock, he was still so worried that he walked straight into someone just outside the door.\"Sorry,\" he grunted, as the tiny old man stumbled and almost fell. It was a few seconds before Mr. Dursley realized that the man was wearing a violet cloak. He did not seem at all upset at being almost knocked to the ground. On the contrary, his face split into a wide smile and he said in a squeaky voice that made passersby stare, \"Do not be sorry, my dear sir, for nothing could upset me today! Rejoice, for You-Know-Who has gone at last! Even Muggles like yourself should be celebrating, this happy, happy day!\"And the old man hugged Mr. Dursley around the middle and walked off.Mr. Dursley stood rooted to the spot. He had been hugged by a complete stranger. He also thought he had been called a Muggle, whatever that was. He was rattled. He hurried to his car and set off for home, hoping he was imagining things, which he had never hoped before, because he did not approve of imagination.']"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize Text"
      ],
      "metadata": {
        "id": "0APjvgrZm0hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "pplVNGTUgft4"
      },
      "outputs": [],
      "source": [
        "# Tokenize the documents.\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Split the documents into tokens.\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for idx in range(len(docs)):\n",
        "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
        "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "\n",
        "# Remove numbers, but not words that contain numbers.\n",
        "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
        "\n",
        "# Remove words that are only one character.\n",
        "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify docs\n",
        "\n",
        "# content and token count of first doc\n",
        "docs[0]\n",
        "print(f'\\n\\nThere are {len(docs[0])} tokens in the first document')"
      ],
      "metadata": {
        "id": "1dY809w2jeCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e78c0c-25f5-4af5-88a3-9f5bb04e9030"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['harry',\n",
              " 'potter',\n",
              " 'and',\n",
              " 'the',\n",
              " 'sorcerer',\n",
              " 'stone',\n",
              " 'by',\n",
              " 'rowlingchapter',\n",
              " 'onethe',\n",
              " 'boy',\n",
              " 'who',\n",
              " 'livedmr',\n",
              " 'and',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'of',\n",
              " 'number',\n",
              " 'four',\n",
              " 'privet',\n",
              " 'drive',\n",
              " 'were',\n",
              " 'proud',\n",
              " 'to',\n",
              " 'say',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'perfectly',\n",
              " 'normal',\n",
              " 'thank',\n",
              " 'you',\n",
              " 'very',\n",
              " 'much',\n",
              " 'they',\n",
              " 'were',\n",
              " 'the',\n",
              " 'last',\n",
              " 'people',\n",
              " 'you',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'be',\n",
              " 'involved',\n",
              " 'in',\n",
              " 'anything',\n",
              " 'strange',\n",
              " 'or',\n",
              " 'mysterious',\n",
              " 'because',\n",
              " 'they',\n",
              " 'just',\n",
              " 'didn',\n",
              " 'hold',\n",
              " 'with',\n",
              " 'such',\n",
              " 'nonsense',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'was',\n",
              " 'the',\n",
              " 'director',\n",
              " 'of',\n",
              " 'firm',\n",
              " 'called',\n",
              " 'grunnings',\n",
              " 'which',\n",
              " 'made',\n",
              " 'drills',\n",
              " 'he',\n",
              " 'was',\n",
              " 'big',\n",
              " 'beefy',\n",
              " 'man',\n",
              " 'with',\n",
              " 'hardly',\n",
              " 'any',\n",
              " 'neck',\n",
              " 'although',\n",
              " 'he',\n",
              " 'did',\n",
              " 'have',\n",
              " 'very',\n",
              " 'large',\n",
              " 'mustache',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'was',\n",
              " 'thin',\n",
              " 'and',\n",
              " 'blonde',\n",
              " 'and',\n",
              " 'had',\n",
              " 'nearly',\n",
              " 'twice',\n",
              " 'the',\n",
              " 'usual',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'neck',\n",
              " 'which',\n",
              " 'came',\n",
              " 'in',\n",
              " 'very',\n",
              " 'useful',\n",
              " 'as',\n",
              " 'she',\n",
              " 'spent',\n",
              " 'so',\n",
              " 'much',\n",
              " 'of',\n",
              " 'her',\n",
              " 'time',\n",
              " 'craning',\n",
              " 'over',\n",
              " 'garden',\n",
              " 'fences',\n",
              " 'spying',\n",
              " 'on',\n",
              " 'the',\n",
              " 'neighbors',\n",
              " 'the',\n",
              " 'dursleys',\n",
              " 'had',\n",
              " 'small',\n",
              " 'son',\n",
              " 'called',\n",
              " 'dudley',\n",
              " 'and',\n",
              " 'in',\n",
              " 'their',\n",
              " 'opinion',\n",
              " 'there',\n",
              " 'was',\n",
              " 'no',\n",
              " 'finer',\n",
              " 'boy',\n",
              " 'anywhere',\n",
              " 'the',\n",
              " 'dursleys',\n",
              " 'had',\n",
              " 'everything',\n",
              " 'they',\n",
              " 'wanted',\n",
              " 'but',\n",
              " 'they',\n",
              " 'also',\n",
              " 'had',\n",
              " 'secret',\n",
              " 'and',\n",
              " 'their',\n",
              " 'greatest',\n",
              " 'fear',\n",
              " 'was',\n",
              " 'that',\n",
              " 'somebody',\n",
              " 'would',\n",
              " 'discover',\n",
              " 'it',\n",
              " 'they',\n",
              " 'didn',\n",
              " 'think',\n",
              " 'they',\n",
              " 'could',\n",
              " 'bear',\n",
              " 'it',\n",
              " 'if',\n",
              " 'anyone',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'the',\n",
              " 'potters',\n",
              " 'mrs',\n",
              " 'potter',\n",
              " 'was',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'sister',\n",
              " 'but',\n",
              " 'they',\n",
              " 'hadn',\n",
              " 'met',\n",
              " 'for',\n",
              " 'several',\n",
              " 'years',\n",
              " 'in',\n",
              " 'fact',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'pretended',\n",
              " 'she',\n",
              " 'didn',\n",
              " 'have',\n",
              " 'sister',\n",
              " 'because',\n",
              " 'her',\n",
              " 'sister',\n",
              " 'and',\n",
              " 'her',\n",
              " 'good',\n",
              " 'for',\n",
              " 'nothing',\n",
              " 'husband',\n",
              " 'were',\n",
              " 'as',\n",
              " 'undursleyish',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'possible',\n",
              " 'to',\n",
              " 'be',\n",
              " 'the',\n",
              " 'dursleys',\n",
              " 'shuddered',\n",
              " 'to',\n",
              " 'think',\n",
              " 'what',\n",
              " 'the',\n",
              " 'neighbors',\n",
              " 'would',\n",
              " 'say',\n",
              " 'if',\n",
              " 'the',\n",
              " 'potters',\n",
              " 'arrived',\n",
              " 'in',\n",
              " 'the',\n",
              " 'street',\n",
              " 'the',\n",
              " 'dursleys',\n",
              " 'knew',\n",
              " 'that',\n",
              " 'the',\n",
              " 'potters',\n",
              " 'had',\n",
              " 'small',\n",
              " 'son',\n",
              " 'too',\n",
              " 'but',\n",
              " 'they',\n",
              " 'had',\n",
              " 'never',\n",
              " 'even',\n",
              " 'seen',\n",
              " 'him',\n",
              " 'this',\n",
              " 'boy',\n",
              " 'was',\n",
              " 'another',\n",
              " 'good',\n",
              " 'reason',\n",
              " 'for',\n",
              " 'keeping',\n",
              " 'the',\n",
              " 'potters',\n",
              " 'away',\n",
              " 'they',\n",
              " 'didn',\n",
              " 'want',\n",
              " 'dudley',\n",
              " 'mixing',\n",
              " 'with',\n",
              " 'child',\n",
              " 'like',\n",
              " 'that']"
            ]
          },
          "metadata": {},
          "execution_count": 213
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 266 tokens in the first document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customize Stopwords"
      ],
      "metadata": {
        "id": "JH33oN6vmx4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords_ls = stopwords.words('english')\n",
        "\n",
        "print(f'\\nThe first ten stopwords:')\n",
        "stopwords_ls[20:]\n",
        "print(f'\\n\\nThere are [{len(stopwords_ls)}] English stopwords imported from NLTK')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiuFCv0Ef07n",
        "outputId": "ee47c1ac-c32c-4a8a-a467-799132f98619"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 214
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The first ten stopwords:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are [179] English stopwords imported from NLTK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all stopwords with contractions (optional - could also remove fragments like 'll', 're', and 've' but not necessary)\n",
        "\n",
        "stopwords_ls = [x for x in stopwords_ls if not \"'\" in x]\n",
        "stopwords_ls[20:]\n",
        "print(f'\\n\\nThere are now {len(stopwords_ls)} stopwords after removing words with contractions')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4glO1gNtngd4",
        "outputId": "3094521a-05c2-4f09-adfc-51c6cbd5f184"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['herself',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " 'should',\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " 'couldn',\n",
              " 'didn',\n",
              " 'doesn',\n",
              " 'hadn',\n",
              " 'hasn',\n",
              " 'haven',\n",
              " 'isn',\n",
              " 'ma',\n",
              " 'mightn',\n",
              " 'mustn',\n",
              " 'needn',\n",
              " 'shan',\n",
              " 'shouldn',\n",
              " 'wasn',\n",
              " 'weren',\n",
              " 'won',\n",
              " 'wouldn']"
            ]
          },
          "metadata": {},
          "execution_count": 215
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are now 153 stopwords after removing words with contractions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[CUSTOMIZE] Stopwords list by adding or deleting tokens**"
      ],
      "metadata": {
        "id": "7aATg-NyvVX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [CUSTOMIZE] Stopwords to ADD or DELETE from default NLTK English stopword list\n",
        "\n",
        "STOPWORDS_ADD_SET = set(['bazinga', 'woo-hoo']) # Edit this list to add new words to the stopwords list\n",
        "STOPWORDS_DEL_SET = set(['the']) # Edit this list to remove exising words from the stopwords list\n",
        "\n",
        "stopwords_en_ls = list(set(stopwords_ls).difference(set(STOPWORDS_DEL_SET)).union(set(STOPWORDS_ADD_SET)))\n",
        "print(f'Final Count after Customized Add/Del: {len(stopwords_en_ls)} Stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glbh2ePNfdEy",
        "outputId": "bd6f973d-5799-4f92-c25a-0ab4fba5e8fe"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Count after Customized Add/Del: 154 Stopwords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatize"
      ],
      "metadata": {
        "id": "Yq08gxuCm45Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5F_B5V0gft5"
      },
      "source": [
        "We use the WordNet lemmatizer from NLTK. A lemmatizer is preferred over a\n",
        "stemmer in this case because it produces more readable words. Output that is\n",
        "easy to read is very desirable in topic modelling.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9XiwmYDg5Zh",
        "outputId": "2ba8010c-f346-4429-8668-f8c67087dba6"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "oF_I-F9Rgft5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dc4171-a63e-420a-de2d-78ea1eecdb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.8 s, sys: 28.4 ms, total: 4.83 s\n",
            "Wall time: 4.87 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 0m24s @03:48 on 20220228 Colab Pro \n",
        "\n",
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeHP0Dougft6"
      },
      "source": [
        "We find bigrams in the documents. Bigrams are sets of two adjacent words.\n",
        "Using bigrams we can get phrases like \"machine_learning\" in our output\n",
        "(spaces are replaced with underscores); without bigrams we would only get\n",
        "\"machine\" and \"learning\".\n",
        "\n",
        "Note that in the code below, we find bigrams and then add them to the\n",
        "original data, because we would like to keep the words \"machine\" and\n",
        "\"learning\" as well as the bigram \"machine_learning\".\n",
        "\n",
        ".. Important::\n",
        "    Computing n-grams of large dataset can be very computationally\n",
        "    and memory intensive.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify Bi- and Tri-Grams"
      ],
      "metadata": {
        "id": "od5nsgvem8E_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk5VQcqSgft6",
        "outputId": "a6116747-ca5f-449e-8a02-dcc7cf87c08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-28 18:17:29,876 : INFO : collecting all words and their counts\n",
            "2022-03-28 18:17:29,883 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "2022-03-28 18:17:32,407 : INFO : collected 351552 word types from a corpus of 1054368 words (unigram + bigrams) and 5375 sentences\n",
            "2022-03-28 18:17:32,413 : INFO : using 351552 counts as vocab in Phrases<0 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n"
          ]
        }
      ],
      "source": [
        "# Compute bigrams.\n",
        "from gensim.models import Phrases\n",
        "\n",
        "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
        "bigram = Phrases(docs, min_count=20)\n",
        "for idx in range(len(docs)):\n",
        "    for token in bigram[docs[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            docs[idx].append(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5o8CBSMgft6"
      },
      "source": [
        "We remove rare words and common words based on their *document frequency*.\n",
        "Below we remove words that appear in less than 20 documents or in more than\n",
        "50% of the documents. Consider trying to remove words only based on their\n",
        "frequency, or maybe combining that with this approach.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Minimum number of documents a word must appear in: (default 20)\n",
        "\n",
        "Min_No_Documents = 20 #@param {type:\"slider\", min:5, max:100, step:1}\n",
        "\n",
        "#@markdown Max percent of documents a word can appear in: (default 0.50 or 50%)\n",
        "\n",
        "Max_Percent_Documents = 0.5 #@param {type:\"slider\", min:0.05, max:0.9, step:0.01}\n"
      ],
      "metadata": {
        "id": "nFiU_87MpQJO"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "6Aa1mH88gft7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fa0005-34f0-4bf6-9620-8f87787888b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-28 18:17:55,151 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2022-03-28 18:17:56,471 : INFO : built Dictionary(22417 unique tokens: ['a', 'about', 'also', 'although', 'amount']...) from 5375 documents (total 1097259 corpus positions)\n",
            "2022-03-28 18:17:56,636 : INFO : discarding 18478 tokens: [('a', 3793), ('and', 5321), ('be', 2828), ('beefy', 3), ('but', 3618), ('craning', 16), ('director', 2), ('drill', 8), ('finer', 5), ('for', 3354)]...\n",
            "2022-03-28 18:17:56,639 : INFO : keeping 3939 tokens which were in no less than 20 and no more than 2687 (=50.0%) documents\n",
            "2022-03-28 18:17:56,662 : INFO : resulting dictionary: Dictionary(3939 unique tokens: ['about', 'also', 'although', 'amount', 'another']...)\n"
          ]
        }
      ],
      "source": [
        "# Remove rare and common tokens.\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(docs)\n",
        "\n",
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "dictionary.filter_extremes(no_below=Min_No_Documents, no_above=Max_Percent_Documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0YX0ewEgft7"
      },
      "source": [
        "Finally, we transform the documents to a vectorized form. We simply compute\n",
        "the frequency of each word, including the bigrams.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "i7WBqZ5Mgft7"
      },
      "outputs": [],
      "source": [
        "# Bag-of-words representation of the documents.\n",
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eAsWXotgft8"
      },
      "source": [
        "Let's see how many tokens and documents we have to train on.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus as a list of documents, each a list of tokens identifyed by dictionary tuples\n",
        "\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh9LzoeXhfip",
        "outputId": "a36b7592-6d6c-4e9c-964f-0e3993dbb542"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5375"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpRsFMgAhgzn",
        "outputId": "0969e254-07fe-4c54-c9d5-71e824b08be8"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42KjXcKPhtJF",
        "outputId": "79e70b49-c021-4be8-8225-17490e0167bf"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1),\n",
              " (1, 1),\n",
              " (2, 1),\n",
              " (3, 1),\n",
              " (4, 1),\n",
              " (5, 1),\n",
              " (6, 1),\n",
              " (7, 1),\n",
              " (8, 1),\n",
              " (9, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oZGyeXzgft8",
        "outputId": "05eb051c-4656-41ea-bef8-791df81a65fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique tokens: 3939\n",
            "Number of documents: 5375\n"
          ]
        }
      ],
      "source": [
        "print('Number of unique tokens: %d' % len(dictionary))  # Orig 1864\n",
        "print('Number of documents: %d' % len(corpus))          # Orig 1740"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqaaUBeagft8"
      },
      "source": [
        "## Training\n",
        "\n",
        "We are ready to train the LDA model. We will first discuss how to set some of\n",
        "the training parameters.\n",
        "\n",
        "First of all, the elephant in the room: how many topics do I need? There is\n",
        "really no easy answer for this, it will depend on both your data and your\n",
        "application. I have used 10 topics here because I wanted to have a few topics\n",
        "that I could interpret and \"label\", and because that turned out to give me\n",
        "reasonably good results. You might not need to interpret all your topics, so\n",
        "you could use a large number of topics, for example 100.\n",
        "\n",
        "``chunksize`` controls how many documents are processed at a time in the\n",
        "training algorithm. Increasing chunksize will speed up training, at least as\n",
        "long as the chunk of documents easily fit into memory. I've set ``chunksize =\n",
        "2000``, which is more than the amount of documents, so I process all the\n",
        "data in one go. Chunksize can however influence the quality of the model, as\n",
        "discussed in Hoffman and co-authors [2], but the difference was not\n",
        "substantial in this case.\n",
        "\n",
        "``passes`` controls how often we train the model on the entire corpus.\n",
        "Another word for passes might be \"epochs\". ``iterations`` is somewhat\n",
        "technical, but essentially it controls how often we repeat a particular loop\n",
        "over each document. It is important to set the number of \"passes\" and\n",
        "\"iterations\" high enough.\n",
        "\n",
        "I suggest the following way to choose iterations and passes. First, enable\n",
        "logging (as described in many Gensim tutorials), and set ``eval_every = 1``\n",
        "in ``LdaModel``. When training the model look for a line in the log that\n",
        "looks something like this::\n",
        "\n",
        "   2016-06-21 15:40:06,753 - gensim.models.ldamodel - DEBUG - 68/1566 documents converged within 400 iterations\n",
        "\n",
        "If you set ``passes = 20`` you will see this line 20 times. Make sure that by\n",
        "the final passes, most of the documents have converged. So you want to choose\n",
        "both passes and iterations to be high enough for this to happen.\n",
        "\n",
        "We set ``alpha = 'auto'`` and ``eta = 'auto'``. Again this is somewhat\n",
        "technical, but essentially we are automatically learning two parameters in\n",
        "the model that we usually would have to specify explicitly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown How many Topics do you want to find?\n",
        "\n",
        "No_of_Topics = 10 #@param {type:\"slider\", min:2, max:200, step:1}\n",
        "\n",
        "#@markdown Default 10-50 depending upon how large the text and diverse the vocabulary"
      ],
      "metadata": {
        "id": "evkoGUByoQFL"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0wOHHJCgft9",
        "outputId": "91168c9d-fb3c-4326-c193-c8af63ddcdaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-28 18:19:30,976 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
            "2022-03-28 18:19:30,980 : INFO : using serial LDA version on this node\n",
            "2022-03-28 18:19:30,990 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 5375 documents, updating model once every 2000 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
            "2022-03-28 18:19:30,995 : INFO : PROGRESS: pass 0, at document #2000/5375\n",
            "2022-03-28 18:19:39,605 : INFO : optimized alpha [0.055956107, 0.06970318, 0.085161895, 0.053631734, 0.0656931, 0.063605644, 0.049110614, 0.063020125, 0.06691721, 0.051566537]\n",
            "2022-03-28 18:19:39,610 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:39,621 : INFO : topic #6 (0.049): 0.008*\"have\" + 0.008*\"there\" + 0.007*\"their\" + 0.006*\"if\" + 0.006*\"mr\" + 0.006*\"is\" + 0.006*\"been\" + 0.006*\"my\" + 0.005*\"didn\" + 0.005*\"me\"\n",
            "2022-03-28 18:19:39,632 : INFO : topic #9 (0.052): 0.014*\"ron\" + 0.009*\"hagrid\" + 0.008*\"them\" + 0.008*\"hermione\" + 0.007*\"into\" + 0.007*\"her\" + 0.006*\"so\" + 0.006*\"there\" + 0.006*\"got\" + 0.006*\"about\"\n",
            "2022-03-28 18:19:39,635 : INFO : topic #8 (0.067): 0.011*\"ron\" + 0.009*\"hermione\" + 0.009*\"them\" + 0.007*\"back\" + 0.006*\"there\" + 0.006*\"into\" + 0.006*\"her\" + 0.006*\"have\" + 0.006*\"is\" + 0.005*\"about\"\n",
            "2022-03-28 18:19:39,639 : INFO : topic #1 (0.070): 0.013*\"ron\" + 0.011*\"hermione\" + 0.008*\"she\" + 0.007*\"mr\" + 0.007*\"back\" + 0.007*\"have\" + 0.007*\"weasley\" + 0.006*\"into\" + 0.006*\"her\" + 0.006*\"them\"\n",
            "2022-03-28 18:19:39,643 : INFO : topic #2 (0.085): 0.010*\"ron\" + 0.010*\"her\" + 0.008*\"professor\" + 0.008*\"she\" + 0.006*\"them\" + 0.006*\"been\" + 0.005*\"back\" + 0.005*\"hagrid\" + 0.005*\"their\" + 0.005*\"who\"\n",
            "2022-03-28 18:19:39,648 : INFO : topic diff=3.017397, rho=1.000000\n",
            "2022-03-28 18:19:39,666 : INFO : PROGRESS: pass 0, at document #4000/5375\n",
            "2022-03-28 18:19:44,892 : INFO : optimized alpha [0.053778615, 0.07345688, 0.09136705, 0.050797842, 0.0657512, 0.058950342, 0.048545115, 0.05873912, 0.07311768, 0.0472604]\n",
            "2022-03-28 18:19:44,895 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:44,905 : INFO : topic #9 (0.047): 0.012*\"ron\" + 0.012*\"hagrid\" + 0.010*\"hermione\" + 0.009*\"her\" + 0.008*\"them\" + 0.007*\"an\" + 0.007*\"she\" + 0.006*\"into\" + 0.006*\"so\" + 0.006*\"no\"\n",
            "2022-03-28 18:19:44,908 : INFO : topic #6 (0.049): 0.012*\"have\" + 0.010*\"my\" + 0.008*\"is\" + 0.008*\"sirius\" + 0.008*\"me\" + 0.007*\"been\" + 0.007*\"there\" + 0.006*\"would\" + 0.006*\"who\" + 0.006*\"so\"\n",
            "2022-03-28 18:19:44,911 : INFO : topic #8 (0.073): 0.009*\"hermione\" + 0.009*\"ron\" + 0.009*\"her\" + 0.007*\"them\" + 0.007*\"is\" + 0.007*\"back\" + 0.007*\"have\" + 0.006*\"she\" + 0.006*\"there\" + 0.005*\"about\"\n",
            "2022-03-28 18:19:44,914 : INFO : topic #1 (0.073): 0.013*\"ron\" + 0.012*\"hermione\" + 0.011*\"she\" + 0.009*\"her\" + 0.009*\"mr\" + 0.009*\"weasley\" + 0.008*\"mr_weasley\" + 0.007*\"have\" + 0.006*\"know\" + 0.006*\"well\"\n",
            "2022-03-28 18:19:44,917 : INFO : topic #2 (0.091): 0.016*\"her\" + 0.012*\"she\" + 0.010*\"professor\" + 0.008*\"ron\" + 0.007*\"dumbledore\" + 0.006*\"them\" + 0.006*\"been\" + 0.006*\"have\" + 0.005*\"who\" + 0.005*\"hermione\"\n",
            "2022-03-28 18:19:44,919 : INFO : topic diff=0.969076, rho=0.707107\n",
            "2022-03-28 18:19:44,933 : INFO : PROGRESS: pass 0, at document #5375/5375\n",
            "2022-03-28 18:19:47,851 : INFO : optimized alpha [0.05083306, 0.07562204, 0.089505196, 0.048785202, 0.073189154, 0.057176635, 0.050193593, 0.05960858, 0.084326304, 0.043298334]\n",
            "2022-03-28 18:19:47,856 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:47,866 : INFO : topic #9 (0.043): 0.014*\"hagrid\" + 0.012*\"ron\" + 0.010*\"hermione\" + 0.009*\"them\" + 0.007*\"her\" + 0.007*\"an\" + 0.007*\"into\" + 0.006*\"there\" + 0.006*\"she\" + 0.006*\"back\"\n",
            "2022-03-28 18:19:47,868 : INFO : topic #3 (0.049): 0.012*\"have\" + 0.010*\"we\" + 0.009*\"so\" + 0.008*\"would\" + 0.007*\"this\" + 0.007*\"snape\" + 0.007*\"been\" + 0.007*\"ron\" + 0.007*\"hermione\" + 0.007*\"is\"\n",
            "2022-03-28 18:19:47,871 : INFO : topic #1 (0.076): 0.015*\"ron\" + 0.013*\"hermione\" + 0.012*\"she\" + 0.011*\"her\" + 0.008*\"mr\" + 0.007*\"weasley\" + 0.007*\"have\" + 0.007*\"mr_weasley\" + 0.007*\"know\" + 0.006*\"we\"\n",
            "2022-03-28 18:19:47,874 : INFO : topic #8 (0.084): 0.010*\"hermione\" + 0.010*\"ron\" + 0.008*\"her\" + 0.008*\"have\" + 0.007*\"them\" + 0.007*\"is\" + 0.007*\"there\" + 0.006*\"know\" + 0.006*\"she\" + 0.006*\"dumbledore\"\n",
            "2022-03-28 18:19:47,876 : INFO : topic #2 (0.090): 0.018*\"her\" + 0.014*\"she\" + 0.009*\"professor\" + 0.008*\"dumbledore\" + 0.007*\"ron\" + 0.006*\"them\" + 0.005*\"been\" + 0.005*\"who\" + 0.005*\"have\" + 0.005*\"into\"\n",
            "2022-03-28 18:19:47,878 : INFO : topic diff=0.595842, rho=0.577350\n",
            "2022-03-28 18:19:47,900 : INFO : PROGRESS: pass 1, at document #2000/5375\n",
            "2022-03-28 18:19:51,240 : INFO : optimized alpha [0.04682293, 0.075355954, 0.089944504, 0.046511874, 0.0667586, 0.05453678, 0.047647066, 0.060974527, 0.073324576, 0.042670347]\n",
            "2022-03-28 18:19:51,242 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:51,260 : INFO : topic #9 (0.043): 0.027*\"hagrid\" + 0.013*\"ron\" + 0.010*\"hermione\" + 0.009*\"them\" + 0.009*\"an\" + 0.008*\"yeh\" + 0.007*\"ter\" + 0.007*\"into\" + 0.006*\"there\" + 0.006*\"ve\"\n",
            "2022-03-28 18:19:51,264 : INFO : topic #3 (0.047): 0.012*\"have\" + 0.011*\"we\" + 0.009*\"so\" + 0.008*\"would\" + 0.008*\"this\" + 0.008*\"snape\" + 0.007*\"been\" + 0.007*\"ron\" + 0.006*\"is\" + 0.006*\"if\"\n",
            "2022-03-28 18:19:51,269 : INFO : topic #8 (0.073): 0.010*\"hermione\" + 0.009*\"ron\" + 0.008*\"is\" + 0.007*\"have\" + 0.007*\"them\" + 0.007*\"her\" + 0.007*\"know\" + 0.006*\"there\" + 0.006*\"me\" + 0.006*\"back\"\n",
            "2022-03-28 18:19:51,273 : INFO : topic #1 (0.075): 0.016*\"ron\" + 0.012*\"hermione\" + 0.011*\"she\" + 0.011*\"mr\" + 0.009*\"weasley\" + 0.009*\"her\" + 0.008*\"mr_weasley\" + 0.007*\"know\" + 0.007*\"have\" + 0.006*\"we\"\n",
            "2022-03-28 18:19:51,277 : INFO : topic #2 (0.090): 0.015*\"her\" + 0.012*\"she\" + 0.012*\"professor\" + 0.008*\"ron\" + 0.006*\"dumbledore\" + 0.006*\"them\" + 0.005*\"who\" + 0.005*\"been\" + 0.005*\"their\" + 0.005*\"have\"\n",
            "2022-03-28 18:19:51,280 : INFO : topic diff=0.355232, rho=0.461880\n",
            "2022-03-28 18:19:51,299 : INFO : PROGRESS: pass 1, at document #4000/5375\n",
            "2022-03-28 18:19:54,726 : INFO : optimized alpha [0.045867372, 0.07814084, 0.091696195, 0.046150222, 0.06621118, 0.052875906, 0.04881127, 0.06138927, 0.078298785, 0.040625803]\n",
            "2022-03-28 18:19:54,728 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:54,741 : INFO : topic #9 (0.041): 0.033*\"hagrid\" + 0.012*\"an\" + 0.011*\"ron\" + 0.011*\"hermione\" + 0.010*\"ter\" + 0.009*\"yeh\" + 0.009*\"them\" + 0.007*\"back\" + 0.006*\"we\" + 0.006*\"there\"\n",
            "2022-03-28 18:19:54,744 : INFO : topic #0 (0.046): 0.010*\"she\" + 0.010*\"mr\" + 0.009*\"her\" + 0.006*\"well\" + 0.006*\"been\" + 0.006*\"ron\" + 0.006*\"this\" + 0.006*\"eye\" + 0.006*\"have\" + 0.005*\"wand\"\n",
            "2022-03-28 18:19:54,750 : INFO : topic #1 (0.078): 0.016*\"ron\" + 0.013*\"hermione\" + 0.012*\"she\" + 0.012*\"mr\" + 0.011*\"her\" + 0.010*\"weasley\" + 0.009*\"mr_weasley\" + 0.007*\"know\" + 0.006*\"we\" + 0.006*\"have\"\n",
            "2022-03-28 18:19:54,755 : INFO : topic #8 (0.078): 0.010*\"hermione\" + 0.009*\"ron\" + 0.008*\"her\" + 0.008*\"is\" + 0.007*\"have\" + 0.007*\"know\" + 0.007*\"them\" + 0.006*\"she\" + 0.006*\"me\" + 0.006*\"there\"\n",
            "2022-03-28 18:19:54,758 : INFO : topic #2 (0.092): 0.018*\"her\" + 0.015*\"she\" + 0.013*\"professor\" + 0.007*\"ron\" + 0.007*\"dumbledore\" + 0.006*\"them\" + 0.005*\"who\" + 0.005*\"been\" + 0.005*\"have\" + 0.005*\"their\"\n",
            "2022-03-28 18:19:54,761 : INFO : topic diff=0.288872, rho=0.461880\n",
            "2022-03-28 18:19:54,776 : INFO : PROGRESS: pass 1, at document #5375/5375\n",
            "2022-03-28 18:19:56,756 : INFO : optimized alpha [0.044606462, 0.07770461, 0.08683393, 0.04532485, 0.07390918, 0.051213536, 0.05077848, 0.06405431, 0.090236686, 0.0381663]\n",
            "2022-03-28 18:19:56,770 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:56,782 : INFO : topic #9 (0.038): 0.037*\"hagrid\" + 0.012*\"an\" + 0.010*\"hermione\" + 0.010*\"ter\" + 0.010*\"ron\" + 0.010*\"yeh\" + 0.009*\"them\" + 0.007*\"back\" + 0.006*\"we\" + 0.006*\"there\"\n",
            "2022-03-28 18:19:56,786 : INFO : topic #0 (0.045): 0.010*\"she\" + 0.009*\"wand\" + 0.009*\"mr\" + 0.009*\"her\" + 0.006*\"eye\" + 0.006*\"this\" + 0.006*\"ron\" + 0.006*\"been\" + 0.006*\"well\" + 0.006*\"have\"\n",
            "2022-03-28 18:19:56,789 : INFO : topic #1 (0.078): 0.017*\"ron\" + 0.014*\"she\" + 0.014*\"hermione\" + 0.012*\"her\" + 0.011*\"mr\" + 0.010*\"weasley\" + 0.009*\"mr_weasley\" + 0.007*\"know\" + 0.007*\"we\" + 0.006*\"have\"\n",
            "2022-03-28 18:19:56,792 : INFO : topic #2 (0.087): 0.019*\"her\" + 0.016*\"she\" + 0.013*\"professor\" + 0.007*\"dumbledore\" + 0.006*\"ron\" + 0.006*\"them\" + 0.005*\"who\" + 0.005*\"mcgonagall\" + 0.005*\"been\" + 0.005*\"their\"\n",
            "2022-03-28 18:19:56,795 : INFO : topic #8 (0.090): 0.011*\"hermione\" + 0.010*\"ron\" + 0.008*\"have\" + 0.008*\"her\" + 0.008*\"know\" + 0.008*\"is\" + 0.007*\"dumbledore\" + 0.007*\"there\" + 0.007*\"them\" + 0.007*\"she\"\n",
            "2022-03-28 18:19:56,797 : INFO : topic diff=0.296690, rho=0.461880\n",
            "2022-03-28 18:19:56,813 : INFO : PROGRESS: pass 2, at document #2000/5375\n",
            "2022-03-28 18:19:59,743 : INFO : optimized alpha [0.042175274, 0.07925564, 0.08887162, 0.045312025, 0.068486035, 0.05010676, 0.049745295, 0.067166135, 0.079405695, 0.039585356]\n",
            "2022-03-28 18:19:59,745 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:19:59,758 : INFO : topic #9 (0.040): 0.040*\"hagrid\" + 0.012*\"an\" + 0.011*\"yeh\" + 0.011*\"ron\" + 0.010*\"hermione\" + 0.009*\"ter\" + 0.009*\"them\" + 0.009*\"ve\" + 0.008*\"don\" + 0.007*\"got\"\n",
            "2022-03-28 18:19:59,761 : INFO : topic #0 (0.042): 0.012*\"mr\" + 0.009*\"she\" + 0.008*\"wand\" + 0.007*\"her\" + 0.006*\"been\" + 0.006*\"this\" + 0.006*\"eye\" + 0.006*\"ron\" + 0.005*\"have\" + 0.005*\"well\"\n",
            "2022-03-28 18:19:59,765 : INFO : topic #1 (0.079): 0.018*\"ron\" + 0.013*\"hermione\" + 0.012*\"mr\" + 0.012*\"she\" + 0.010*\"weasley\" + 0.010*\"her\" + 0.009*\"mr_weasley\" + 0.007*\"know\" + 0.007*\"we\" + 0.006*\"about\"\n",
            "2022-03-28 18:19:59,767 : INFO : topic #8 (0.079): 0.010*\"hermione\" + 0.009*\"ron\" + 0.008*\"have\" + 0.008*\"is\" + 0.008*\"know\" + 0.007*\"her\" + 0.007*\"me\" + 0.007*\"there\" + 0.006*\"them\" + 0.006*\"dumbledore\"\n",
            "2022-03-28 18:19:59,770 : INFO : topic #2 (0.089): 0.016*\"her\" + 0.015*\"professor\" + 0.014*\"she\" + 0.007*\"ron\" + 0.006*\"dumbledore\" + 0.006*\"mcgonagall\" + 0.006*\"them\" + 0.005*\"professor_mcgonagall\" + 0.005*\"who\" + 0.005*\"their\"\n",
            "2022-03-28 18:19:59,772 : INFO : topic diff=0.253190, rho=0.419314\n",
            "2022-03-28 18:19:59,794 : INFO : PROGRESS: pass 2, at document #4000/5375\n",
            "2022-03-28 18:20:02,827 : INFO : optimized alpha [0.04197153, 0.08148282, 0.09122401, 0.045717727, 0.06902361, 0.049344927, 0.051095203, 0.068654, 0.08531737, 0.037994727]\n",
            "2022-03-28 18:20:02,830 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:02,842 : INFO : topic #9 (0.038): 0.043*\"hagrid\" + 0.014*\"an\" + 0.011*\"yeh\" + 0.011*\"ter\" + 0.011*\"hermione\" + 0.010*\"ron\" + 0.009*\"them\" + 0.008*\"we\" + 0.007*\"ve\" + 0.007*\"back\"\n",
            "2022-03-28 18:20:02,846 : INFO : topic #0 (0.042): 0.012*\"mr\" + 0.010*\"she\" + 0.009*\"her\" + 0.008*\"wand\" + 0.006*\"eye\" + 0.006*\"this\" + 0.006*\"well\" + 0.006*\"been\" + 0.005*\"have\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:02,848 : INFO : topic #1 (0.081): 0.018*\"ron\" + 0.013*\"hermione\" + 0.013*\"mr\" + 0.013*\"she\" + 0.012*\"weasley\" + 0.012*\"her\" + 0.010*\"mr_weasley\" + 0.007*\"we\" + 0.007*\"know\" + 0.006*\"about\"\n",
            "2022-03-28 18:20:02,850 : INFO : topic #8 (0.085): 0.010*\"hermione\" + 0.009*\"ron\" + 0.008*\"her\" + 0.008*\"know\" + 0.008*\"have\" + 0.008*\"is\" + 0.007*\"she\" + 0.007*\"me\" + 0.006*\"there\" + 0.006*\"dumbledore\"\n",
            "2022-03-28 18:20:02,859 : INFO : topic #2 (0.091): 0.019*\"her\" + 0.016*\"she\" + 0.016*\"professor\" + 0.006*\"ron\" + 0.006*\"dumbledore\" + 0.006*\"them\" + 0.006*\"mcgonagall\" + 0.005*\"who\" + 0.005*\"their\" + 0.005*\"been\"\n",
            "2022-03-28 18:20:02,863 : INFO : topic diff=0.220503, rho=0.419314\n",
            "2022-03-28 18:20:02,886 : INFO : PROGRESS: pass 2, at document #5375/5375\n",
            "2022-03-28 18:20:04,693 : INFO : optimized alpha [0.041542538, 0.07988369, 0.0863269, 0.04508982, 0.07738028, 0.04806642, 0.05280824, 0.072023086, 0.098724164, 0.03609708]\n",
            "2022-03-28 18:20:04,695 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:04,710 : INFO : topic #9 (0.036): 0.048*\"hagrid\" + 0.014*\"an\" + 0.012*\"yeh\" + 0.011*\"ter\" + 0.010*\"hermione\" + 0.009*\"ron\" + 0.008*\"them\" + 0.008*\"we\" + 0.007*\"back\" + 0.006*\"me\"\n",
            "2022-03-28 18:20:04,714 : INFO : topic #0 (0.042): 0.012*\"wand\" + 0.011*\"she\" + 0.010*\"mr\" + 0.009*\"her\" + 0.007*\"eye\" + 0.006*\"this\" + 0.006*\"been\" + 0.006*\"well\" + 0.005*\"have\" + 0.005*\"ollivander\"\n",
            "2022-03-28 18:20:04,721 : INFO : topic #1 (0.080): 0.019*\"ron\" + 0.014*\"she\" + 0.014*\"hermione\" + 0.013*\"mr\" + 0.013*\"her\" + 0.011*\"weasley\" + 0.010*\"mr_weasley\" + 0.007*\"we\" + 0.007*\"know\" + 0.006*\"have\"\n",
            "2022-03-28 18:20:04,728 : INFO : topic #2 (0.086): 0.020*\"her\" + 0.017*\"she\" + 0.016*\"professor\" + 0.006*\"dumbledore\" + 0.006*\"mcgonagall\" + 0.006*\"ron\" + 0.006*\"them\" + 0.006*\"who\" + 0.005*\"professor_mcgonagall\" + 0.005*\"their\"\n",
            "2022-03-28 18:20:04,730 : INFO : topic #8 (0.099): 0.011*\"hermione\" + 0.010*\"ron\" + 0.009*\"have\" + 0.009*\"know\" + 0.008*\"her\" + 0.008*\"is\" + 0.007*\"dumbledore\" + 0.007*\"she\" + 0.007*\"there\" + 0.007*\"me\"\n",
            "2022-03-28 18:20:04,737 : INFO : topic diff=0.228467, rho=0.419314\n",
            "2022-03-28 18:20:04,755 : INFO : PROGRESS: pass 3, at document #2000/5375\n",
            "2022-03-28 18:20:07,521 : INFO : optimized alpha [0.039763387, 0.08132512, 0.0888374, 0.045823608, 0.072561316, 0.047577042, 0.052369043, 0.075455785, 0.08763553, 0.038672857]\n",
            "2022-03-28 18:20:07,524 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:07,536 : INFO : topic #9 (0.039): 0.042*\"hagrid\" + 0.012*\"an\" + 0.011*\"ve\" + 0.011*\"yeh\" + 0.010*\"hermione\" + 0.010*\"don\" + 0.009*\"ron\" + 0.009*\"ter\" + 0.009*\"ll\" + 0.009*\"them\"\n",
            "2022-03-28 18:20:07,540 : INFO : topic #0 (0.040): 0.013*\"mr\" + 0.011*\"wand\" + 0.009*\"she\" + 0.008*\"her\" + 0.007*\"eye\" + 0.007*\"this\" + 0.006*\"been\" + 0.005*\"have\" + 0.005*\"is\" + 0.005*\"well\"\n",
            "2022-03-28 18:20:07,543 : INFO : topic #1 (0.081): 0.020*\"ron\" + 0.014*\"mr\" + 0.013*\"she\" + 0.013*\"hermione\" + 0.012*\"weasley\" + 0.011*\"her\" + 0.010*\"mr_weasley\" + 0.007*\"we\" + 0.007*\"know\" + 0.006*\"about\"\n",
            "2022-03-28 18:20:07,546 : INFO : topic #8 (0.088): 0.011*\"hermione\" + 0.009*\"ron\" + 0.009*\"know\" + 0.009*\"have\" + 0.008*\"is\" + 0.007*\"her\" + 0.007*\"me\" + 0.007*\"there\" + 0.007*\"dumbledore\" + 0.007*\"she\"\n",
            "2022-03-28 18:20:07,549 : INFO : topic #2 (0.089): 0.017*\"professor\" + 0.017*\"her\" + 0.015*\"she\" + 0.007*\"ron\" + 0.007*\"mcgonagall\" + 0.006*\"professor_mcgonagall\" + 0.006*\"them\" + 0.006*\"dumbledore\" + 0.006*\"who\" + 0.005*\"their\"\n",
            "2022-03-28 18:20:07,552 : INFO : topic diff=0.208227, rho=0.386695\n",
            "2022-03-28 18:20:07,567 : INFO : PROGRESS: pass 3, at document #4000/5375\n",
            "2022-03-28 18:20:10,254 : INFO : optimized alpha [0.039876178, 0.083270684, 0.09153314, 0.04644882, 0.073620126, 0.04724823, 0.053719517, 0.07682511, 0.09390911, 0.037506457]\n",
            "2022-03-28 18:20:10,257 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:10,271 : INFO : topic #9 (0.038): 0.044*\"hagrid\" + 0.014*\"an\" + 0.011*\"hermione\" + 0.011*\"yeh\" + 0.011*\"ter\" + 0.010*\"we\" + 0.009*\"ve\" + 0.009*\"don\" + 0.009*\"ron\" + 0.008*\"them\"\n",
            "2022-03-28 18:20:10,275 : INFO : topic #0 (0.040): 0.012*\"mr\" + 0.011*\"she\" + 0.010*\"wand\" + 0.010*\"her\" + 0.006*\"eye\" + 0.006*\"this\" + 0.006*\"well\" + 0.006*\"been\" + 0.005*\"looked\" + 0.005*\"very\"\n",
            "2022-03-28 18:20:10,281 : INFO : topic #1 (0.083): 0.019*\"ron\" + 0.015*\"mr\" + 0.013*\"she\" + 0.013*\"hermione\" + 0.013*\"weasley\" + 0.012*\"her\" + 0.011*\"mr_weasley\" + 0.007*\"we\" + 0.007*\"fred\" + 0.006*\"know\"\n",
            "2022-03-28 18:20:10,284 : INFO : topic #2 (0.092): 0.020*\"her\" + 0.017*\"professor\" + 0.017*\"she\" + 0.006*\"ron\" + 0.006*\"mcgonagall\" + 0.006*\"them\" + 0.006*\"dumbledore\" + 0.006*\"who\" + 0.006*\"professor_mcgonagall\" + 0.005*\"their\"\n",
            "2022-03-28 18:20:10,286 : INFO : topic #8 (0.094): 0.011*\"hermione\" + 0.009*\"ron\" + 0.009*\"know\" + 0.008*\"have\" + 0.008*\"her\" + 0.008*\"is\" + 0.007*\"she\" + 0.007*\"me\" + 0.007*\"there\" + 0.007*\"dont\"\n",
            "2022-03-28 18:20:10,288 : INFO : topic diff=0.180295, rho=0.386695\n",
            "2022-03-28 18:20:10,308 : INFO : PROGRESS: pass 3, at document #5375/5375\n",
            "2022-03-28 18:20:12,023 : INFO : optimized alpha [0.03984886, 0.08110339, 0.08679295, 0.04594, 0.082131945, 0.046241987, 0.055197738, 0.07995489, 0.10790384, 0.03574607]\n",
            "2022-03-28 18:20:12,025 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:12,042 : INFO : topic #9 (0.036): 0.049*\"hagrid\" + 0.014*\"an\" + 0.011*\"yeh\" + 0.011*\"ter\" + 0.010*\"hermione\" + 0.009*\"we\" + 0.008*\"ron\" + 0.008*\"don\" + 0.008*\"them\" + 0.008*\"ve\"\n",
            "2022-03-28 18:20:12,044 : INFO : topic #0 (0.040): 0.015*\"wand\" + 0.011*\"she\" + 0.011*\"mr\" + 0.010*\"her\" + 0.007*\"this\" + 0.006*\"eye\" + 0.006*\"been\" + 0.006*\"luna\" + 0.005*\"ollivander\" + 0.005*\"well\"\n",
            "2022-03-28 18:20:12,051 : INFO : topic #4 (0.082): 0.011*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.007*\"there\" + 0.007*\"dumbledore\" + 0.007*\"death\" + 0.007*\"hand\" + 0.007*\"eye\" + 0.006*\"then\" + 0.006*\"face\"\n",
            "2022-03-28 18:20:12,056 : INFO : topic #2 (0.087): 0.021*\"her\" + 0.018*\"she\" + 0.017*\"professor\" + 0.007*\"mcgonagall\" + 0.006*\"ron\" + 0.006*\"dumbledore\" + 0.006*\"them\" + 0.006*\"professor_mcgonagall\" + 0.006*\"who\" + 0.005*\"their\"\n",
            "2022-03-28 18:20:12,061 : INFO : topic #8 (0.108): 0.012*\"hermione\" + 0.010*\"ron\" + 0.009*\"know\" + 0.009*\"have\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"she\" + 0.007*\"me\" + 0.007*\"dumbledore\" + 0.007*\"there\"\n",
            "2022-03-28 18:20:12,065 : INFO : topic diff=0.190053, rho=0.386695\n",
            "2022-03-28 18:20:12,085 : INFO : PROGRESS: pass 4, at document #2000/5375\n",
            "2022-03-28 18:20:14,622 : INFO : optimized alpha [0.038533136, 0.0824098, 0.08892138, 0.0470133, 0.07703572, 0.0461584, 0.055048987, 0.08326728, 0.09590132, 0.038992558]\n",
            "2022-03-28 18:20:14,625 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:14,636 : INFO : topic #0 (0.039): 0.014*\"mr\" + 0.013*\"wand\" + 0.010*\"she\" + 0.009*\"her\" + 0.007*\"this\" + 0.007*\"eye\" + 0.006*\"been\" + 0.005*\"is\" + 0.005*\"one\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:14,640 : INFO : topic #9 (0.039): 0.041*\"hagrid\" + 0.012*\"an\" + 0.012*\"ve\" + 0.012*\"don\" + 0.011*\"hermione\" + 0.010*\"ll\" + 0.010*\"yeh\" + 0.010*\"we\" + 0.009*\"ron\" + 0.009*\"re\"\n",
            "2022-03-28 18:20:14,647 : INFO : topic #7 (0.083): 0.019*\"ron\" + 0.013*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:14,653 : INFO : topic #2 (0.089): 0.019*\"professor\" + 0.018*\"her\" + 0.016*\"she\" + 0.007*\"mcgonagall\" + 0.007*\"ron\" + 0.006*\"professor_mcgonagall\" + 0.006*\"them\" + 0.006*\"dumbledore\" + 0.006*\"who\" + 0.005*\"their\"\n",
            "2022-03-28 18:20:14,659 : INFO : topic #8 (0.096): 0.011*\"hermione\" + 0.010*\"ron\" + 0.009*\"know\" + 0.009*\"have\" + 0.008*\"is\" + 0.008*\"me\" + 0.008*\"her\" + 0.007*\"she\" + 0.007*\"there\" + 0.007*\"we\"\n",
            "2022-03-28 18:20:14,664 : INFO : topic diff=0.188322, rho=0.360668\n",
            "2022-03-28 18:20:14,681 : INFO : PROGRESS: pass 4, at document #4000/5375\n",
            "2022-03-28 18:20:17,133 : INFO : optimized alpha [0.038829453, 0.08422792, 0.09179743, 0.04774567, 0.0780246, 0.046102434, 0.0564466, 0.084394544, 0.10237931, 0.03805025]\n",
            "2022-03-28 18:20:17,135 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:17,152 : INFO : topic #9 (0.038): 0.043*\"hagrid\" + 0.014*\"an\" + 0.011*\"hermione\" + 0.011*\"we\" + 0.010*\"don\" + 0.010*\"ve\" + 0.010*\"yeh\" + 0.010*\"ter\" + 0.009*\"ll\" + 0.009*\"ron\"\n",
            "2022-03-28 18:20:17,158 : INFO : topic #0 (0.039): 0.012*\"mr\" + 0.012*\"wand\" + 0.011*\"she\" + 0.011*\"her\" + 0.007*\"this\" + 0.006*\"eye\" + 0.006*\"been\" + 0.006*\"well\" + 0.005*\"very\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:17,161 : INFO : topic #7 (0.084): 0.017*\"ron\" + 0.012*\"hermione\" + 0.012*\"them\" + 0.011*\"door\" + 0.011*\"into\" + 0.008*\"their\" + 0.007*\"around\" + 0.007*\"there\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:17,166 : INFO : topic #2 (0.092): 0.020*\"her\" + 0.018*\"professor\" + 0.017*\"she\" + 0.007*\"mcgonagall\" + 0.006*\"ron\" + 0.006*\"them\" + 0.006*\"professor_mcgonagall\" + 0.006*\"who\" + 0.005*\"dumbledore\" + 0.005*\"hermione\"\n",
            "2022-03-28 18:20:17,168 : INFO : topic #8 (0.102): 0.012*\"hermione\" + 0.009*\"ron\" + 0.009*\"know\" + 0.009*\"have\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"she\" + 0.008*\"me\" + 0.007*\"dont\" + 0.007*\"we\"\n",
            "2022-03-28 18:20:17,171 : INFO : topic diff=0.161369, rho=0.360668\n",
            "2022-03-28 18:20:17,188 : INFO : PROGRESS: pass 4, at document #5375/5375\n",
            "2022-03-28 18:20:18,746 : INFO : optimized alpha [0.038916573, 0.08196626, 0.08744344, 0.047139436, 0.08672358, 0.045112453, 0.057858825, 0.08746799, 0.11691265, 0.036339074]\n",
            "2022-03-28 18:20:18,751 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:18,762 : INFO : topic #9 (0.036): 0.048*\"hagrid\" + 0.014*\"an\" + 0.011*\"yeh\" + 0.011*\"hermione\" + 0.010*\"we\" + 0.010*\"ter\" + 0.010*\"don\" + 0.009*\"ve\" + 0.008*\"ron\" + 0.008*\"them\"\n",
            "2022-03-28 18:20:18,765 : INFO : topic #0 (0.039): 0.016*\"wand\" + 0.011*\"she\" + 0.011*\"mr\" + 0.011*\"her\" + 0.007*\"this\" + 0.006*\"luna\" + 0.006*\"eye\" + 0.006*\"been\" + 0.005*\"ollivander\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:18,768 : INFO : topic #2 (0.087): 0.021*\"her\" + 0.018*\"she\" + 0.018*\"professor\" + 0.007*\"mcgonagall\" + 0.006*\"professor_mcgonagall\" + 0.006*\"ron\" + 0.006*\"them\" + 0.006*\"dumbledore\" + 0.006*\"who\" + 0.005*\"hermione\"\n",
            "2022-03-28 18:20:18,771 : INFO : topic #7 (0.087): 0.017*\"ron\" + 0.013*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"through\" + 0.007*\"back\"\n",
            "2022-03-28 18:20:18,774 : INFO : topic #8 (0.117): 0.012*\"hermione\" + 0.010*\"ron\" + 0.010*\"know\" + 0.009*\"have\" + 0.008*\"she\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"we\" + 0.008*\"me\" + 0.007*\"dont\"\n",
            "2022-03-28 18:20:18,776 : INFO : topic diff=0.170141, rho=0.360668\n",
            "2022-03-28 18:20:18,790 : INFO : PROGRESS: pass 5, at document #2000/5375\n",
            "2022-03-28 18:20:21,235 : INFO : optimized alpha [0.037864175, 0.082904555, 0.08958098, 0.0484379, 0.08134273, 0.04528881, 0.057806425, 0.09050132, 0.1040404, 0.040223915]\n",
            "2022-03-28 18:20:21,237 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:21,254 : INFO : topic #0 (0.038): 0.015*\"wand\" + 0.014*\"mr\" + 0.010*\"she\" + 0.010*\"her\" + 0.007*\"this\" + 0.006*\"eye\" + 0.006*\"been\" + 0.005*\"one\" + 0.005*\"is\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:21,257 : INFO : topic #9 (0.040): 0.039*\"hagrid\" + 0.013*\"ve\" + 0.012*\"don\" + 0.012*\"an\" + 0.011*\"ll\" + 0.011*\"hermione\" + 0.011*\"we\" + 0.010*\"re\" + 0.009*\"yeh\" + 0.009*\"ron\"\n",
            "2022-03-28 18:20:21,262 : INFO : topic #2 (0.090): 0.020*\"professor\" + 0.018*\"her\" + 0.016*\"she\" + 0.007*\"mcgonagall\" + 0.007*\"professor_mcgonagall\" + 0.007*\"ron\" + 0.006*\"them\" + 0.006*\"who\" + 0.005*\"dumbledore\" + 0.005*\"hermione\"\n",
            "2022-03-28 18:20:21,266 : INFO : topic #7 (0.091): 0.018*\"ron\" + 0.013*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:21,269 : INFO : topic #8 (0.104): 0.012*\"hermione\" + 0.010*\"ron\" + 0.010*\"know\" + 0.009*\"have\" + 0.008*\"is\" + 0.008*\"me\" + 0.008*\"she\" + 0.008*\"her\" + 0.007*\"we\" + 0.007*\"there\"\n",
            "2022-03-28 18:20:21,272 : INFO : topic diff=0.177913, rho=0.339276\n",
            "2022-03-28 18:20:21,289 : INFO : PROGRESS: pass 5, at document #4000/5375\n",
            "2022-03-28 18:20:23,538 : INFO : optimized alpha [0.038211238, 0.08467515, 0.09232446, 0.049202938, 0.08225541, 0.04534993, 0.05921453, 0.09121089, 0.11069686, 0.039366864]\n",
            "2022-03-28 18:20:23,547 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:23,557 : INFO : topic #0 (0.038): 0.013*\"wand\" + 0.012*\"mr\" + 0.011*\"her\" + 0.011*\"she\" + 0.007*\"this\" + 0.006*\"eye\" + 0.005*\"very\" + 0.005*\"been\" + 0.005*\"looked\" + 0.005*\"one\"\n",
            "2022-03-28 18:20:23,559 : INFO : topic #9 (0.039): 0.041*\"hagrid\" + 0.013*\"an\" + 0.012*\"hermione\" + 0.012*\"we\" + 0.011*\"ve\" + 0.011*\"don\" + 0.010*\"ll\" + 0.010*\"yeh\" + 0.009*\"ter\" + 0.009*\"ron\"\n",
            "2022-03-28 18:20:23,567 : INFO : topic #7 (0.091): 0.017*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.011*\"door\" + 0.011*\"into\" + 0.008*\"their\" + 0.007*\"around\" + 0.007*\"there\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:23,570 : INFO : topic #2 (0.092): 0.021*\"her\" + 0.019*\"professor\" + 0.018*\"she\" + 0.007*\"mcgonagall\" + 0.006*\"ron\" + 0.006*\"professor_mcgonagall\" + 0.006*\"them\" + 0.006*\"who\" + 0.006*\"hermione\" + 0.006*\"umbridge\"\n",
            "2022-03-28 18:20:23,576 : INFO : topic #8 (0.111): 0.012*\"hermione\" + 0.010*\"know\" + 0.010*\"ron\" + 0.009*\"have\" + 0.008*\"her\" + 0.008*\"she\" + 0.008*\"is\" + 0.008*\"me\" + 0.007*\"we\" + 0.007*\"dont\"\n",
            "2022-03-28 18:20:23,578 : INFO : topic diff=0.151578, rho=0.339276\n",
            "2022-03-28 18:20:23,594 : INFO : PROGRESS: pass 5, at document #5375/5375\n",
            "2022-03-28 18:20:25,016 : INFO : optimized alpha [0.038483456, 0.082314916, 0.08827963, 0.048668154, 0.09078696, 0.04448575, 0.060568538, 0.09398151, 0.12509485, 0.03764859]\n",
            "2022-03-28 18:20:25,019 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:25,028 : INFO : topic #9 (0.038): 0.046*\"hagrid\" + 0.013*\"an\" + 0.011*\"hermione\" + 0.011*\"we\" + 0.010*\"don\" + 0.010*\"yeh\" + 0.010*\"ve\" + 0.009*\"ter\" + 0.008*\"ll\" + 0.008*\"ron\"\n",
            "2022-03-28 18:20:25,032 : INFO : topic #0 (0.038): 0.018*\"wand\" + 0.011*\"her\" + 0.011*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.007*\"luna\" + 0.006*\"eye\" + 0.005*\"one\" + 0.005*\"been\" + 0.005*\"looked\"\n",
            "2022-03-28 18:20:25,034 : INFO : topic #4 (0.091): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"eye\" + 0.007*\"there\" + 0.007*\"face\" + 0.007*\"death\" + 0.006*\"dumbledore\" + 0.006*\"then\"\n",
            "2022-03-28 18:20:25,037 : INFO : topic #7 (0.094): 0.017*\"ron\" + 0.013*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"through\" + 0.007*\"back\"\n",
            "2022-03-28 18:20:25,039 : INFO : topic #8 (0.125): 0.012*\"hermione\" + 0.010*\"ron\" + 0.010*\"know\" + 0.010*\"have\" + 0.008*\"she\" + 0.008*\"her\" + 0.008*\"we\" + 0.008*\"is\" + 0.008*\"me\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:25,041 : INFO : topic diff=0.157636, rho=0.339276\n",
            "2022-03-28 18:20:25,055 : INFO : PROGRESS: pass 6, at document #2000/5375\n",
            "2022-03-28 18:20:27,285 : INFO : optimized alpha [0.03759813, 0.08318637, 0.09015016, 0.05008522, 0.08523198, 0.044747923, 0.06054972, 0.09662168, 0.11139629, 0.041946214]\n",
            "2022-03-28 18:20:27,288 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:27,298 : INFO : topic #0 (0.038): 0.016*\"wand\" + 0.014*\"mr\" + 0.010*\"her\" + 0.010*\"she\" + 0.007*\"this\" + 0.006*\"eye\" + 0.006*\"one\" + 0.006*\"been\" + 0.005*\"malfoy\" + 0.005*\"very\"\n",
            "2022-03-28 18:20:27,301 : INFO : topic #9 (0.042): 0.037*\"hagrid\" + 0.013*\"ve\" + 0.013*\"don\" + 0.012*\"ll\" + 0.012*\"we\" + 0.012*\"an\" + 0.011*\"hermione\" + 0.010*\"re\" + 0.009*\"ron\" + 0.009*\"got\"\n",
            "2022-03-28 18:20:27,304 : INFO : topic #2 (0.090): 0.021*\"professor\" + 0.019*\"her\" + 0.017*\"she\" + 0.008*\"mcgonagall\" + 0.007*\"professor_mcgonagall\" + 0.007*\"ron\" + 0.006*\"them\" + 0.006*\"who\" + 0.006*\"hermione\" + 0.005*\"dumbledore\"\n",
            "2022-03-28 18:20:27,307 : INFO : topic #7 (0.097): 0.018*\"ron\" + 0.012*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:27,309 : INFO : topic #8 (0.111): 0.012*\"hermione\" + 0.010*\"ron\" + 0.010*\"know\" + 0.009*\"have\" + 0.008*\"is\" + 0.008*\"she\" + 0.008*\"me\" + 0.008*\"we\" + 0.008*\"her\" + 0.007*\"if\"\n",
            "2022-03-28 18:20:27,311 : INFO : topic diff=0.170075, rho=0.321288\n",
            "2022-03-28 18:20:27,326 : INFO : PROGRESS: pass 6, at document #4000/5375\n",
            "2022-03-28 18:20:29,444 : INFO : optimized alpha [0.038074095, 0.084788114, 0.09280077, 0.050955735, 0.08604781, 0.044824496, 0.06201189, 0.09696942, 0.11775587, 0.041110605]\n",
            "2022-03-28 18:20:29,446 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:29,456 : INFO : topic #0 (0.038): 0.014*\"wand\" + 0.012*\"mr\" + 0.012*\"her\" + 0.012*\"she\" + 0.007*\"this\" + 0.006*\"eye\" + 0.006*\"very\" + 0.006*\"luna\" + 0.006*\"one\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:29,461 : INFO : topic #9 (0.041): 0.039*\"hagrid\" + 0.013*\"an\" + 0.012*\"we\" + 0.012*\"hermione\" + 0.012*\"ve\" + 0.012*\"don\" + 0.010*\"ll\" + 0.009*\"re\" + 0.009*\"yeh\" + 0.009*\"ron\"\n",
            "2022-03-28 18:20:29,463 : INFO : topic #2 (0.093): 0.021*\"her\" + 0.020*\"professor\" + 0.018*\"she\" + 0.007*\"mcgonagall\" + 0.006*\"professor_mcgonagall\" + 0.006*\"ron\" + 0.006*\"umbridge\" + 0.006*\"them\" + 0.006*\"hermione\" + 0.006*\"who\"\n",
            "2022-03-28 18:20:29,465 : INFO : topic #7 (0.097): 0.016*\"ron\" + 0.012*\"them\" + 0.011*\"door\" + 0.011*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.007*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:29,472 : INFO : topic #8 (0.118): 0.012*\"hermione\" + 0.010*\"know\" + 0.010*\"ron\" + 0.009*\"have\" + 0.009*\"she\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"me\" + 0.008*\"we\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:29,476 : INFO : topic diff=0.144250, rho=0.321288\n",
            "2022-03-28 18:20:29,496 : INFO : PROGRESS: pass 6, at document #5375/5375\n",
            "2022-03-28 18:20:30,824 : INFO : optimized alpha [0.038439076, 0.082485095, 0.08898481, 0.05036563, 0.09436394, 0.043986075, 0.063266955, 0.09947546, 0.13207471, 0.03932446]\n",
            "2022-03-28 18:20:30,832 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:30,844 : INFO : topic #0 (0.038): 0.019*\"wand\" + 0.012*\"her\" + 0.011*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.007*\"luna\" + 0.006*\"eye\" + 0.006*\"one\" + 0.006*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:30,852 : INFO : topic #9 (0.039): 0.044*\"hagrid\" + 0.013*\"an\" + 0.012*\"we\" + 0.011*\"hermione\" + 0.011*\"don\" + 0.011*\"ve\" + 0.010*\"yeh\" + 0.009*\"ll\" + 0.009*\"ter\" + 0.008*\"ron\"\n",
            "2022-03-28 18:20:30,854 : INFO : topic #4 (0.094): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"eye\" + 0.007*\"face\" + 0.007*\"there\" + 0.007*\"death\" + 0.006*\"then\" + 0.006*\"dumbledore\"\n",
            "2022-03-28 18:20:30,859 : INFO : topic #7 (0.099): 0.017*\"ron\" + 0.013*\"hermione\" + 0.012*\"them\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:30,863 : INFO : topic #8 (0.132): 0.013*\"hermione\" + 0.011*\"ron\" + 0.010*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.008*\"we\" + 0.008*\"her\" + 0.008*\"me\" + 0.008*\"is\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:30,867 : INFO : topic diff=0.148029, rho=0.321288\n",
            "2022-03-28 18:20:30,886 : INFO : PROGRESS: pass 7, at document #2000/5375\n",
            "2022-03-28 18:20:33,073 : INFO : optimized alpha [0.03768194, 0.08308693, 0.09054875, 0.051833395, 0.0886953, 0.044308975, 0.06325386, 0.10197069, 0.117604546, 0.04397554]\n",
            "2022-03-28 18:20:33,076 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:33,088 : INFO : topic #0 (0.038): 0.017*\"wand\" + 0.013*\"mr\" + 0.011*\"her\" + 0.011*\"she\" + 0.007*\"this\" + 0.006*\"one\" + 0.006*\"eye\" + 0.006*\"malfoy\" + 0.006*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:33,090 : INFO : topic #9 (0.044): 0.035*\"hagrid\" + 0.014*\"ve\" + 0.013*\"don\" + 0.012*\"we\" + 0.012*\"ll\" + 0.012*\"hermione\" + 0.011*\"an\" + 0.011*\"re\" + 0.009*\"ron\" + 0.009*\"got\"\n",
            "2022-03-28 18:20:33,093 : INFO : topic #2 (0.091): 0.022*\"professor\" + 0.020*\"her\" + 0.018*\"she\" + 0.008*\"mcgonagall\" + 0.007*\"professor_mcgonagall\" + 0.006*\"ron\" + 0.006*\"them\" + 0.006*\"hermione\" + 0.006*\"who\" + 0.005*\"dumbledore\"\n",
            "2022-03-28 18:20:33,096 : INFO : topic #7 (0.102): 0.018*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:33,098 : INFO : topic #8 (0.118): 0.013*\"hermione\" + 0.011*\"ron\" + 0.010*\"know\" + 0.010*\"have\" + 0.008*\"she\" + 0.008*\"me\" + 0.008*\"we\" + 0.008*\"is\" + 0.008*\"her\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:33,101 : INFO : topic diff=0.162701, rho=0.305888\n",
            "2022-03-28 18:20:33,124 : INFO : PROGRESS: pass 7, at document #4000/5375\n",
            "2022-03-28 18:20:35,233 : INFO : optimized alpha [0.03818494, 0.08445044, 0.09296147, 0.05268526, 0.089243695, 0.044404995, 0.064678736, 0.10227847, 0.12389023, 0.04311104]\n",
            "2022-03-28 18:20:35,236 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:35,248 : INFO : topic #0 (0.038): 0.015*\"wand\" + 0.013*\"her\" + 0.012*\"mr\" + 0.012*\"she\" + 0.007*\"this\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"eye\" + 0.006*\"luna\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:35,251 : INFO : topic #9 (0.043): 0.037*\"hagrid\" + 0.013*\"we\" + 0.012*\"hermione\" + 0.012*\"an\" + 0.012*\"ve\" + 0.012*\"don\" + 0.010*\"ll\" + 0.009*\"re\" + 0.009*\"ron\" + 0.009*\"yeh\"\n",
            "2022-03-28 18:20:35,254 : INFO : topic #2 (0.093): 0.022*\"her\" + 0.021*\"professor\" + 0.019*\"she\" + 0.007*\"mcgonagall\" + 0.007*\"professor_mcgonagall\" + 0.006*\"umbridge\" + 0.006*\"ron\" + 0.006*\"hermione\" + 0.006*\"them\" + 0.006*\"who\"\n",
            "2022-03-28 18:20:35,256 : INFO : topic #7 (0.102): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.007*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:35,259 : INFO : topic #8 (0.124): 0.013*\"hermione\" + 0.010*\"ron\" + 0.010*\"know\" + 0.009*\"have\" + 0.009*\"she\" + 0.008*\"her\" + 0.008*\"me\" + 0.008*\"we\" + 0.008*\"is\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:35,262 : INFO : topic diff=0.137677, rho=0.305888\n",
            "2022-03-28 18:20:35,275 : INFO : PROGRESS: pass 7, at document #5375/5375\n",
            "2022-03-28 18:20:36,567 : INFO : optimized alpha [0.038619347, 0.082318395, 0.08923759, 0.05203978, 0.09739394, 0.0435837, 0.065932676, 0.104470015, 0.1384275, 0.041232277]\n",
            "2022-03-28 18:20:36,570 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:36,582 : INFO : topic #0 (0.039): 0.019*\"wand\" + 0.013*\"her\" + 0.012*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.007*\"luna\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\" + 0.005*\"eye\"\n",
            "2022-03-28 18:20:36,585 : INFO : topic #9 (0.041): 0.042*\"hagrid\" + 0.012*\"an\" + 0.012*\"we\" + 0.012*\"hermione\" + 0.011*\"ve\" + 0.011*\"don\" + 0.010*\"ll\" + 0.009*\"yeh\" + 0.009*\"ron\" + 0.009*\"re\"\n",
            "2022-03-28 18:20:36,587 : INFO : topic #4 (0.097): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"eye\" + 0.007*\"face\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"dumbledore\"\n",
            "2022-03-28 18:20:36,589 : INFO : topic #7 (0.104): 0.017*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.011*\"door\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:36,590 : INFO : topic #8 (0.138): 0.013*\"hermione\" + 0.011*\"ron\" + 0.010*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"we\" + 0.008*\"her\" + 0.008*\"me\" + 0.008*\"is\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:36,599 : INFO : topic diff=0.139964, rho=0.305888\n",
            "2022-03-28 18:20:36,620 : INFO : PROGRESS: pass 8, at document #2000/5375\n",
            "2022-03-28 18:20:38,692 : INFO : optimized alpha [0.037980307, 0.0826418, 0.09066339, 0.053668205, 0.091574274, 0.043929834, 0.065879054, 0.1067313, 0.123014934, 0.046175703]\n",
            "2022-03-28 18:20:38,700 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:38,709 : INFO : topic #0 (0.038): 0.018*\"wand\" + 0.013*\"mr\" + 0.012*\"her\" + 0.011*\"she\" + 0.008*\"this\" + 0.006*\"one\" + 0.006*\"hand\" + 0.006*\"malfoy\" + 0.006*\"looked\" + 0.006*\"is\"\n",
            "2022-03-28 18:20:38,711 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.012*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"one\" + 0.006*\"around\" + 0.006*\"hand\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:38,718 : INFO : topic #4 (0.092): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.007*\"eye\" + 0.007*\"hand\" + 0.007*\"face\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:38,724 : INFO : topic #7 (0.107): 0.017*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:38,729 : INFO : topic #8 (0.123): 0.013*\"hermione\" + 0.011*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"we\" + 0.008*\"me\" + 0.008*\"is\" + 0.008*\"her\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:38,732 : INFO : topic diff=0.155925, rho=0.292509\n",
            "2022-03-28 18:20:38,747 : INFO : PROGRESS: pass 8, at document #4000/5375\n",
            "2022-03-28 18:20:40,752 : INFO : optimized alpha [0.038517155, 0.08395862, 0.093003884, 0.054517616, 0.09200567, 0.044089656, 0.06725528, 0.10683558, 0.12939057, 0.04525954]\n",
            "2022-03-28 18:20:40,755 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:40,768 : INFO : topic #0 (0.039): 0.016*\"wand\" + 0.013*\"her\" + 0.012*\"she\" + 0.012*\"mr\" + 0.007*\"this\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\" + 0.006*\"malfoy\" + 0.006*\"luna\"\n",
            "2022-03-28 18:20:40,771 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.007*\"eye\" + 0.006*\"into\" + 0.006*\"one\" + 0.006*\"around\" + 0.006*\"back\" + 0.006*\"hand\" + 0.006*\"potter\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:40,779 : INFO : topic #2 (0.093): 0.022*\"her\" + 0.022*\"professor\" + 0.019*\"she\" + 0.008*\"mcgonagall\" + 0.007*\"professor_mcgonagall\" + 0.006*\"umbridge\" + 0.006*\"ron\" + 0.006*\"hermione\" + 0.006*\"them\" + 0.006*\"who\"\n",
            "2022-03-28 18:20:40,782 : INFO : topic #7 (0.107): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:40,785 : INFO : topic #8 (0.129): 0.013*\"hermione\" + 0.011*\"ron\" + 0.011*\"know\" + 0.009*\"have\" + 0.009*\"she\" + 0.009*\"her\" + 0.008*\"we\" + 0.008*\"me\" + 0.008*\"is\" + 0.008*\"dont\"\n",
            "2022-03-28 18:20:40,787 : INFO : topic diff=0.131360, rho=0.292509\n",
            "2022-03-28 18:20:40,803 : INFO : PROGRESS: pass 8, at document #5375/5375\n",
            "2022-03-28 18:20:42,064 : INFO : optimized alpha [0.039046817, 0.08189999, 0.089230746, 0.05385408, 0.09999956, 0.043289144, 0.068564415, 0.10885975, 0.1436894, 0.043276202]\n",
            "2022-03-28 18:20:42,067 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:42,083 : INFO : topic #0 (0.039): 0.020*\"wand\" + 0.013*\"her\" + 0.012*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.007*\"luna\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\" + 0.006*\"is\"\n",
            "2022-03-28 18:20:42,086 : INFO : topic #5 (0.043): 0.017*\"snape\" + 0.012*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"them\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:42,088 : INFO : topic #4 (0.100): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"face\" + 0.007*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:42,092 : INFO : topic #7 (0.109): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.012*\"door\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:42,095 : INFO : topic #8 (0.144): 0.014*\"hermione\" + 0.011*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"we\" + 0.009*\"her\" + 0.008*\"me\" + 0.008*\"dont\" + 0.008*\"is\"\n",
            "2022-03-28 18:20:42,097 : INFO : topic diff=0.132945, rho=0.292509\n",
            "2022-03-28 18:20:42,112 : INFO : PROGRESS: pass 9, at document #2000/5375\n",
            "2022-03-28 18:20:44,205 : INFO : optimized alpha [0.038473442, 0.082175344, 0.09059785, 0.055478357, 0.09401907, 0.043663032, 0.06841871, 0.11095611, 0.12784298, 0.048446868]\n",
            "2022-03-28 18:20:44,214 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:44,225 : INFO : topic #0 (0.038): 0.018*\"wand\" + 0.013*\"mr\" + 0.013*\"her\" + 0.011*\"she\" + 0.008*\"this\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"malfoy\" + 0.006*\"is\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:44,227 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.013*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"one\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"hand\" + 0.006*\"malfoy\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:44,234 : INFO : topic #4 (0.094): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.007*\"eye\" + 0.007*\"face\" + 0.007*\"hand\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:44,240 : INFO : topic #7 (0.111): 0.017*\"ron\" + 0.012*\"them\" + 0.012*\"hermione\" + 0.011*\"into\" + 0.011*\"door\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:44,245 : INFO : topic #8 (0.128): 0.013*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"we\" + 0.009*\"me\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:44,247 : INFO : topic diff=0.149277, rho=0.280745\n",
            "2022-03-28 18:20:44,266 : INFO : PROGRESS: pass 9, at document #4000/5375\n",
            "2022-03-28 18:20:46,352 : INFO : optimized alpha [0.03904581, 0.083490424, 0.09286646, 0.056346126, 0.094356395, 0.04384384, 0.06977265, 0.110931866, 0.13399151, 0.047439355]\n",
            "2022-03-28 18:20:46,359 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:46,369 : INFO : topic #0 (0.039): 0.016*\"wand\" + 0.014*\"her\" + 0.013*\"she\" + 0.012*\"mr\" + 0.007*\"this\" + 0.006*\"hand\" + 0.006*\"looked\" + 0.006*\"one\" + 0.006*\"malfoy\" + 0.006*\"very\"\n",
            "2022-03-28 18:20:46,371 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"hand\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:46,374 : INFO : topic #4 (0.094): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.007*\"face\" + 0.007*\"eye\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:46,377 : INFO : topic #7 (0.111): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:46,383 : INFO : topic #8 (0.134): 0.014*\"hermione\" + 0.011*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"her\" + 0.009*\"we\" + 0.009*\"me\" + 0.008*\"dont\" + 0.008*\"is\"\n",
            "2022-03-28 18:20:46,386 : INFO : topic diff=0.125399, rho=0.280745\n",
            "2022-03-28 18:20:46,402 : INFO : PROGRESS: pass 9, at document #5375/5375\n",
            "2022-03-28 18:20:47,647 : INFO : optimized alpha [0.03959535, 0.08150364, 0.08932118, 0.055675298, 0.10215807, 0.043082267, 0.071096234, 0.1127756, 0.14810671, 0.045321632]\n",
            "2022-03-28 18:20:47,652 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:47,663 : INFO : topic #0 (0.040): 0.020*\"wand\" + 0.014*\"her\" + 0.012*\"she\" + 0.011*\"mr\" + 0.008*\"this\" + 0.007*\"luna\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\" + 0.006*\"is\"\n",
            "2022-03-28 18:20:47,665 : INFO : topic #5 (0.043): 0.017*\"snape\" + 0.013*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"malfoy\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:20:47,668 : INFO : topic #4 (0.102): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"face\" + 0.007*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:47,671 : INFO : topic #7 (0.113): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.012*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:47,674 : INFO : topic #8 (0.148): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.010*\"she\" + 0.009*\"we\" + 0.009*\"her\" + 0.008*\"me\" + 0.008*\"dont\" + 0.008*\"is\"\n",
            "2022-03-28 18:20:47,676 : INFO : topic diff=0.126356, rho=0.280745\n",
            "2022-03-28 18:20:47,689 : INFO : PROGRESS: pass 10, at document #2000/5375\n",
            "2022-03-28 18:20:49,656 : INFO : optimized alpha [0.039185546, 0.081692174, 0.09056233, 0.05735514, 0.09621303, 0.043492857, 0.07086292, 0.1145991, 0.13170508, 0.050678916]\n",
            "2022-03-28 18:20:49,660 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:49,671 : INFO : topic #0 (0.039): 0.018*\"wand\" + 0.013*\"her\" + 0.012*\"mr\" + 0.012*\"she\" + 0.008*\"this\" + 0.006*\"hand\" + 0.006*\"is\" + 0.006*\"one\" + 0.006*\"looked\" + 0.006*\"malfoy\"\n",
            "2022-03-28 18:20:49,674 : INFO : topic #5 (0.043): 0.016*\"snape\" + 0.013*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"malfoy\" + 0.006*\"one\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"hand\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:49,676 : INFO : topic #4 (0.096): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"eye\" + 0.007*\"face\" + 0.007*\"hand\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:49,681 : INFO : topic #7 (0.115): 0.017*\"ron\" + 0.012*\"them\" + 0.011*\"door\" + 0.011*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:49,684 : INFO : topic #8 (0.132): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.009*\"she\" + 0.009*\"we\" + 0.009*\"me\" + 0.008*\"her\" + 0.008*\"is\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:49,688 : INFO : topic diff=0.143517, rho=0.270295\n",
            "2022-03-28 18:20:49,707 : INFO : PROGRESS: pass 10, at document #4000/5375\n",
            "2022-03-28 18:20:51,780 : INFO : optimized alpha [0.039795693, 0.08289495, 0.09275617, 0.0582492, 0.09657802, 0.043718003, 0.07217168, 0.114426166, 0.13787812, 0.049574807]\n",
            "2022-03-28 18:20:51,783 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:51,797 : INFO : topic #0 (0.040): 0.016*\"wand\" + 0.015*\"her\" + 0.013*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.006*\"hand\" + 0.006*\"looked\" + 0.006*\"one\" + 0.006*\"is\" + 0.006*\"malfoy\"\n",
            "2022-03-28 18:20:51,799 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"malfoy\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:20:51,803 : INFO : topic #4 (0.097): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.007*\"eye\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:51,806 : INFO : topic #7 (0.114): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:51,808 : INFO : topic #8 (0.138): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.009*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.008*\"dont\" + 0.008*\"is\"\n",
            "2022-03-28 18:20:51,812 : INFO : topic diff=0.119853, rho=0.270295\n",
            "2022-03-28 18:20:51,826 : INFO : PROGRESS: pass 10, at document #5375/5375\n",
            "2022-03-28 18:20:53,095 : INFO : optimized alpha [0.04038952, 0.08100559, 0.08943037, 0.05755181, 0.10415194, 0.043027718, 0.073452026, 0.11596957, 0.15190619, 0.04732399]\n",
            "2022-03-28 18:20:53,104 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:53,117 : INFO : topic #0 (0.040): 0.019*\"wand\" + 0.015*\"her\" + 0.013*\"she\" + 0.010*\"mr\" + 0.008*\"this\" + 0.007*\"luna\" + 0.007*\"hand\" + 0.006*\"is\" + 0.006*\"looked\" + 0.006*\"one\"\n",
            "2022-03-28 18:20:53,119 : INFO : topic #5 (0.043): 0.017*\"snape\" + 0.013*\"moody\" + 0.007*\"eye\" + 0.007*\"into\" + 0.007*\"malfoy\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:53,122 : INFO : topic #4 (0.104): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.007*\"hand\" + 0.007*\"face\" + 0.007*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:53,125 : INFO : topic #7 (0.116): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.012*\"hermione\" + 0.011*\"into\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:53,129 : INFO : topic #8 (0.152): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.009*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.008*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:53,135 : INFO : topic diff=0.120597, rho=0.270295\n",
            "2022-03-28 18:20:53,156 : INFO : PROGRESS: pass 11, at document #2000/5375\n",
            "2022-03-28 18:20:55,157 : INFO : optimized alpha [0.04000595, 0.0811195, 0.09070206, 0.059218958, 0.09822946, 0.043466866, 0.073213376, 0.11764102, 0.1352537, 0.05282064]\n",
            "2022-03-28 18:20:55,161 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:55,180 : INFO : topic #0 (0.040): 0.017*\"wand\" + 0.014*\"her\" + 0.012*\"she\" + 0.012*\"mr\" + 0.008*\"dobby\" + 0.008*\"this\" + 0.007*\"is\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:55,182 : INFO : topic #5 (0.043): 0.016*\"snape\" + 0.013*\"moody\" + 0.007*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"one\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"hand\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:55,186 : INFO : topic #4 (0.098): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"eye\" + 0.008*\"face\" + 0.008*\"hand\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:20:55,191 : INFO : topic #7 (0.118): 0.017*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:55,199 : INFO : topic #8 (0.135): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"have\" + 0.010*\"she\" + 0.009*\"we\" + 0.009*\"me\" + 0.009*\"her\" + 0.008*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:55,202 : INFO : topic diff=0.138137, rho=0.260931\n",
            "2022-03-28 18:20:55,222 : INFO : PROGRESS: pass 11, at document #4000/5375\n",
            "2022-03-28 18:20:57,161 : INFO : optimized alpha [0.040609688, 0.08233901, 0.09283679, 0.0600983, 0.09857329, 0.043708745, 0.074467264, 0.11738091, 0.14170188, 0.05163346]\n",
            "2022-03-28 18:20:57,164 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:57,179 : INFO : topic #0 (0.041): 0.016*\"wand\" + 0.016*\"her\" + 0.013*\"she\" + 0.011*\"mr\" + 0.007*\"this\" + 0.007*\"dobby\" + 0.007*\"hand\" + 0.006*\"is\" + 0.006*\"looked\" + 0.006*\"one\"\n",
            "2022-03-28 18:20:57,182 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.015*\"moody\" + 0.007*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:20:57,185 : INFO : topic #4 (0.099): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.007*\"eye\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"death\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:57,188 : INFO : topic #7 (0.117): 0.015*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:57,191 : INFO : topic #8 (0.142): 0.014*\"hermione\" + 0.012*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.009*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.008*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:57,194 : INFO : topic diff=0.114721, rho=0.260931\n",
            "2022-03-28 18:20:57,209 : INFO : PROGRESS: pass 11, at document #5375/5375\n",
            "2022-03-28 18:20:58,441 : INFO : optimized alpha [0.041220646, 0.08062692, 0.08963043, 0.059356324, 0.106088124, 0.043050192, 0.075816594, 0.11883223, 0.15566677, 0.049258254]\n",
            "2022-03-28 18:20:58,444 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:20:58,456 : INFO : topic #0 (0.041): 0.019*\"wand\" + 0.016*\"her\" + 0.013*\"she\" + 0.010*\"mr\" + 0.008*\"this\" + 0.007*\"hand\" + 0.007*\"is\" + 0.007*\"dobby\" + 0.006*\"luna\" + 0.006*\"looked\"\n",
            "2022-03-28 18:20:58,459 : INFO : topic #5 (0.043): 0.017*\"snape\" + 0.013*\"moody\" + 0.007*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:20:58,460 : INFO : topic #4 (0.106): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.007*\"face\" + 0.007*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:20:58,463 : INFO : topic #7 (0.119): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:20:58,465 : INFO : topic #8 (0.156): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.010*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:20:58,467 : INFO : topic diff=0.115411, rho=0.260931\n",
            "2022-03-28 18:20:58,488 : INFO : PROGRESS: pass 12, at document #2000/5375\n",
            "2022-03-28 18:21:00,458 : INFO : optimized alpha [0.040884856, 0.08074523, 0.09075924, 0.061032422, 0.10016887, 0.04352884, 0.07545019, 0.12026848, 0.1387854, 0.054844853]\n",
            "2022-03-28 18:21:00,461 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:00,473 : INFO : topic #0 (0.041): 0.017*\"wand\" + 0.015*\"her\" + 0.013*\"she\" + 0.011*\"mr\" + 0.010*\"dobby\" + 0.008*\"this\" + 0.007*\"is\" + 0.006*\"hand\" + 0.006*\"one\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:00,476 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.008*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"hand\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:00,478 : INFO : topic #4 (0.100): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"eye\" + 0.008*\"face\" + 0.008*\"hand\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:21:00,486 : INFO : topic #7 (0.120): 0.016*\"ron\" + 0.012*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:00,492 : INFO : topic #8 (0.139): 0.014*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.010*\"we\" + 0.009*\"me\" + 0.009*\"her\" + 0.008*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:00,499 : INFO : topic diff=0.133096, rho=0.252478\n",
            "2022-03-28 18:21:00,514 : INFO : PROGRESS: pass 12, at document #4000/5375\n",
            "2022-03-28 18:21:02,398 : INFO : optimized alpha [0.041458987, 0.081930675, 0.092854746, 0.061952442, 0.10048947, 0.043803375, 0.07665353, 0.12000073, 0.14522173, 0.053568583]\n",
            "2022-03-28 18:21:02,402 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:02,417 : INFO : topic #0 (0.041): 0.016*\"her\" + 0.016*\"wand\" + 0.014*\"she\" + 0.011*\"mr\" + 0.009*\"dobby\" + 0.007*\"this\" + 0.007*\"is\" + 0.007*\"hand\" + 0.006*\"looked\" + 0.006*\"one\"\n",
            "2022-03-28 18:21:02,419 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.015*\"moody\" + 0.008*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:02,422 : INFO : topic #4 (0.100): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"there\" + 0.006*\"death\" + 0.006*\"back\" + 0.006*\"then\"\n",
            "2022-03-28 18:21:02,424 : INFO : topic #7 (0.120): 0.015*\"ron\" + 0.012*\"door\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:02,426 : INFO : topic #8 (0.145): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.009*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:02,430 : INFO : topic diff=0.109981, rho=0.252478\n",
            "2022-03-28 18:21:02,453 : INFO : PROGRESS: pass 12, at document #5375/5375\n",
            "2022-03-28 18:21:03,640 : INFO : optimized alpha [0.042110834, 0.080439515, 0.08979405, 0.06114858, 0.1079124, 0.043127708, 0.07799663, 0.12121791, 0.15905531, 0.051078137]\n",
            "2022-03-28 18:21:03,642 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:03,658 : INFO : topic #0 (0.042): 0.019*\"wand\" + 0.016*\"her\" + 0.014*\"she\" + 0.010*\"mr\" + 0.008*\"dobby\" + 0.007*\"this\" + 0.007*\"is\" + 0.007*\"hand\" + 0.006*\"looked\" + 0.006*\"one\"\n",
            "2022-03-28 18:21:03,661 : INFO : topic #5 (0.043): 0.017*\"snape\" + 0.014*\"moody\" + 0.008*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:21:03,664 : INFO : topic #4 (0.108): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.007*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:03,667 : INFO : topic #7 (0.121): 0.015*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:03,672 : INFO : topic #8 (0.159): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.010*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:03,677 : INFO : topic diff=0.110621, rho=0.252478\n",
            "2022-03-28 18:21:03,697 : INFO : PROGRESS: pass 13, at document #2000/5375\n",
            "2022-03-28 18:21:05,678 : INFO : optimized alpha [0.041779358, 0.08060924, 0.09091545, 0.0627894, 0.1020131, 0.043620095, 0.077581055, 0.1225912, 0.14213227, 0.056719135]\n",
            "2022-03-28 18:21:05,682 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:05,695 : INFO : topic #0 (0.042): 0.017*\"wand\" + 0.015*\"her\" + 0.013*\"she\" + 0.012*\"dobby\" + 0.011*\"mr\" + 0.008*\"is\" + 0.008*\"this\" + 0.007*\"elf\" + 0.007*\"hand\" + 0.006*\"one\"\n",
            "2022-03-28 18:21:05,700 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.009*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"hand\" + 0.006*\"off\"\n",
            "2022-03-28 18:21:05,703 : INFO : topic #4 (0.102): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"eye\" + 0.008*\"face\" + 0.008*\"hand\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:21:05,707 : INFO : topic #7 (0.123): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:05,714 : INFO : topic #8 (0.142): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.010*\"she\" + 0.010*\"have\" + 0.010*\"we\" + 0.009*\"me\" + 0.009*\"her\" + 0.008*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:05,717 : INFO : topic diff=0.128324, rho=0.244796\n",
            "2022-03-28 18:21:05,734 : INFO : PROGRESS: pass 13, at document #4000/5375\n",
            "2022-03-28 18:21:07,559 : INFO : optimized alpha [0.042398483, 0.081754155, 0.09301275, 0.06369643, 0.10231167, 0.04389431, 0.07869926, 0.12203966, 0.14838105, 0.055332057]\n",
            "2022-03-28 18:21:07,562 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:07,572 : INFO : topic #0 (0.042): 0.017*\"her\" + 0.016*\"wand\" + 0.014*\"she\" + 0.010*\"dobby\" + 0.010*\"mr\" + 0.007*\"is\" + 0.007*\"this\" + 0.007*\"elf\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:07,575 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.015*\"moody\" + 0.009*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:07,578 : INFO : topic #4 (0.102): 0.012*\"wand\" + 0.008*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"there\" + 0.007*\"death\" + 0.006*\"back\" + 0.006*\"then\"\n",
            "2022-03-28 18:21:07,580 : INFO : topic #7 (0.122): 0.015*\"ron\" + 0.013*\"door\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"around\" + 0.008*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:07,583 : INFO : topic #8 (0.148): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"have\" + 0.010*\"we\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:07,585 : INFO : topic diff=0.105644, rho=0.244796\n",
            "2022-03-28 18:21:07,597 : INFO : PROGRESS: pass 13, at document #5375/5375\n",
            "2022-03-28 18:21:08,829 : INFO : optimized alpha [0.0430217, 0.08029308, 0.08998765, 0.06286262, 0.10955669, 0.043267835, 0.080093235, 0.123155124, 0.16206281, 0.052741818]\n",
            "2022-03-28 18:21:08,832 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:08,842 : INFO : topic #0 (0.043): 0.019*\"wand\" + 0.016*\"her\" + 0.014*\"she\" + 0.009*\"dobby\" + 0.009*\"mr\" + 0.008*\"is\" + 0.007*\"this\" + 0.007*\"elf\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:08,847 : INFO : topic #5 (0.043): 0.016*\"snape\" + 0.014*\"moody\" + 0.009*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"now\"\n",
            "2022-03-28 18:21:08,849 : INFO : topic #4 (0.110): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:08,852 : INFO : topic #7 (0.123): 0.015*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:08,854 : INFO : topic #8 (0.162): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:08,856 : INFO : topic diff=0.106401, rho=0.244796\n",
            "2022-03-28 18:21:08,869 : INFO : PROGRESS: pass 14, at document #2000/5375\n",
            "2022-03-28 18:21:10,744 : INFO : optimized alpha [0.042706724, 0.080459826, 0.09109464, 0.0644827, 0.10367012, 0.04377502, 0.079609044, 0.12448846, 0.14492592, 0.058448]\n",
            "2022-03-28 18:21:10,747 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:10,759 : INFO : topic #0 (0.043): 0.017*\"wand\" + 0.016*\"her\" + 0.013*\"she\" + 0.013*\"dobby\" + 0.010*\"mr\" + 0.008*\"is\" + 0.008*\"elf\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"one\"\n",
            "2022-03-28 18:21:10,762 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.010*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"one\" + 0.006*\"potter\" + 0.006*\"off\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:10,764 : INFO : topic #4 (0.104): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"eye\" + 0.008*\"hand\" + 0.008*\"face\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:21:10,767 : INFO : topic #7 (0.124): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:10,772 : INFO : topic #8 (0.145): 0.015*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:10,779 : INFO : topic diff=0.123811, rho=0.237775\n",
            "2022-03-28 18:21:10,798 : INFO : PROGRESS: pass 14, at document #4000/5375\n",
            "2022-03-28 18:21:12,702 : INFO : optimized alpha [0.043310955, 0.081574835, 0.09317221, 0.06535957, 0.10391486, 0.04409294, 0.08072396, 0.123969235, 0.15128407, 0.056986883]\n",
            "2022-03-28 18:21:12,704 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:12,723 : INFO : topic #0 (0.043): 0.017*\"her\" + 0.016*\"wand\" + 0.014*\"she\" + 0.011*\"dobby\" + 0.010*\"mr\" + 0.008*\"is\" + 0.008*\"elf\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:12,725 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.015*\"moody\" + 0.010*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:12,734 : INFO : topic #4 (0.104): 0.012*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"there\" + 0.007*\"death\" + 0.007*\"back\" + 0.006*\"then\"\n",
            "2022-03-28 18:21:12,737 : INFO : topic #7 (0.124): 0.015*\"ron\" + 0.013*\"door\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"around\" + 0.008*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:12,741 : INFO : topic #8 (0.151): 0.015*\"hermione\" + 0.013*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.010*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:12,745 : INFO : topic diff=0.101508, rho=0.237775\n",
            "2022-03-28 18:21:12,763 : INFO : PROGRESS: pass 14, at document #5375/5375\n",
            "2022-03-28 18:21:13,971 : INFO : optimized alpha [0.043955375, 0.08019999, 0.09015734, 0.06444948, 0.11106135, 0.04348107, 0.08214102, 0.12510407, 0.16469929, 0.05429721]\n",
            "2022-03-28 18:21:13,976 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:13,988 : INFO : topic #5 (0.043): 0.016*\"snape\" + 0.014*\"moody\" + 0.010*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:13,991 : INFO : topic #0 (0.044): 0.018*\"wand\" + 0.017*\"her\" + 0.014*\"she\" + 0.010*\"dobby\" + 0.009*\"mr\" + 0.008*\"is\" + 0.008*\"elf\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:13,994 : INFO : topic #4 (0.111): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:13,997 : INFO : topic #7 (0.125): 0.015*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.012*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:14,008 : INFO : topic #8 (0.165): 0.015*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.010*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:14,010 : INFO : topic diff=0.102474, rho=0.237775\n",
            "2022-03-28 18:21:14,027 : INFO : PROGRESS: pass 15, at document #2000/5375\n",
            "2022-03-28 18:21:15,999 : INFO : optimized alpha [0.043611214, 0.08028274, 0.09121605, 0.0661162, 0.10527085, 0.04398834, 0.08159117, 0.12637605, 0.14760889, 0.060011417]\n",
            "2022-03-28 18:21:16,002 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:16,020 : INFO : topic #0 (0.044): 0.017*\"wand\" + 0.016*\"her\" + 0.014*\"she\" + 0.013*\"dobby\" + 0.010*\"mr\" + 0.009*\"is\" + 0.009*\"elf\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"potter\"\n",
            "2022-03-28 18:21:16,022 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.011*\"malfoy\" + 0.007*\"into\" + 0.007*\"eye\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"off\" + 0.006*\"broom\"\n",
            "2022-03-28 18:21:16,028 : INFO : topic #4 (0.105): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"eye\" + 0.008*\"face\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:21:16,034 : INFO : topic #7 (0.126): 0.016*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.007*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:16,035 : INFO : topic #8 (0.148): 0.015*\"hermione\" + 0.014*\"ron\" + 0.012*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:16,038 : INFO : topic diff=0.119479, rho=0.231326\n",
            "2022-03-28 18:21:16,055 : INFO : PROGRESS: pass 15, at document #4000/5375\n",
            "2022-03-28 18:21:17,942 : INFO : optimized alpha [0.04419968, 0.0813073, 0.093221, 0.06695248, 0.105464235, 0.044304002, 0.08264527, 0.12574756, 0.15387447, 0.058471784]\n",
            "2022-03-28 18:21:17,947 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:17,957 : INFO : topic #0 (0.044): 0.017*\"her\" + 0.015*\"wand\" + 0.015*\"she\" + 0.012*\"dobby\" + 0.009*\"mr\" + 0.008*\"elf\" + 0.008*\"is\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:17,960 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.015*\"moody\" + 0.011*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"hand\"\n",
            "2022-03-28 18:21:17,963 : INFO : topic #4 (0.105): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"there\" + 0.007*\"death\" + 0.007*\"back\" + 0.006*\"then\"\n",
            "2022-03-28 18:21:17,966 : INFO : topic #7 (0.126): 0.014*\"ron\" + 0.013*\"door\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"around\" + 0.008*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:17,968 : INFO : topic #8 (0.154): 0.015*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"her\" + 0.010*\"have\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:17,970 : INFO : topic diff=0.097656, rho=0.231326\n",
            "2022-03-28 18:21:17,984 : INFO : PROGRESS: pass 15, at document #5375/5375\n",
            "2022-03-28 18:21:19,152 : INFO : optimized alpha [0.04486552, 0.08002123, 0.09031803, 0.066007145, 0.112478696, 0.043727934, 0.08402401, 0.1268292, 0.16707133, 0.05571022]\n",
            "2022-03-28 18:21:19,155 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:19,165 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.012*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"her\"\n",
            "2022-03-28 18:21:19,168 : INFO : topic #0 (0.045): 0.018*\"wand\" + 0.017*\"her\" + 0.014*\"she\" + 0.011*\"dobby\" + 0.009*\"mr\" + 0.009*\"elf\" + 0.008*\"is\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:19,170 : INFO : topic #4 (0.112): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:19,172 : INFO : topic #7 (0.127): 0.015*\"ron\" + 0.013*\"them\" + 0.013*\"door\" + 0.012*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.007*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:19,175 : INFO : topic #8 (0.167): 0.016*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.010*\"her\" + 0.009*\"dont\" + 0.009*\"me\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:19,176 : INFO : topic diff=0.098888, rho=0.231326\n",
            "2022-03-28 18:21:19,190 : INFO : PROGRESS: pass 16, at document #2000/5375\n",
            "2022-03-28 18:21:21,087 : INFO : optimized alpha [0.044518843, 0.08014138, 0.09137923, 0.06762728, 0.10665975, 0.04423885, 0.08344379, 0.12809765, 0.14980868, 0.061473735]\n",
            "2022-03-28 18:21:21,090 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:21,099 : INFO : topic #5 (0.044): 0.015*\"snape\" + 0.014*\"moody\" + 0.013*\"malfoy\" + 0.007*\"into\" + 0.007*\"eye\" + 0.006*\"potter\" + 0.006*\"around\" + 0.006*\"off\" + 0.006*\"one\" + 0.006*\"broom\"\n",
            "2022-03-28 18:21:21,103 : INFO : topic #0 (0.045): 0.017*\"wand\" + 0.016*\"her\" + 0.014*\"she\" + 0.014*\"dobby\" + 0.010*\"mr\" + 0.009*\"elf\" + 0.009*\"is\" + 0.007*\"this\" + 0.007*\"hand\" + 0.007*\"potter\"\n",
            "2022-03-28 18:21:21,106 : INFO : topic #4 (0.107): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"eye\" + 0.008*\"face\" + 0.007*\"there\" + 0.007*\"then\" + 0.006*\"back\" + 0.006*\"death\"\n",
            "2022-03-28 18:21:21,109 : INFO : topic #7 (0.128): 0.015*\"ron\" + 0.013*\"them\" + 0.012*\"door\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"back\" + 0.008*\"around\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:21,111 : INFO : topic #8 (0.150): 0.015*\"hermione\" + 0.014*\"ron\" + 0.012*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"have\" + 0.009*\"her\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:21,113 : INFO : topic diff=0.115521, rho=0.225374\n",
            "2022-03-28 18:21:21,127 : INFO : PROGRESS: pass 16, at document #4000/5375\n",
            "2022-03-28 18:21:23,008 : INFO : optimized alpha [0.045093015, 0.0811331, 0.093392886, 0.06845963, 0.10687546, 0.044551898, 0.0843847, 0.12737451, 0.1562336, 0.059933394]\n",
            "2022-03-28 18:21:23,010 : INFO : merging changes from 2000 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:23,027 : INFO : topic #5 (0.045): 0.015*\"snape\" + 0.015*\"moody\" + 0.013*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"off\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:23,030 : INFO : topic #0 (0.045): 0.018*\"her\" + 0.015*\"wand\" + 0.015*\"she\" + 0.012*\"dobby\" + 0.009*\"mr\" + 0.009*\"elf\" + 0.009*\"is\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"potter\"\n",
            "2022-03-28 18:21:23,035 : INFO : topic #4 (0.107): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"hand\" + 0.008*\"into\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"there\" + 0.007*\"death\" + 0.007*\"back\" + 0.007*\"then\"\n",
            "2022-03-28 18:21:23,038 : INFO : topic #7 (0.127): 0.014*\"ron\" + 0.013*\"door\" + 0.012*\"them\" + 0.011*\"into\" + 0.010*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"around\" + 0.008*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:23,041 : INFO : topic #8 (0.156): 0.015*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"her\" + 0.010*\"have\" + 0.009*\"me\" + 0.009*\"dont\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:23,043 : INFO : topic diff=0.093971, rho=0.225374\n",
            "2022-03-28 18:21:23,057 : INFO : PROGRESS: pass 16, at document #5375/5375\n",
            "2022-03-28 18:21:24,250 : INFO : optimized alpha [0.045739, 0.07992307, 0.09056141, 0.06752543, 0.11379007, 0.043959484, 0.085799575, 0.1283994, 0.16923052, 0.057101246]\n",
            "2022-03-28 18:21:24,252 : INFO : merging changes from 1375 documents into a model of 5375 documents\n",
            "2022-03-28 18:21:24,268 : INFO : topic #5 (0.044): 0.016*\"snape\" + 0.014*\"moody\" + 0.013*\"malfoy\" + 0.007*\"eye\" + 0.007*\"into\" + 0.006*\"around\" + 0.006*\"potter\" + 0.006*\"one\" + 0.006*\"off\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:24,272 : INFO : topic #0 (0.046): 0.018*\"wand\" + 0.017*\"her\" + 0.015*\"she\" + 0.011*\"dobby\" + 0.009*\"elf\" + 0.009*\"is\" + 0.009*\"mr\" + 0.007*\"this\" + 0.007*\"hand\" + 0.006*\"looked\"\n",
            "2022-03-28 18:21:24,275 : INFO : topic #4 (0.114): 0.013*\"wand\" + 0.009*\"could\" + 0.008*\"into\" + 0.008*\"hand\" + 0.008*\"face\" + 0.008*\"eye\" + 0.007*\"death\" + 0.007*\"there\" + 0.006*\"then\" + 0.006*\"back\"\n",
            "2022-03-28 18:21:24,278 : INFO : topic #7 (0.128): 0.014*\"ron\" + 0.013*\"them\" + 0.013*\"door\" + 0.012*\"into\" + 0.011*\"hermione\" + 0.008*\"their\" + 0.008*\"there\" + 0.008*\"around\" + 0.007*\"back\" + 0.007*\"through\"\n",
            "2022-03-28 18:21:24,279 : INFO : topic #8 (0.169): 0.016*\"hermione\" + 0.014*\"ron\" + 0.011*\"know\" + 0.011*\"she\" + 0.010*\"we\" + 0.010*\"her\" + 0.010*\"have\" + 0.009*\"dont\" + 0.009*\"me\" + 0.008*\"if\"\n",
            "2022-03-28 18:21:24,282 : INFO : topic diff=0.095683, rho=0.225374\n",
            "2022-03-28 18:21:24,300 : INFO : PROGRESS: pass 17, at document #2000/5375\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 2m01s @20220328 with Google Colab/CPU on Harry Potter\n",
        "\n",
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = No_of_Topics\n",
        "chunksize = 2000\n",
        "passes = 20\n",
        "iterations = 400\n",
        "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make a index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "    eval_every=eval_every\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4IDUbAygft9"
      },
      "source": [
        "We can compute the topic coherence of each topic. Below we display the\n",
        "average topic coherence and print the topics in order of topic coherence.\n",
        "\n",
        "Note that we use the \"Umass\" topic coherence measure here (see\n",
        ":py:func:`gensim.models.ldamodel.LdaModel.top_topics`), Gensim has recently\n",
        "obtained an implementation of the \"AKSW\" topic coherence measure (see\n",
        "accompanying blog post, http://rare-technologies.com/what-is-topic-coherence/).\n",
        "\n",
        "If you are familiar with the subject of the articles in this dataset, you can\n",
        "see that the topics below make a lot of sense. However, they are not without\n",
        "flaws. We can see that there is substantial overlap between some topics,\n",
        "others are hard to interpret, and most of them have at least some terms that\n",
        "seem out of place. If you were able to do better, feel free to share your\n",
        "methods on the blog at http://rare-technologies.com/lda-training-tips/ !\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa3_6XDbgft-",
        "outputId": "b0cf5750-65ae-4118-d4d3-15d9411ecdf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-28 17:56:42,676 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
            "2022-03-28 17:56:42,722 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
            "2022-03-28 17:56:42,773 : INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
            "2022-03-28 17:56:42,823 : INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
            "2022-03-28 17:56:42,878 : INFO : CorpusAccumulator accumulated stats from 5000 documents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[([(0.029319314, 'ron'),\n",
            "   (0.029076837, 'she'),\n",
            "   (0.023293182, 'her'),\n",
            "   (0.021932947, 'hermione'),\n",
            "   (0.010585379, 'do'),\n",
            "   (0.007714369, 'are'),\n",
            "   (0.0073170606, 'did'),\n",
            "   (0.007317019, 'got'),\n",
            "   (0.007127823, 'do_not'),\n",
            "   (0.006803478, 'back'),\n",
            "   (0.0067026764, 'just'),\n",
            "   (0.0066377646, 'well'),\n",
            "   (0.0063258954, 'know'),\n",
            "   (0.005776355, 'about'),\n",
            "   (0.0054152827, 'me'),\n",
            "   (0.0053171036, 'would'),\n",
            "   (0.0052627763, 'will'),\n",
            "   (0.0051741274, 'we'),\n",
            "   (0.005088116, 'looking'),\n",
            "   (0.005057784, 'them')],\n",
            "  -0.9431404662814848),\n",
            " ([(0.015426293, 'do'),\n",
            "   (0.013684746, 'we'),\n",
            "   (0.012124019, 'would'),\n",
            "   (0.0112393955, 'are'),\n",
            "   (0.010038636, 'know'),\n",
            "   (0.009065553, 'if'),\n",
            "   (0.009002145, 'did'),\n",
            "   (0.008753977, 'me'),\n",
            "   (0.008684587, 'ron'),\n",
            "   (0.008467633, 'hermione'),\n",
            "   (0.007663319, 'will'),\n",
            "   (0.007631141, 'snape'),\n",
            "   (0.007528578, 'do_not'),\n",
            "   (0.0074608214, 'think'),\n",
            "   (0.0073579396, 'about'),\n",
            "   (0.0072945524, 'so'),\n",
            "   (0.0072705885, 'this'),\n",
            "   (0.0070826374, 'dumbledore'),\n",
            "   (0.006752053, 'there'),\n",
            "   (0.0067416145, 'been')],\n",
            "  -0.9931401643665112),\n",
            " ([(0.018024353, 'dumbledore'),\n",
            "   (0.0155731365, 'voldemort'),\n",
            "   (0.01150295, 'my'),\n",
            "   (0.0089000845, 'been'),\n",
            "   (0.0077890777, 'who'),\n",
            "   (0.007722775, 'wand'),\n",
            "   (0.007090113, 'could'),\n",
            "   (0.0070343767, 'death'),\n",
            "   (0.007031535, 'did'),\n",
            "   (0.006814253, 'would'),\n",
            "   (0.006716786, 'me'),\n",
            "   (0.006401371, 'lord'),\n",
            "   (0.0059824283, 'so'),\n",
            "   (0.0054031196, 'your'),\n",
            "   (0.0053645903, 'no'),\n",
            "   (0.0053253025, 'there'),\n",
            "   (0.005289459, 'more'),\n",
            "   (0.0051654233, 'now'),\n",
            "   (0.005121658, 'this'),\n",
            "   (0.0047035967, 'wizard')],\n",
            "  -1.1898371711655398),\n",
            " ([(0.013905523, 'wand'),\n",
            "   (0.008715568, 'ron'),\n",
            "   (0.00817466, 'them'),\n",
            "   (0.008087074, 'into'),\n",
            "   (0.0079659745, 'her'),\n",
            "   (0.007888335, 'hand'),\n",
            "   (0.007847361, 'face'),\n",
            "   (0.0075439727, 'malfoy'),\n",
            "   (0.0073280716, 'over'),\n",
            "   (0.006903677, 'could'),\n",
            "   (0.0064250897, 'back'),\n",
            "   (0.0062303087, 'around'),\n",
            "   (0.0060489555, 'then'),\n",
            "   (0.0058540455, 'there'),\n",
            "   (0.005696508, 'foot'),\n",
            "   (0.005392434, 'hermione'),\n",
            "   (0.0053668898, 'death'),\n",
            "   (0.005362678, 'eye'),\n",
            "   (0.005153721, 'no'),\n",
            "   (0.005076569, 'saw')],\n",
            "  -1.2449641998091068),\n",
            " ([(0.029079055, 'her'),\n",
            "   (0.024191901, 'she'),\n",
            "   (0.007952388, 'hermione'),\n",
            "   (0.0071981912, 'umbridge'),\n",
            "   (0.006598947, 'professor'),\n",
            "   (0.006281696, 'who'),\n",
            "   (0.006023377, 'looked'),\n",
            "   (0.005916796, 'ron'),\n",
            "   (0.005892466, 'them'),\n",
            "   (0.0057855854, 'been'),\n",
            "   (0.0050580753, 'by'),\n",
            "   (0.0049419366, 'an'),\n",
            "   (0.0049060667, 'their'),\n",
            "   (0.004466611, 'there'),\n",
            "   (0.0044169994, 'very'),\n",
            "   (0.0041764285, 'look'),\n",
            "   (0.004154701, 'so'),\n",
            "   (0.0040587205, 'when'),\n",
            "   (0.004002413, 'luna'),\n",
            "   (0.0039027028, 'around')],\n",
            "  -1.248021432745238),\n",
            " ([(0.011597253, 'door'),\n",
            "   (0.010262094, 'into'),\n",
            "   (0.0098502515, 'them'),\n",
            "   (0.007978204, 'there'),\n",
            "   (0.0072818073, 'through'),\n",
            "   (0.0071710483, 'their'),\n",
            "   (0.007101719, 'back'),\n",
            "   (0.0065958397, 'could'),\n",
            "   (0.006579425, 'around'),\n",
            "   (0.006536227, 'ron'),\n",
            "   (0.0061440426, 'down'),\n",
            "   (0.0058435854, 'hermione'),\n",
            "   (0.0054816455, 'then'),\n",
            "   (0.0054235253, 'room'),\n",
            "   (0.0053467676, 'cloak'),\n",
            "   (0.0053152516, 'over'),\n",
            "   (0.005135002, 'where'),\n",
            "   (0.004569933, 'behind'),\n",
            "   (0.004250365, 'which'),\n",
            "   (0.0041312655, 'off')],\n",
            "  -1.2590665107109975),\n",
            " ([(0.025335826, 'mr'),\n",
            "   (0.024298105, 'weasley'),\n",
            "   (0.019724922, 'mr_weasley'),\n",
            "   (0.013221298, 'fred'),\n",
            "   (0.011600751, 'george'),\n",
            "   (0.008357617, 'uncle'),\n",
            "   (0.0073798867, 'vernon'),\n",
            "   (0.0064633796, 'uncle_vernon'),\n",
            "   (0.0062150625, 'dudley'),\n",
            "   (0.0052438513, 'aunt'),\n",
            "   (0.0048578954, 'petunia'),\n",
            "   (0.004708576, 'would'),\n",
            "   (0.0045709764, 'into'),\n",
            "   (0.0045294613, 'are'),\n",
            "   (0.00447316, 'back'),\n",
            "   (0.004294935, 'their'),\n",
            "   (0.0042693783, 'them'),\n",
            "   (0.004226851, 'who'),\n",
            "   (0.0041946988, 'we'),\n",
            "   (0.0041596508, 'percy')],\n",
            "  -1.5081829746285706),\n",
            " ([(0.034628127, 'hagrid'),\n",
            "   (0.019549878, 'professor'),\n",
            "   (0.013035975, 'mcgonagall'),\n",
            "   (0.012224701, 'them'),\n",
            "   (0.011391621, 'professor_mcgonagall'),\n",
            "   (0.01119782, 'an'),\n",
            "   (0.007322374, 'yeh'),\n",
            "   (0.0067604734, 'their'),\n",
            "   (0.0066727204, 'ter'),\n",
            "   (0.0052197934, 'who'),\n",
            "   (0.0050774002, 'one'),\n",
            "   (0.0048201266, 'would'),\n",
            "   (0.0045606117, 'we'),\n",
            "   (0.0045430427, 'goblin'),\n",
            "   (0.0044910987, 'there'),\n",
            "   (0.004455828, 'by'),\n",
            "   (0.0042246217, 'now'),\n",
            "   (0.0041965772, 'student'),\n",
            "   (0.004141242, 'hall'),\n",
            "   (0.0041401903, 'back')],\n",
            "  -1.5827150220615527),\n",
            " ([(0.015980778, 'dumbledore'),\n",
            "   (0.010747262, 'dobby'),\n",
            "   (0.010582367, 'eye'),\n",
            "   (0.010529386, 'elf'),\n",
            "   (0.0100147985, 'kreacher'),\n",
            "   (0.009715163, 'moody'),\n",
            "   (0.008850333, 'into'),\n",
            "   (0.0076478967, 'potter'),\n",
            "   (0.006552377, 'sir'),\n",
            "   (0.0058895764, 'snape'),\n",
            "   (0.0057745515, 'house'),\n",
            "   (0.0055356463, 'then'),\n",
            "   (0.005458218, 'hand'),\n",
            "   (0.005368924, 'upon'),\n",
            "   (0.0052144337, 'looked'),\n",
            "   (0.005212969, 'back'),\n",
            "   (0.0050935317, 'head'),\n",
            "   (0.0050385823, 'there'),\n",
            "   (0.0049636704, 'water'),\n",
            "   (0.004819086, 'down')],\n",
            "  -1.6426143638911568),\n",
            " ([(0.014291273, 'slughorn'),\n",
            "   (0.00969431, 'potion'),\n",
            "   (0.0070719137, 'into'),\n",
            "   (0.0070282565, 'professor'),\n",
            "   (0.0065266476, 'trelawney'),\n",
            "   (0.0061192615, 'her'),\n",
            "   (0.0059312624, 'this'),\n",
            "   (0.005700934, 'professor_trelawney'),\n",
            "   (0.005642913, 'an'),\n",
            "   (0.005542596, 'your'),\n",
            "   (0.005083736, 'she'),\n",
            "   (0.0050822063, 'will'),\n",
            "   (0.005042084, 'mundungus'),\n",
            "   (0.00470682, 'bottle'),\n",
            "   (0.0046315677, 'one'),\n",
            "   (0.0045707934, 'rita'),\n",
            "   (0.0045461343, 'very'),\n",
            "   (0.004410345, 'eye'),\n",
            "   (0.004248915, 'there'),\n",
            "   (0.004183156, 'by')],\n",
            "  -2.181746053809485)]\n",
            "\n",
            "\n",
            "\n",
            "Topic #0: coherence = -0.9431404662814848\n",
            "Topic #1: coherence = -0.9931401643665112\n",
            "Topic #2: coherence = -1.1898371711655398\n",
            "Topic #3: coherence = -1.2449641998091068\n",
            "Topic #4: coherence = -1.248021432745238\n",
            "Topic #5: coherence = -1.2590665107109975\n",
            "Topic #6: coherence = -1.5081829746285706\n",
            "Topic #7: coherence = -1.5827150220615527\n",
            "Topic #8: coherence = -1.6426143638911568\n",
            "Topic #9: coherence = -2.181746053809485\n",
            "\n",
            "Average topic coherence: -1.3793.\n"
          ]
        }
      ],
      "source": [
        "top_topics = model.top_topics(corpus) #, num_words=20)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)\n",
        "\n",
        "print('\\n\\n')\n",
        "for i,atopic in enumerate(top_topics):\n",
        "  print(f'Topic #{i}: coherence = {atopic[1]}')\n",
        "\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('\\nAverage topic coherence: %.4f.' % avg_topic_coherence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "1TXD97_dQTnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis"
      ],
      "metadata": {
        "id": "GHAcDkpbQdJ1"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vis_data = gensimvis.prepare(lda, corpus, dictionary)\n",
        "vis_data = gensimvis.prepare(model, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "GgLhaMRiQdIH",
        "outputId": "521c9e16-a3f1-481f-f6c6-244c6a082bd0"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el631400897199002407734849199\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el631400897199002407734849199_data = {\"mdsDat\": {\"x\": [-0.11394594545834122, -0.07569014880983244, 0.1261731614104477, -0.01057959192677015, 0.15405494992301164, -0.037780140793276996, -0.05694704295176895, -0.05105611951706053, 0.08752630012650663, -0.021755422002915473], \"y\": [-0.04435513214205181, 0.06146792948736304, 0.0505796961139499, 0.06432572693897327, -0.027551390726470573, 0.08965291145451261, -0.1609012474624741, 0.061552779888156016, -0.05996699455575368, -0.034804278996204877], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [21.92339290892709, 14.362606774187888, 13.16927880104336, 9.269134341657544, 9.242214770475034, 8.396107425924694, 8.24952063663608, 7.058702666636943, 4.473841662509092, 3.8552000120022747]}, \"tinfo\": {\"Term\": [\"hagrid\", \"she\", \"her\", \"weasley\", \"dumbledore\", \"mr\", \"mr_weasley\", \"professor\", \"voldemort\", \"ron\", \"fred\", \"mcgonagall\", \"wand\", \"george\", \"hermione\", \"professor_mcgonagall\", \"snape\", \"slughorn\", \"door\", \"uncle\", \"into\", \"my\", \"death\", \"eye\", \"vernon\", \"umbridge\", \"elf\", \"dobby\", \"potion\", \"moody\", \"elder\", \"cave\", \"grindelwald\", \"fragment\", \"bagshot\", \"occlumency\", \"marquee\", \"stooped\", \"companion\", \"instance\", \"personally\", \"imperius_curse\", \"for_instance\", \"apparate\", \"snakelike\", \"lookout\", \"imperius\", \"mission\", \"summon\", \"remorse\", \"peverell\", \"exchange\", \"magical_law\", \"torture\", \"transform\", \"cruciatus\", \"cruciatus_curse\", \"spite\", \"whereabouts\", \"priority\", \"squad\", \"deny\", \"what_dyou\", \"snape\", \"sirius\", \"scrimgeour\", \"steal\", \"lupin\", \"we\", \"severus\", \"think\", \"james\", \"doe_not\", \"do\", \"u\", \"know\", \"if\", \"do_not\", \"would\", \"doe\", \"are\", \"can\", \"me\", \"mean\", \"why\", \"cannot\", \"about\", \"will\", \"want\", \"how\", \"well\", \"did\", \"am\", \"because\", \"your\", \"dumbledore\", \"so\", \"this\", \"did_not\", \"been\", \"hermione\", \"ron\", \"there\", \"could\", \"who\", \"them\", \"no\", \"crouch\", \"mr_crouch\", \"pomfrey\", \"madam_pomfrey\", \"narcissa\", \"borgin\", \"burke\", \"barty\", \"her_husband\", \"mr_diggory\", \"wow\", \"barty_crouch\", \"stowed\", \"bertha_jorkins\", \"jorkins\", \"unexpectedly\", \"similar\", \"bidding\", \"chocolate_frog\", \"freak\", \"owlery\", \"grimy\", \"heaven_sake\", \"zat\", \"joke_shop\", \"sympathy\", \"st_mungos\", \"firstly\", \"pineapple\", \"succeeded\", \"shakily\", \"hospital_wing\", \"mungos\", \"zabini\", \"hospital\", \"married\", \"she\", \"chocolate\", \"krum\", \"ron\", \"bagman\", \"her\", \"hermione\", \"common_room\", \"madam\", \"cedric\", \"diggory\", \"owl\", \"yeah\", \"ginny\", \"common\", \"got\", \"oh\", \"do_not\", \"well\", \"just\", \"do\", \"bed\", \"looking\", \"asked\", \"are\", \"know\", \"am\", \"go\", \"did\", \"back\", \"about\", \"look\", \"think\", \"me\", \"will\", \"did_not\", \"going\", \"right\", \"looked\", \"we\", \"would\", \"this\", \"them\", \"if\", \"who\", \"no\", \"been\", \"aberforth\", \"stone_step\", \"spiral_staircase\", \"lane\", \"creaked\", \"eyelid\", \"spiral\", \"pavement\", \"hallway\", \"cubicle\", \"bode\", \"blackness\", \"swung_open\", \"atrium\", \"grille\", \"mound\", \"creaking\", \"dot\", \"wandlight\", \"crown\", \"runcorn\", \"lumos\", \"knocker\", \"sprawled\", \"worker\", \"registered\", \"gabrielle\", \"ajar\", \"winding\", \"fragile\", \"nick\", \"bunk\", \"front_door\", \"baron\", \"bus\", \"passage\", \"invisibility_cloak\", \"invisibility\", \"stag\", \"road\", \"cloak\", \"circular\", \"door\", \"nearly_headless\", \"iron\", \"lift\", \"headless\", \"deserted\", \"staircase\", \"lamp\", \"street\", \"climbed\", \"window\", \"corridor\", \"gate\", \"step\", \"tree\", \"darkness\", \"stair\", \"wall\", \"reached\", \"through\", \"entrance\", \"open\", \"stone\", \"along\", \"into\", \"room\", \"stood\", \"behind\", \"light\", \"front\", \"toward\", \"around\", \"where\", \"their\", \"them\", \"down\", \"there\", \"back\", \"inside\", \"could\", \"over\", \"then\", \"which\", \"here\", \"ron\", \"hermione\", \"off\", \"by\", \"see\", \"looked\", \"one\", \"prime_minister\", \"prime\", \"professor_umbridge\", \"fleurs\", \"auntie_muriel\", \"headquarters\", \"seeking\", \"river\", \"clipboard\", \"tomb\", \"freds\", \"puffy\", \"ability\", \"bloodshot\", \"scanning\", \"magazine\", \"frail\", \"leader\", \"confided\", \"bust\", \"generally\", \"ornate\", \"confidently\", \"chang\", \"dagger\", \"vane\", \"davy\", \"slashed\", \"gilderoy\", \"resolved\", \"ogden\", \"umbridge\", \"quibbler\", \"luna_lovegood\", \"myrtle\", \"parvati\", \"rune\", \"lovegood\", \"thomas\", \"muriel\", \"luna\", \"dean_thomas\", \"minister\", \"photograph\", \"defense_against\", \"her\", \"she\", \"lavender\", \"lockhart\", \"umbridges\", \"witch\", \"art\", \"dark_art\", \"class\", \"hair\", \"rather\", \"page\", \"wearing\", \"professor\", \"desk\", \"neville\", \"seat\", \"looked\", \"table\", \"hermione\", \"who\", \"by\", \"been\", \"look\", \"very\", \"their\", \"had_been\", \"an\", \"them\", \"than\", \"which\", \"ron\", \"looking\", \"when\", \"around\", \"there\", \"so\", \"down\", \"one\", \"like\", \"into\", \"this\", \"prince\", \"mate\", \"defensive\", \"stunning_spell\", \"blasted\", \"respond\", \"green_light\", \"discussed\", \"scabior\", \"sphere\", \"toppled\", \"wormtails\", \"surroundings\", \"frustrated\", \"dance_floor\", \"pod\", \"seared\", \"graf\", \"blinding\", \"teenage\", \"flustered\", \"vos\", \"stupefy\", \"expelliarmus\", \"rampart\", \"detached\", \"dais\", \"oncoming\", \"sidecar\", \"reverse\", \"scream\", \"wound\", \"stunning\", \"aimed\", \"screamed\", \"alecto\", \"greyback\", \"midair\", \"in_midair\", \"yelled\", \"shattered\", \"yell\", \"jet\", \"hit\", \"roar\", \"crabbe\", \"pain\", \"backward\", \"goyle\", \"death_eater\", \"eater\", \"flew\", \"wand\", \"flash\", \"malfoy\", \"shouted\", \"air\", \"floor\", \"death\", \"foot\", \"arm\", \"spell\", \"face\", \"hand\", \"fell\", \"body\", \"ground\", \"light\", \"over\", \"saw\", \"into\", \"around\", \"them\", \"could\", \"ron\", \"then\", \"her\", \"back\", \"eye\", \"head\", \"harrys\", \"there\", \"still\", \"no\", \"again\", \"hermione\", \"voice\", \"who\", \"vernon\", \"uncle_vernon\", \"mr_weasley\", \"petunia\", \"aunt_petunia\", \"aunt\", \"gregorovitch\", \"katie\", \"quaffle\", \"necklace\", \"dudley\", \"marge\", \"uncle\", \"rucksack\", \"jordan\", \"fred_george\", \"alicia\", \"chaser\", \"arthur\", \"lee_jordan\", \"dursley\", \"madam_hooch\", \"hooch\", \"invited\", \"montague\", \"beater\", \"aunt_marge\", \"desperation\", \"katie_bell\", \"platform_nine\", \"weasley\", \"molly\", \"angelina\", \"fred\", \"george\", \"team\", \"mr_weasleys\", \"goal\", \"mr\", \"field\", \"weasleys\", \"lee\", \"bludger\", \"snitch\", \"percy\", \"dursleys\", \"wood\", \"quidditch\", \"match\", \"bill\", \"broom\", \"car\", \"kitchen\", \"off\", \"their\", \"back\", \"into\", \"would\", \"are\", \"by\", \"one\", \"who\", \"we\", \"this\", \"them\", \"so\", \"been\", \"over\", \"time\", \"tom\", \"lord_voldemort\", \"ollivander\", \"riddle\", \"my_lord\", \"hallows\", \"regulus\", \"elder_wand\", \"morfin\", \"ted\", \"tom_riddle\", \"my_mother\", \"destroyed\", \"mr_ollivander\", \"dirk\", \"deathly_hallows\", \"dudleys\", \"orphanage\", \"wandmaker\", \"lord\", \"nagini\", \"previously\", \"marvolo\", \"kendra\", \"merope\", \"wizarding_world\", \"dippet\", \"vein\", \"madness\", \"resurrection\", \"destroy\", \"faithful\", \"yaxley\", \"voldemort\", \"dark_lord\", \"diary\", \"ariana\", \"muggle_born\", \"frank\", \"power\", \"soul\", \"voldemorts\", \"albus\", \"godrics\", \"godrics_hollow\", \"death\", \"dumbledore\", \"born\", \"my\", \"mother\", \"son\", \"horcruxes\", \"muggle\", \"eater\", \"death_eater\", \"wand\", \"wizard\", \"died\", \"boy\", \"man\", \"been\", \"father\", \"who\", \"never\", \"me\", \"could\", \"did\", \"more\", \"your\", \"would\", \"so\", \"than\", \"knew\", \"no\", \"now\", \"this\", \"there\", \"year\", \"by\", \"know\", \"did_not\", \"one\", \"when\", \"then\", \"yeh\", \"ter\", \"professor_mcgonagall\", \"fer\", \"yer\", \"jus\", \"righ\", \"grubbly\", \"plank\", \"abou\", \"mcgonagall\", \"professor_flitwick\", \"professor_grubbly\", \"tortured\", \"all_righ\", \"archway\", \"motorbike\", \"didn\", \"tha\", \"minerva\", \"skrewts\", \"professor_sprout\", \"don\", \"latter\", \"hagrid\", \"outta\", \"thas\", \"grudgingly\", \"inter\", \"confess\", \"flitwick\", \"fir\", \"sprout\", \"cabin\", \"professor\", \"goblin\", \"bin\", \"griphook\", \"vault\", \"ernie\", \"gringotts\", \"student\", \"dragon\", \"maxime\", \"hagrids\", \"an\", \"gryffindor\", \"hall\", \"them\", \"great_hall\", \"table\", \"their\", \"class\", \"great\", \"one\", \"who\", \"by\", \"year\", \"would\", \"we\", \"now\", \"there\", \"back\", \"down\", \"will\", \"are\", \"into\", \"so\", \"hermione\", \"like\", \"when\", \"dobby\", \"phineas\", \"nigellus\", \"phineas_nigellus\", \"posse\", \"cliff\", \"kreacher\", \"magical_eye\", \"master_regulus\", \"dobbys\", \"mistress\", \"dedalus\", \"blindly\", \"arrow\", \"growled_moody\", \"bane\", \"gracefully\", \"magorian\", \"searing\", \"lovegoods\", \"radish\", \"cavern\", \"diggle\", \"bella\", \"hoisting\", \"wrapping\", \"mangled\", \"hind\", \"confunded\", \"moran\", \"slanting\", \"elf\", \"winky\", \"house_elf\", \"kreachers\", \"moody\", \"boat\", \"sir\", \"centaur\", \"water\", \"surface\", \"master\", \"rock\", \"firenze\", \"mr_cattermole\", \"cattermole\", \"dumbledore\", \"potter\", \"eye\", \"house\", \"upon\", \"into\", \"snape\", \"sword\", \"head\", \"hand\", \"hat\", \"then\", \"looked\", \"down\", \"very\", \"back\", \"again\", \"there\", \"so\", \"this\", \"could\", \"around\", \"did\", \"now\", \"mundungus\", \"rita\", \"professor_trelawney\", \"rita_skeeter\", \"trelawney\", \"pure_blood\", \"kissing\", \"red_light\", \"possessed\", \"fletcher\", \"mafalda\", \"felicis\", \"felix_felicis\", \"murmuring\", \"advanced_potion\", \"sorcerer_stone\", \"bezoar\", \"vapor\", \"reacted\", \"scurried\", \"create\", \"statute\", \"trelawneys\", \"footprint\", \"shift\", \"temptation\", \"vain\", \"appears\", \"skeeter\", \"bay\", \"sibyll\", \"soup\", \"slughorn\", \"felix\", \"ingredient\", \"horace\", \"thief\", \"quirrell\", \"basin\", \"potion\", \"bottle\", \"wine\", \"connection\", \"drink\", \"goblet\", \"antidote\", \"cauldron\", \"copy\", \"dear\", \"quill\", \"book\", \"professor\", \"blood\", \"into\", \"glass\", \"your\", \"an\", \"this\", \"will\", \"very\", \"her\", \"eye\", \"one\", \"by\", \"she\", \"my\", \"which\", \"there\", \"then\", \"who\", \"would\", \"dumbledore\", \"over\", \"did\", \"back\"], \"Freq\": [1745.0, 5474.0, 5592.0, 1482.0, 2999.0, 2087.0, 1166.0, 1806.0, 1042.0, 6216.0, 854.0, 653.0, 1909.0, 754.0, 5233.0, 566.0, 1614.0, 444.0, 1485.0, 497.0, 3468.0, 1885.0, 839.0, 2062.0, 436.0, 499.0, 361.0, 338.0, 449.0, 393.0, 109.21979270715323, 61.4166569789797, 89.6798440636247, 44.8153674400509, 31.680113675964396, 42.92468181057051, 28.760596929332106, 26.81313665346975, 25.85342249713068, 33.634921047992044, 34.48348935590321, 39.508217075158974, 32.086011032345496, 46.311672964600014, 21.093338213077505, 25.81722510085706, 41.71708106881201, 20.36932975309286, 20.36933199511183, 22.456257061014487, 21.020389641844623, 26.34694916496143, 19.91838126752488, 28.44684879464454, 20.804537023471177, 23.679439834615774, 23.02229959041687, 31.826813461221484, 22.011505515880096, 16.559768468610486, 17.545763571318055, 20.283444732402018, 59.99457125041956, 1175.7327558609177, 724.3613896428557, 162.5622129603536, 39.86589981358627, 531.8470408353139, 2108.4138671158285, 130.73374937317007, 1149.4915201324193, 145.79664620744146, 246.99297046637622, 2376.7346797694686, 807.62107786422, 1546.6563202415648, 1396.733049789906, 1159.9307909252389, 1867.9520593349646, 389.0315803482986, 1731.6578249053855, 720.2431774538145, 1348.7284462370717, 406.66500574034137, 571.9597017407966, 492.9961523339473, 1133.6404818855212, 1180.6903799523957, 603.4967656383874, 846.1237539152894, 970.6992242299924, 1386.9638736268953, 783.4620858660146, 477.53110007295606, 847.7338463866132, 1091.2245679877408, 1123.8743907406133, 1120.1822697728176, 831.782580923672, 1038.6830507191455, 1304.6113959616262, 1338.0374953627354, 1040.291277830686, 911.9222396738245, 835.1045714637179, 814.5531852862082, 771.2709552583485, 281.1725828491242, 132.78664330366541, 138.8012911889438, 138.07921383026869, 78.3033150282441, 74.31844703224694, 49.07441646994148, 42.91855158743672, 31.391705375991215, 36.21931911548353, 30.033660948200303, 26.70447435124873, 19.25644251164909, 22.17626226671797, 22.176316612583516, 18.472742816669722, 19.061039748855674, 18.065768661678376, 21.838840537979536, 17.94395754487465, 28.559298742447684, 16.63403124020256, 23.216691830552413, 19.18523180209333, 21.65907028997103, 15.71644242700292, 51.65759002646139, 14.930936099195833, 14.523916411181998, 22.557513201618352, 20.204000866488425, 97.55769092819514, 54.288112051139365, 36.203937766725886, 119.5791761698286, 40.65125088956134, 2934.8897519563643, 62.47258765241246, 162.44978001577903, 2959.3643566918363, 133.5420449595725, 2351.1127389696208, 2213.816446366528, 133.1965462601677, 201.40450867645075, 164.1194142604863, 78.9080405687049, 204.40597501606803, 369.23746699596836, 382.2390896167904, 163.02657471896183, 738.5481628425538, 425.8705590813464, 719.4515074572699, 669.9871579332048, 676.5390719829182, 1068.4422077969841, 238.1134781653051, 513.5723540940339, 393.2983381258207, 778.6549180987547, 638.5084345448188, 485.22681967289947, 430.6045363633044, 738.5523460053938, 686.713558050348, 583.0402123049258, 436.8416321579265, 455.0724668389643, 546.5951345887216, 531.2018003645171, 470.09462761430984, 379.9285266723234, 392.7036004741636, 453.8032764325394, 522.2539680476663, 536.6853628259613, 498.1001978014825, 510.5107489133612, 452.6450573459519, 461.786631204679, 449.4262310450521, 451.22781117608446, 113.29740108947844, 60.45648327200567, 46.559419855463894, 34.939370494590406, 28.299235701133117, 29.567812450945436, 58.52856014040033, 24.2120439414691, 20.642376924598818, 19.25638335911285, 19.284031205150704, 21.79167158196987, 23.677405789371306, 21.979859826424423, 20.16362434993718, 20.591349147379844, 19.9902357635327, 25.96223111236969, 23.424646646271665, 17.447248055274613, 20.393302544846613, 18.301464008629882, 15.158973653718926, 16.91529132270341, 15.034762382238322, 14.437732405726495, 16.185177552440173, 16.924788746360626, 17.8289227382659, 13.345402088745288, 94.373221502523, 28.391036947044967, 120.45970832979086, 22.887603162544295, 44.69445553853914, 72.91384931339682, 189.13679088831415, 198.70267356982563, 37.21169240277971, 68.38967101742307, 494.8398420184057, 37.86573250986918, 1073.3182094595181, 52.17632441886629, 34.005035180292474, 97.64456948620574, 62.13416572084021, 88.93470473661635, 163.11118884957372, 74.53275870942353, 123.29191225125648, 98.69256143369704, 379.02988484077105, 268.55988239657995, 73.5713102168688, 225.34586133908815, 200.5901774333084, 174.85813898207576, 156.2777844475866, 309.3436404140084, 236.61511745832883, 673.9264947473897, 166.66487374413256, 351.79088592205426, 223.6203146763033, 255.83542488330866, 949.750123117955, 501.943720979089, 279.8789582401439, 422.94429106248396, 269.6732411839219, 320.9264892876074, 379.3721153172858, 608.9214943478258, 475.2410813848231, 663.6758278879936, 911.6343276989853, 568.6271203092493, 738.3775308420649, 657.2594266456535, 298.6867230084763, 610.4406511665068, 491.9230609265383, 507.3226997266975, 393.3684841834572, 371.91669700426263, 604.9235476641784, 540.8199998369932, 382.3459132735819, 357.305489818837, 340.96261624670444, 348.9310570496447, 354.6302223386544, 92.6253509188437, 94.85002306560432, 140.83363832954035, 51.469462204442266, 37.73141042858484, 31.065997290527523, 30.300997268394315, 32.25950546352137, 31.77932252007931, 22.3977607987934, 24.39829208715741, 21.78929234375406, 30.205003525591817, 19.517866993785074, 21.438799726133254, 31.662419605783967, 20.997913664249243, 17.974908912783356, 18.586105475337266, 17.53429016372739, 17.493203613306413, 16.983110070658384, 16.246371270707048, 21.7763987654312, 15.764676398326232, 15.637155856417715, 21.40606433179406, 16.67508038014763, 31.2150478901075, 13.653515515865426, 60.146030893901575, 468.8931814207161, 40.51731818075448, 18.94904046239388, 81.33972940258256, 87.50569221938643, 32.32104428904116, 67.9509057219608, 36.57374113290542, 61.85866816229845, 260.7188386180474, 33.02366752629291, 166.196916455085, 67.25610470264172, 82.95121246351073, 1894.2218032354801, 1575.8705312248578, 92.24796587238745, 87.03620747657308, 58.89018764441079, 158.79012919888794, 102.2559306540552, 95.81860550423836, 154.57991803216166, 232.92010933707635, 192.93961977344557, 91.63831820756768, 138.4925542899203, 429.85816785069665, 126.29988157720224, 199.00533838389748, 114.09704718534724, 392.36530283985223, 206.40266162848042, 518.0218970442858, 409.1922851564123, 329.48513567398106, 376.87544583086475, 272.0542978621355, 287.72518442661385, 319.5832315224698, 233.28221394811393, 321.91981105656197, 383.83768237484725, 241.52420022925835, 236.37864441468707, 385.42257065313856, 245.06028256870093, 264.38674978593554, 254.22369048060412, 290.95690172587626, 270.63894279189356, 242.5101409391943, 240.7622866275794, 233.58287831708606, 228.27152029904408, 221.2720343760162, 96.12948283718661, 48.19060335354362, 34.57729541197833, 37.45603320972237, 34.26472560830911, 20.180124435871473, 45.88339541162574, 19.665746809496028, 24.82467406614084, 20.301683980326654, 23.900030614316982, 21.35120072464522, 16.917118517634886, 16.246469221733033, 21.417091948497962, 15.369461134268617, 16.481437208791455, 14.789066577112523, 20.71026552197403, 13.21556460549957, 12.2225072847809, 11.874247110398429, 15.883058999625062, 13.680842807129594, 14.619686415983082, 11.759292378065389, 13.416787371150322, 12.432651461653874, 27.723532533669676, 12.730472912667992, 144.91242101570816, 50.09204823546098, 44.152288142852676, 15.318645290116528, 132.12110405960132, 23.165140352428054, 112.74793870707174, 76.95025019365379, 72.67495190439836, 204.86879585251143, 29.06375363751986, 64.93876986973586, 66.31629852139446, 208.56328654756192, 62.06665956807088, 142.41025958673228, 170.16408087387452, 120.28048686049624, 131.22575315747542, 328.16928863310767, 328.79040561875297, 145.8606860280009, 903.1809201289977, 60.09651632263239, 489.99034625689376, 202.5421780047921, 257.3419298969073, 298.96402680135446, 348.58612015940116, 369.995238697043, 282.2099284304286, 173.3807869457151, 509.69580889429085, 512.3570907197159, 202.434565313181, 163.70143667104713, 221.2081710004548, 226.606347841026, 475.9673055628676, 329.7294306992618, 525.2654720161489, 404.66624531570227, 530.9542454674564, 448.4023357783729, 566.086915977277, 392.88713188511633, 517.3998855685977, 417.3175115218076, 348.3125516389901, 305.4708744748928, 265.69631024809183, 380.22748773758985, 301.7369439400838, 334.7405587442884, 296.69487497782325, 350.24525501353816, 265.4313918765849, 266.301185520585, 435.4507472562364, 381.3721799339089, 1163.8704618678794, 286.6404706200836, 207.36870251362643, 309.41382680427876, 84.8980991359499, 99.34379793752123, 81.54874241050753, 45.31447858799725, 366.7202090944943, 55.289870310283234, 493.1417988367788, 40.16711921226437, 51.621976501525154, 55.35540834062267, 47.09323403558248, 45.97229741992845, 151.60880067603617, 45.34763227245729, 80.30164457126801, 43.15909069061525, 43.15909755970972, 30.573755613481435, 30.664300582239342, 35.359364432587064, 36.67151259645864, 27.10392355740122, 31.631561816407814, 29.418916582070114, 1433.7114629061653, 82.58774103277472, 100.16552710169847, 780.1236634520274, 684.5031757429019, 238.48130424281655, 69.67933183542767, 76.84379049867007, 1494.942241296295, 105.76444357516097, 161.32554694969144, 83.83954420172628, 69.86920047567631, 142.39382801523436, 245.4404937560083, 147.29090163030665, 168.20517861073023, 199.00821772852984, 126.78761631021939, 182.36605041009796, 128.50365349074517, 109.63905934745013, 133.05916825238515, 233.7546253851701, 253.42295853422513, 263.9391300223131, 269.71079048351027, 277.82986781254885, 267.26118896633125, 232.27164284182658, 238.56378832921376, 249.4056373243192, 247.50850333718313, 239.46594772054166, 251.91497248701037, 228.419317281093, 213.8296903430892, 207.60545272363362, 201.94147218735014, 116.93426984710136, 119.06815418154437, 113.2070825099405, 248.103479141801, 79.61937728092109, 88.93891143071696, 65.7109760623421, 77.17534844566944, 56.11229633873288, 48.35640934902101, 47.536102015065, 60.69012851841578, 42.13765878888204, 40.698371791832, 29.49770288674533, 41.88214880016286, 25.21845050911067, 25.147160738564324, 21.657361874994777, 371.11891101742236, 31.772435600779993, 19.910160977042924, 19.96757952078608, 22.266406763314787, 21.918644089342678, 33.52337553760739, 16.697116794648338, 19.38033106937686, 12.663551835870948, 17.03737439419877, 45.263286064641626, 21.818042683712406, 62.462081988707105, 902.8511660726882, 134.64567855216953, 79.13424711057043, 60.72767413802709, 61.541023080140704, 39.1881341699098, 149.66631560203822, 96.89233980824176, 156.25757972119686, 140.70344796563063, 60.37224947148555, 60.37224947148555, 407.817348109208, 1044.9602361871537, 83.52800249189296, 666.8825013806047, 191.9258778569313, 118.55745816415299, 85.41538697642339, 159.68791166864287, 220.71512736510766, 219.9760125179257, 447.7271741500232, 272.6905888872751, 129.32049079160961, 225.5474774058659, 195.58130804368636, 515.981587537866, 157.6686147024833, 451.57106809410817, 269.2683019476624, 389.4050518425014, 411.04866060112676, 407.65258742864876, 306.6559100460541, 313.24536538828374, 395.0556979652573, 346.8307354052979, 255.74359090972382, 231.832477795612, 311.01163386769485, 299.46494188659665, 296.9276598019887, 308.73392477072855, 218.6268674039475, 253.41380523520573, 261.4791685581293, 240.3494954173651, 240.28262466433458, 237.30805050964648, 226.3920412483394, 363.23538018286104, 331.00852354384347, 565.0954086776841, 90.58059111260248, 87.53678376819897, 70.8580537596712, 51.692814048920354, 48.30782121444046, 49.76104947177625, 44.260386667946236, 646.6656317468523, 79.65175814560949, 38.13942178397853, 30.970264597304517, 35.53084748000455, 29.737271788929007, 31.336683624654434, 32.57246860954253, 29.66121024426036, 46.113291748983535, 32.46054766455348, 70.40115319850696, 101.5685824171238, 22.377975177897298, 1717.7709218354637, 26.438640078869984, 25.252551215965493, 20.286743249823584, 20.37505629908676, 16.589077176532605, 125.33475730298773, 21.705721867341325, 93.75710047165491, 81.80895271726315, 969.7958170319152, 225.36323636997923, 76.95589584166082, 140.69955892129116, 70.6494634481207, 69.71590630542084, 72.98169023884368, 208.1763879854162, 132.92102292619313, 61.67424160169915, 87.00351559131094, 555.4816821857315, 194.60445820939805, 205.43140416457803, 606.4213766413538, 102.92460423982024, 202.79970128370041, 335.3616162383139, 118.9345689928357, 170.87795706219282, 251.87069912431718, 258.934287784128, 221.03684693133962, 161.47149264890987, 239.1083215142568, 226.23476503714298, 209.5675675549764, 222.78648768081575, 205.37924503683928, 187.58962147124032, 188.63792061006964, 200.41879187043116, 194.28369574359624, 182.96733639629883, 191.03113061480073, 172.88079364831398, 171.13753996651715, 337.90126420418915, 93.6519000530393, 64.67355971402573, 64.67355971402573, 29.599172276434697, 31.663219406754134, 314.8721026931629, 41.23373364077863, 30.658998547655393, 29.227788735994576, 33.60583283789176, 25.283585438390137, 17.374612307457635, 16.776125751882514, 23.367694961037557, 22.29514591384688, 13.284435652590046, 14.878333935772037, 13.788457609685539, 11.759829099149615, 11.089072344631102, 11.703662764870755, 9.86146355026201, 13.079563638763346, 8.961893562808735, 10.033092004610191, 9.970369377910094, 9.361138372145136, 8.004802060465872, 9.312153305545534, 10.43170909355567, 331.0510815143279, 101.93312418640987, 135.60111781380053, 35.71629101519029, 305.45136291043053, 47.31750084482812, 206.01120006011283, 60.24809801641766, 156.0611863028383, 71.3360777981526, 133.84805397965866, 59.30474224408668, 39.27823272569673, 28.27158757175721, 40.53797055558495, 502.4465802240205, 240.45509269245744, 332.71684280173906, 181.55584318019876, 168.8026291765704, 278.2605213527181, 185.1723032301968, 77.29218168141472, 160.14411397674832, 171.61010221966725, 75.42481783346662, 174.04450072045455, 163.945354412842, 151.51534869726112, 141.46256951450118, 163.89930938358356, 133.33923078511248, 158.41646641312877, 148.7813427310542, 146.82224020160106, 147.8050270629782, 135.10293841457099, 149.3021273847114, 135.2874259864901, 136.6055528187897, 123.83684017838219, 154.45582928018135, 82.13691413966085, 176.82694275562318, 31.445804087044262, 30.223581766039963, 29.32530864974583, 21.034692507240695, 22.096635527153985, 18.314861550871587, 31.34304517507494, 31.34304517507494, 16.29670869109251, 28.76931291610703, 19.421970550508657, 22.99233967064889, 12.93305356792236, 13.374987066977656, 12.027419690093284, 11.79450658623943, 11.354675260751586, 17.563737430250157, 10.333296463270383, 10.849414768617098, 13.27888950620782, 10.956479745797166, 12.09921057329739, 113.19444850352379, 9.543327076847413, 11.655677971468354, 21.342169691761793, 387.19452053998765, 38.00331768984826, 36.12835864846719, 24.629800409640946, 43.07268795792649, 67.1932198678398, 60.492941397283204, 262.64865017711486, 127.5222201133016, 36.97812564729122, 43.152882804327106, 78.6397173761269, 77.4369397663654, 31.49579260748017, 74.66149662043696, 60.83017860985484, 84.84235632511516, 60.19118723442474, 110.26927004185467, 190.41707064962168, 77.84452488478614, 191.59987682198016, 82.09394337794599, 150.16595695629962, 152.8838513266666, 160.69612757259853, 137.69258945146015, 123.16874954813844, 165.7896010820908, 119.48980387290035, 125.48340507941843, 113.33455135403568, 137.73403365352513, 106.65438940712981, 100.19022934258449, 115.11616001120693, 107.58936303599837, 104.1306456685978, 105.80834734001346, 101.25888417847908, 98.08429614888834, 99.63226548245494, 98.49787396014952], \"Total\": [1745.0, 5474.0, 5592.0, 1482.0, 2999.0, 2087.0, 1166.0, 1806.0, 1042.0, 6216.0, 854.0, 653.0, 1909.0, 754.0, 5233.0, 566.0, 1614.0, 444.0, 1485.0, 497.0, 3468.0, 1885.0, 839.0, 2062.0, 436.0, 499.0, 361.0, 338.0, 449.0, 393.0, 109.71514486451615, 61.79275936535015, 90.28346154659296, 45.19620811117793, 32.04449787234527, 43.432885023868735, 29.117907296784317, 27.177548100823383, 26.21688620301894, 34.12469774187012, 34.986503942053396, 40.092529664177285, 32.57812006318411, 47.031958394471296, 21.455670253939417, 26.263758359188337, 42.44697847548526, 20.729725072937814, 20.729736002989128, 22.85696580306938, 21.42860014381948, 26.865432354615436, 20.31833598154904, 29.031876768671648, 21.245788337029545, 24.18514775458066, 23.523459175373997, 32.52186699896835, 22.508268184814792, 16.935307446352137, 17.963130779342144, 20.83892026021094, 64.09297638377718, 1614.2373838867952, 964.3567841291506, 200.9778453243735, 43.087389378710824, 744.3443464037223, 3518.006941327469, 162.53164598151764, 1876.3257676374044, 185.79094311065234, 336.9708998495341, 4317.921289752829, 1321.573334818908, 2794.690708091243, 2619.6663683593847, 2145.653306977383, 3870.7127277205723, 613.732057315746, 3671.975240756651, 1306.5494650954902, 2783.172871135679, 668.9546857906473, 1014.0739491339264, 856.7929829198472, 2418.6734744513933, 2649.790298368094, 1146.829456938399, 1809.8589588063442, 2162.2996728716453, 3633.6683352455107, 1750.9483335549555, 911.6557948586293, 2077.174754001308, 2999.974969591033, 3151.942873205919, 3179.4659340162702, 2225.0561854071607, 3194.1081860853865, 5233.898389207154, 6216.293761377234, 3847.4156347735984, 3387.8360708122505, 3275.9316707084927, 4300.216112478771, 2725.6485068957754, 281.76196110812845, 133.26932690173956, 139.35391890966665, 138.63012316307555, 78.6780701867065, 74.94283505591734, 49.51633037226187, 43.39147044925738, 31.790577610929095, 36.69929841843433, 30.53040003624263, 27.17526619683763, 19.61188909659562, 22.600810172511363, 22.60132926616578, 18.827966251700392, 19.432928049513077, 18.419522255736243, 22.276252135188898, 18.31255702603066, 29.15425497541759, 16.987819798965397, 23.719441644759733, 19.610513190271927, 22.143320384096018, 16.083918933830873, 52.8703076505783, 15.283438666036059, 14.87457103107079, 23.123948794506713, 20.82824539288905, 105.41854028826553, 57.685131130443004, 38.11987148992757, 136.960252685948, 44.82595649840271, 5474.971148415796, 73.220953733808, 220.78234479583438, 6216.293761377234, 181.32518699815458, 5592.545744267597, 5233.898389207154, 191.3632271902089, 322.049791636234, 255.90828676409947, 104.99717887921703, 338.1064820791492, 712.5386245314971, 783.1232189927034, 271.3718824406339, 2032.4829894890222, 983.5101645845787, 2145.653306977383, 2162.2996728716453, 2229.949680475891, 4317.921289752829, 505.1609842300609, 1766.217451182657, 1196.644514187192, 3671.975240756651, 2794.690708091243, 1750.9483335549555, 1428.6719947673257, 3633.6683352455107, 3215.052565463183, 2418.6734744513933, 1631.4178801388712, 1876.3257676374044, 2783.172871135679, 2649.790298368094, 2225.0561854071607, 1448.8146228826888, 1637.3879087887806, 2352.734071892504, 3518.006941327469, 3870.7127277205723, 3179.4659340162702, 4300.216112478771, 2619.6663683593847, 3275.9316707084927, 2725.6485068957754, 3194.1081860853865, 113.67923867157376, 61.0493189209089, 47.15659250177246, 35.43799457039594, 28.724062931225763, 30.03331437896599, 59.5097499260638, 24.63767569813223, 21.027455026788697, 19.616341654072283, 19.645413855517024, 22.215107833169046, 24.138813212388897, 22.415109654571925, 20.576308076345196, 21.02819289603462, 20.42527249831699, 26.528283253068828, 23.956664131808086, 17.848326704516374, 20.878414541913607, 18.739775251008663, 15.526664619976575, 17.32682076235311, 15.405764296395812, 14.794205049757856, 16.604561964460043, 17.372226059914116, 18.301497947744753, 13.71445080044795, 98.1663472630087, 29.24264374001119, 128.080061195038, 23.591766780471207, 47.04920607822415, 79.00402492294367, 214.6907153879247, 227.85712673328854, 39.480260511298, 75.0396401727009, 616.9556879591007, 40.53417596874236, 1485.780366892878, 57.56651272177322, 36.16584879503432, 114.0581887850052, 70.58855057176886, 105.42119405942756, 206.89699523526787, 86.91147085841332, 155.82048866865142, 122.43054041306696, 578.0075595477977, 393.37209294059613, 88.57829234905317, 336.41732319787707, 305.676448273952, 262.4892043642422, 231.86448023654097, 546.3218634901132, 398.64010923642593, 1550.766805927982, 257.5568958224615, 708.971504906023, 398.157496075993, 488.0198979725353, 3468.23909563416, 1440.9167050459891, 605.680026095163, 1124.9326201399006, 593.7965081519959, 783.6065671130777, 1028.8255976040373, 2180.5776188342275, 1473.036429843392, 2545.6713740745377, 4300.216112478771, 2309.6935821719912, 3847.4156347735984, 3215.052565463183, 731.1614331074398, 3387.8360708122505, 2402.2463434510732, 2638.9545208652257, 1511.4685255229167, 1467.073328026039, 6216.293761377234, 5233.898389207154, 1794.4733318813774, 2273.2130557443134, 1886.6590928653886, 2352.734071892504, 2681.180211722089, 93.04328473877939, 95.29689765299905, 141.77536917029803, 51.857571162948375, 38.14185133580557, 31.432025745681912, 30.665557271598814, 32.653229549069536, 32.30336342681194, 22.778313243315242, 24.83119100119372, 22.176554493582497, 30.750238395208648, 19.87716226745865, 21.85931312782616, 32.28574951192873, 21.415238270974292, 18.33257046655121, 18.96094064031274, 17.891134943156832, 17.85135462399648, 17.33946262906877, 16.602437227539102, 22.264219600125593, 16.12133366606162, 15.993374392546492, 21.90170723642915, 17.075363622589908, 31.972960899469086, 14.006735737233317, 62.08999187273871, 499.01781085932413, 42.96252958642184, 19.522701978706106, 93.01738389443362, 104.09523335158593, 35.427721756328346, 82.60203295004818, 41.02803060278567, 74.9375076430571, 406.9278775878613, 37.25832393806664, 261.54509684458543, 88.4823554575614, 114.38180055913192, 5592.545744267597, 5474.971148415796, 142.05428235360225, 137.48444400758805, 81.64411441132596, 319.0023948551176, 174.1008137748314, 160.31632418027718, 321.48493156594725, 598.1787596105643, 466.6479224763792, 162.12242914028218, 308.32402120731666, 1806.0863695826274, 277.94531904549274, 616.1185746527043, 251.6056107409095, 2352.734071892504, 744.1578350071153, 5233.898389207154, 3275.9316707084927, 2273.2130557443134, 3194.1081860853865, 1631.4178801388712, 1879.7274635907183, 2545.6713740745377, 1229.113730221507, 2620.676742507046, 4300.216112478771, 1398.650542375302, 1511.4685255229167, 6216.293761377234, 1766.217451182657, 2296.8762826970496, 2180.5776188342275, 3847.4156347735984, 3151.942873205919, 2309.6935821719912, 2681.180211722089, 2431.023922905044, 3468.23909563416, 3179.4659340162702, 96.526417553453, 48.56731531530505, 34.99209361755517, 37.92068845732116, 34.7596443739941, 20.544385685926528, 46.714503958394495, 20.05592201102106, 25.31849874364036, 20.71957010540396, 24.39611172112256, 21.802923009803905, 17.27820640060813, 16.60728837980544, 21.895567990949342, 15.731124858094473, 16.870334899487876, 15.14875385588963, 21.25411705481516, 13.573476819235083, 12.58117208976406, 12.23147278338768, 16.361135921281996, 14.099419793348197, 15.07446895821013, 12.127026021644895, 13.839602883540527, 12.826947293610377, 28.606278136590863, 13.150107182623016, 150.2992968719682, 52.81475287053615, 46.53488474054838, 15.850771228094153, 145.59893742917504, 24.2655104551236, 124.83582720663753, 84.07931440200133, 79.56940757505052, 235.50196397638078, 30.904943363228625, 72.1890449821974, 75.0245313688513, 263.3939995419561, 71.76616515230475, 194.56305471977532, 238.7567644880085, 162.74231643009347, 181.97338023871694, 557.4794460761259, 558.8572953028378, 212.80931856449428, 1909.8071246692973, 76.33194728115761, 1096.7359180826816, 381.68046011776676, 530.2079574066831, 670.2351361467756, 839.0415395167284, 936.1375448782858, 649.2821194784232, 345.2160309801321, 1691.693260332383, 1750.8473280371252, 455.8427543527665, 338.19577984398364, 566.1394030651628, 593.7965081519959, 2402.2463434510732, 1234.3095721335228, 3468.23909563416, 2180.5776188342275, 4300.216112478771, 3387.8360708122505, 6216.293761377234, 2638.9545208652257, 5592.545744267597, 3215.052565463183, 2062.290195505413, 1462.1403372180712, 1030.8240963898963, 3847.4156347735984, 1735.519662233014, 2725.6485068957754, 1898.2745145623635, 5233.898389207154, 1551.9480712096058, 3275.9316707084927, 436.0598427191127, 381.95943508718364, 1166.8790127952807, 287.39031511633533, 207.94342568043047, 310.3082145398787, 85.26720110279692, 99.87653196887737, 82.0197130464763, 45.68821360871213, 369.7582795142662, 55.766394598379684, 497.48365687021874, 40.52648065543986, 52.103010330050815, 55.88594987143554, 47.54802682826813, 46.4265707031699, 153.1125802584506, 45.831752304094266, 81.22331758893515, 43.6666878976921, 43.666747557773476, 30.948918092096186, 31.042943077219945, 35.80279412544908, 37.136002440567644, 27.459868032972125, 32.06979043132988, 29.83901830854667, 1482.2166637278785, 84.89809172884932, 103.8262905480577, 854.8743375602282, 754.5161326964254, 256.61156724507384, 72.5454804592008, 81.25262781035597, 2087.7376600991397, 115.75849824160389, 197.0878175482045, 94.3841844821608, 76.05524980595958, 184.97392590053238, 375.9278346197994, 197.39276987418557, 244.61888771383397, 387.44041460914923, 200.61749699039697, 389.9947677612893, 212.03526026932798, 158.29549285964396, 267.5105964062829, 1794.4733318813774, 2545.6713740745377, 3215.052565463183, 3468.23909563416, 3870.7127277205723, 3671.975240756651, 2273.2130557443134, 2681.180211722089, 3275.9316707084927, 3518.006941327469, 3179.4659340162702, 4300.216112478771, 3151.942873205919, 3194.1081860853865, 2402.2463434510732, 1925.359950133407, 117.43144695789863, 119.60139796017333, 113.73533534394862, 249.31286419391822, 80.08984775831537, 89.54849944798445, 66.18121743148293, 77.81009286946626, 56.611295506696194, 48.80058677408196, 47.981061845374235, 61.2769728036772, 42.58172489057953, 41.15319708226131, 29.88684990337174, 42.49213490269345, 25.643718983705085, 25.613035314353702, 22.07220909008625, 378.4688896162669, 32.446116690596185, 20.332854925011492, 20.398857431641954, 22.764027536170744, 22.412177209892608, 34.27953677597613, 17.14936113988762, 19.92201570878495, 13.026751780798902, 17.52838528354066, 46.96762935620036, 22.548571543357177, 66.20524208463274, 1042.9394759584484, 147.59786099301965, 86.068942596117, 65.72085004454306, 66.665737772934, 42.60739236826484, 189.28054532961488, 119.14534953118608, 209.4457961758901, 194.40182431455327, 71.89039907598804, 71.89039907598804, 839.0415395167284, 2999.974969591033, 110.38771870101701, 1885.5213988911623, 362.6637313265574, 194.64072142212854, 122.55116404384519, 325.8626597512702, 558.8572953028378, 557.4794460761259, 1909.8071246692973, 827.0926319017843, 242.2849976427495, 656.4147269776295, 515.915483710777, 3194.1081860853865, 358.28250378895314, 3275.9316707084927, 1125.4605071969197, 2783.172871135679, 3387.8360708122505, 3633.6683352455107, 1907.7463700208152, 2077.174754001308, 3870.7127277205723, 3151.942873205919, 1398.650542375302, 1049.056830774313, 2725.6485068957754, 2671.4177568334007, 3179.4659340162702, 3847.4156347735984, 992.14359328992, 2273.2130557443134, 2794.690708091243, 2225.0561854071607, 2681.180211722089, 2296.8762826970496, 2638.9545208652257, 363.77674916862, 331.5184979231053, 566.4573000340046, 91.04408731420403, 88.01502939481934, 71.31354450709478, 52.12331385232099, 48.71797106488321, 50.184029352655465, 44.69278208394807, 653.3686813539206, 80.48918749355603, 38.54270014503006, 31.331763009022147, 35.95030149530398, 30.115864737955476, 31.742948414384834, 33.00048554362083, 30.07340843244993, 46.79038314521117, 32.94031912333516, 71.45681636578998, 103.14082722449169, 22.733805447273273, 1745.6926443794591, 26.87951178482084, 25.684404414487965, 20.642719536105467, 20.796820195274965, 16.94201374215493, 129.308839320505, 22.205051117915886, 103.03274627827298, 94.38808853888192, 1806.0863695826274, 332.13487997292833, 95.72582720549185, 207.71980723531038, 90.67318919349387, 92.21861520020276, 98.27018964111963, 433.6676778766447, 241.19795258525707, 81.47895446413767, 139.3831760320844, 2620.676742507046, 530.1810141272332, 590.0334612271618, 4300.216112478771, 195.9832219527579, 744.1578350071153, 2545.6713740745377, 321.48493156594725, 887.2098465004092, 2681.180211722089, 3275.9316707084927, 2273.2130557443134, 992.14359328992, 3870.7127277205723, 3518.006941327469, 2671.4177568334007, 3847.4156347735984, 3215.052565463183, 2309.6935821719912, 2649.790298368094, 3671.975240756651, 3468.23909563416, 3151.942873205919, 5233.898389207154, 2431.023922905044, 2296.8762826970496, 338.4634667784873, 94.3063695128849, 65.19852831282327, 65.19852831282327, 29.967938886416427, 32.071825583770035, 319.6556758514402, 41.902257954114916, 31.161112746601486, 29.73589323183328, 34.20052325190995, 25.74093606528317, 17.795903931097477, 17.186211902689983, 23.956818078208187, 22.93767683606796, 13.679435293264458, 15.321749879599338, 14.205421267180194, 12.116345006517838, 11.445226519460055, 12.127943002221238, 10.245742287492913, 13.595450593137981, 9.328078334901212, 10.443248703165503, 10.384674555876014, 9.75932550501439, 8.35781237408951, 9.748399881671107, 10.923933730632873, 361.88024393681536, 112.16207326255915, 156.24403633665025, 39.36762088939351, 393.45950379153567, 58.74432906449756, 350.98714670638077, 87.50244856185593, 284.9315314027691, 113.41136132808283, 259.6519564223228, 97.30632134953429, 57.86233618310372, 37.47332854922656, 65.23735759882139, 2999.974969591033, 1126.2624560445386, 2062.290195505413, 772.6051772468999, 686.764402950867, 3468.23909563416, 1614.2373838867952, 263.5580690339034, 1462.1403372180712, 1750.8473280371252, 262.07405528325603, 2638.9545208652257, 2352.734071892504, 2309.6935821719912, 1879.7274635907183, 3215.052565463183, 1898.2745145623635, 3847.4156347735984, 3151.942873205919, 3179.4659340162702, 3387.8360708122505, 2180.5776188342275, 3633.6683352455107, 2671.4177568334007, 137.13642326164808, 124.47803553490064, 155.3021758125381, 82.64419290838026, 178.25898941058128, 31.878247176899826, 30.67201914965603, 29.85413553243654, 21.428554388255293, 22.513734721536235, 18.676208581089526, 31.979438109112895, 31.979438109112895, 16.657417585307922, 29.42362967387325, 19.895999887117444, 23.61998504793359, 13.29212999191823, 13.753686758482326, 12.385091425651623, 12.151016773048942, 11.711877076122661, 18.158319470373584, 10.695411153930715, 11.2367531840571, 13.755501504439323, 11.352917222354426, 12.538752749633778, 117.38275282668374, 9.896959760650468, 12.109905805942052, 22.414519315822268, 444.35841322408464, 40.659649594889395, 38.7947668673294, 26.650346524976747, 48.32852040492859, 79.66190428182699, 78.29373771038165, 449.73009676377217, 199.50028873922489, 46.020033753278355, 56.08950068746447, 133.92107619416495, 143.9706699032334, 42.558681379200245, 175.56189961715478, 128.48768567083425, 263.8443498071195, 150.96311264569505, 527.1858951087656, 1806.0863695826274, 306.28357581924973, 3468.23909563416, 412.1497452092081, 2077.174754001308, 2620.676742507046, 3179.4659340162702, 2649.790298368094, 1879.7274635907183, 5592.545744267597, 2062.290195505413, 2681.180211722089, 2273.2130557443134, 5474.971148415796, 1885.5213988911623, 1511.4685255229167, 3847.4156347735984, 2638.9545208652257, 3275.9316707084927, 3870.7127277205723, 2999.974969591033, 2402.2463434510732, 3633.6683352455107, 3215.052565463183], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.2518, -7.8275, -7.4489, -8.1426, -8.4895, -8.1857, -8.5862, -8.6563, -8.6927, -8.4296, -8.4047, -8.2687, -8.4767, -8.1098, -8.8962, -8.6941, -8.2143, -8.9311, -8.9311, -8.8336, -8.8997, -8.6738, -8.9535, -8.5971, -8.91, -8.7806, -8.8087, -8.4849, -8.8536, -9.1382, -9.0804, -8.9354, -7.8509, -4.8755, -5.3599, -6.8541, -8.2596, -5.6688, -4.2915, -7.072, -4.8981, -6.963, -6.4358, -4.1717, -5.2511, -4.6013, -4.7033, -4.889, -4.4126, -5.9815, -4.4883, -5.3656, -4.7382, -5.9372, -5.5961, -5.7447, -4.912, -4.8713, -5.5424, -5.2045, -5.0671, -4.7103, -5.2814, -5.7765, -5.2026, -4.9501, -4.9206, -4.9239, -5.2216, -4.9995, -4.7715, -4.7462, -4.9979, -5.1296, -5.2176, -5.2425, -5.2971, -5.8833, -6.6335, -6.5892, -6.5944, -7.1616, -7.2139, -7.6289, -7.7629, -8.0757, -7.9326, -8.1199, -8.2374, -8.5644, -8.4232, -8.4232, -8.6059, -8.5746, -8.6282, -8.4385, -8.635, -8.1703, -8.7108, -8.3774, -8.5681, -8.4468, -8.7675, -7.5776, -8.8188, -8.8464, -8.4062, -8.5164, -6.9418, -7.5279, -7.9331, -6.7383, -7.8172, -3.5378, -7.3875, -6.4319, -3.5295, -6.6278, -3.7596, -3.8198, -6.6304, -6.2169, -6.4216, -7.154, -6.2021, -5.6108, -5.5762, -6.4283, -4.9176, -5.4681, -4.9437, -5.015, -5.0052, -4.5483, -6.0495, -5.2808, -5.5477, -4.8647, -5.0631, -5.3376, -5.457, -4.9175, -4.9903, -5.154, -5.4427, -5.4018, -5.2185, -5.2471, -5.3693, -5.5823, -5.5492, -5.4046, -5.2641, -5.2368, -5.3114, -5.2868, -5.4071, -5.3871, -5.4143, -5.4103, -6.7055, -7.3336, -7.5948, -7.8819, -8.0927, -8.0488, -7.366, -8.2486, -8.4082, -8.4777, -8.4762, -8.354, -8.271, -8.3454, -8.4316, -8.4106, -8.4403, -8.1789, -8.2817, -8.5763, -8.4203, -8.5285, -8.7169, -8.6073, -8.7251, -8.7657, -8.6514, -8.6067, -8.5547, -8.8443, -6.8882, -8.0894, -6.6442, -8.3049, -7.6356, -7.1462, -6.193, -6.1437, -7.8189, -7.2103, -5.2313, -7.8015, -4.457, -7.4809, -7.909, -6.8542, -7.3062, -6.9476, -6.3411, -7.1243, -6.6209, -6.8435, -5.4979, -5.8424, -7.1372, -6.0179, -6.1342, -6.2715, -6.3839, -5.701, -5.9691, -4.9224, -6.3195, -5.5725, -6.0255, -5.891, -4.5793, -5.217, -5.8011, -5.3883, -5.8383, -5.6643, -5.497, -5.0238, -5.2717, -4.9377, -4.6203, -5.0923, -4.831, -4.9474, -5.7361, -5.0213, -5.2372, -5.2063, -5.4608, -5.5168, -5.0304, -5.1424, -5.4892, -5.5569, -5.6037, -5.5806, -5.5644, -6.5557, -6.532, -6.1367, -7.1433, -7.4538, -7.6482, -7.6731, -7.6105, -7.6255, -7.9753, -7.8898, -8.0029, -7.6763, -8.113, -8.0191, -7.6292, -8.0399, -8.1953, -8.1619, -8.2201, -8.2225, -8.2521, -8.2964, -8.0035, -8.3265, -8.3347, -8.0206, -8.2704, -7.6434, -8.4703, -6.9875, -4.9339, -7.3826, -8.1425, -6.6857, -6.6126, -7.6086, -6.8655, -7.485, -6.9594, -5.5209, -7.5871, -5.9711, -6.8758, -6.666, -3.5377, -3.7217, -6.5598, -6.618, -7.0086, -6.0167, -6.4568, -6.5218, -6.0436, -5.6336, -5.8219, -6.5665, -6.1535, -5.0208, -6.2456, -5.791, -6.3473, -5.1121, -5.7545, -4.8343, -5.0701, -5.2868, -5.1524, -5.4783, -5.4223, -5.3173, -5.6321, -5.31, -5.1341, -5.5973, -5.6189, -5.13, -5.5828, -5.5069, -5.5461, -5.4111, -5.4835, -5.5933, -5.6005, -5.6308, -5.6538, -5.6849, -6.5157, -7.2062, -7.5382, -7.4582, -7.5473, -8.0767, -7.2553, -8.1025, -7.8696, -8.0707, -7.9075, -8.0203, -8.2531, -8.2935, -8.0172, -8.349, -8.2792, -8.3875, -8.0508, -8.5, -8.5781, -8.607, -8.3161, -8.4654, -8.399, -8.6167, -8.4849, -8.5611, -7.7591, -8.5374, -6.1053, -7.1675, -7.2937, -8.3523, -6.1977, -7.9387, -6.3562, -6.7382, -6.7954, -5.759, -7.7119, -6.9079, -6.887, -5.7411, -6.9532, -6.1227, -5.9446, -6.2916, -6.2045, -5.2879, -5.286, -6.0987, -4.2755, -6.9854, -4.887, -5.7704, -5.531, -5.3811, -5.2275, -5.1679, -5.4387, -5.9259, -4.8476, -4.8424, -5.771, -5.9833, -5.6823, -5.6582, -4.916, -5.2831, -4.8175, -5.0783, -4.8067, -4.9757, -4.7426, -5.1079, -4.8326, -5.0475, -5.2283, -5.3595, -5.499, -5.1406, -5.3718, -5.268, -5.3887, -5.2228, -5.5, -5.4968, -4.909, -5.0416, -3.9259, -5.3271, -5.6509, -5.2507, -6.5439, -6.3868, -6.5842, -7.1718, -5.0808, -6.9728, -4.7846, -7.2923, -7.0414, -6.9716, -7.1332, -7.1573, -5.9641, -7.171, -6.5996, -7.2205, -7.2205, -7.5652, -7.5623, -7.4198, -7.3834, -7.6857, -7.5312, -7.6037, -3.7174, -6.5715, -6.3786, -4.3259, -4.4567, -5.5111, -6.7415, -6.6436, -3.6755, -6.3242, -5.902, -6.5565, -6.7388, -6.0268, -5.4823, -5.993, -5.8602, -5.692, -6.1429, -5.7794, -6.1294, -6.2882, -6.0946, -5.5311, -5.4503, -5.4097, -5.388, -5.3584, -5.3972, -5.5375, -5.5107, -5.4663, -5.4739, -5.507, -5.4563, -5.5542, -5.6202, -5.6497, -5.6774, -6.2062, -6.1881, -6.2385, -5.4539, -6.5905, -6.4798, -6.7825, -6.6217, -6.9404, -7.0892, -7.1063, -6.862, -7.2268, -7.2616, -7.5835, -7.2329, -7.7402, -7.743, -7.8924, -5.0512, -7.5092, -7.9765, -7.9737, -7.8647, -7.8804, -7.4555, -8.1525, -8.0035, -8.429, -8.1324, -7.1553, -7.885, -6.8332, -4.1622, -6.0651, -6.5966, -6.8614, -6.8481, -7.2994, -5.9594, -6.3942, -5.9163, -6.0211, -6.8672, -6.8672, -4.9569, -4.016, -6.5426, -4.4652, -5.7107, -6.1924, -6.5202, -5.8945, -5.5709, -5.5742, -4.8636, -5.3594, -6.1055, -5.5492, -5.6918, -4.7217, -5.9073, -4.855, -5.3721, -5.0031, -4.9491, -4.9574, -5.242, -5.2208, -4.9887, -5.1189, -5.4236, -5.5218, -5.2279, -5.2658, -5.2743, -5.2353, -5.5804, -5.4327, -5.4014, -5.4857, -5.4859, -5.4984, -5.5455, -4.9168, -5.0097, -4.4749, -6.3056, -6.3398, -6.5512, -6.8666, -6.9343, -6.9046, -7.0218, -4.34, -6.4342, -7.1706, -7.3788, -7.2415, -7.4195, -7.3671, -7.3284, -7.422, -6.9808, -7.3318, -6.5577, -6.1911, -7.7038, -3.3631, -7.537, -7.5829, -7.8019, -7.7976, -8.0031, -5.9809, -7.7343, -6.2712, -6.4075, -3.9348, -5.3942, -6.4686, -5.8652, -6.5541, -6.5674, -6.5217, -5.4735, -5.9221, -6.69, -6.3459, -4.492, -5.5409, -5.4868, -4.4043, -6.1779, -5.4997, -4.9967, -6.0333, -5.6709, -5.283, -5.2553, -5.4135, -5.7275, -5.335, -5.3903, -5.4668, -5.4057, -5.487, -5.5776, -5.572, -5.5115, -5.5426, -5.6026, -5.5594, -5.6593, -5.6694, -4.5331, -5.8163, -6.1865, -6.1865, -6.9681, -6.9007, -4.6037, -6.6366, -6.9329, -6.9807, -6.8412, -7.1257, -7.5008, -7.5359, -7.2045, -7.2515, -7.7693, -7.656, -7.732, -7.8912, -7.9499, -7.896, -8.0672, -7.7848, -8.1629, -8.05, -8.0562, -8.1193, -8.2758, -8.1245, -8.011, -4.5536, -5.7315, -5.4461, -6.7803, -4.6341, -6.499, -5.0279, -6.2574, -5.3056, -6.0885, -5.4592, -6.2732, -6.6852, -7.014, -6.6536, -4.1364, -4.8733, -4.5486, -5.1543, -5.2271, -4.7273, -5.1346, -6.0083, -5.2798, -5.2106, -6.0327, -5.1965, -5.2563, -5.3352, -5.4038, -5.2566, -5.463, -5.2906, -5.3534, -5.3666, -5.36, -5.4498, -5.3499, -5.4485, -5.2899, -5.3881, -5.1671, -5.7986, -5.0319, -6.7588, -6.7984, -6.8286, -7.1609, -7.1116, -7.2993, -6.762, -6.762, -7.4161, -6.8477, -7.2406, -7.0719, -7.6472, -7.6136, -7.7198, -7.7394, -7.7774, -7.3412, -7.8717, -7.8229, -7.6209, -7.8131, -7.7139, -5.4779, -7.9512, -7.7512, -7.1463, -4.2481, -6.5694, -6.62, -7.0031, -6.4441, -5.9995, -6.1045, -4.6362, -5.3587, -6.5967, -6.4423, -5.8422, -5.8576, -6.7572, -5.8941, -6.0989, -5.7662, -6.1095, -5.5041, -4.9578, -5.8523, -4.9516, -5.7992, -5.1953, -5.1774, -5.1275, -5.282, -5.3935, -5.0963, -5.4238, -5.3749, -5.4767, -5.2817, -5.5374, -5.6, -5.4611, -5.5287, -5.5614, -5.5454, -5.5894, -5.6212, -5.6055, -5.617], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5131, 1.5115, 1.5109, 1.5092, 1.5062, 1.5058, 1.5053, 1.5041, 1.5037, 1.5032, 1.5031, 1.5029, 1.5024, 1.5022, 1.5006, 1.5005, 1.5003, 1.5001, 1.5001, 1.4999, 1.4984, 1.4981, 1.4977, 1.4973, 1.4966, 1.4965, 1.4961, 1.496, 1.4953, 1.4952, 1.4941, 1.4906, 1.4515, 1.2006, 1.2314, 1.3055, 1.4399, 1.1815, 1.0057, 1.2999, 1.0276, 1.2752, 1.207, 0.9206, 1.0251, 0.926, 0.8887, 0.9025, 0.789, 1.0617, 0.766, 0.9221, 0.7932, 1.0199, 0.945, 0.9649, 0.7598, 0.7092, 0.8756, 0.7573, 0.7167, 0.5545, 0.7134, 0.871, 0.6214, 0.5063, 0.4864, 0.4744, 0.5336, 0.3943, 0.1284, -0.0184, 0.2097, 0.2052, 0.1508, -0.1462, 0.2552, 1.9384, 1.9369, 1.9366, 1.9366, 1.9358, 1.9322, 1.9316, 1.9296, 1.9279, 1.9274, 1.9241, 1.9231, 1.9223, 1.9216, 1.9216, 1.9215, 1.9212, 1.9211, 1.9207, 1.9202, 1.9199, 1.9195, 1.9191, 1.9186, 1.9184, 1.9174, 1.9173, 1.9172, 1.9167, 1.9157, 1.9101, 1.863, 1.8798, 1.889, 1.8048, 1.8428, 1.317, 1.7818, 1.6337, 1.1983, 1.6347, 1.074, 1.0801, 1.5782, 1.4712, 1.4963, 1.6549, 1.4373, 1.2831, 1.2233, 1.431, 0.9282, 1.1035, 0.8478, 0.7689, 0.7478, 0.544, 1.1884, 0.7053, 0.8278, 0.3896, 0.4642, 0.6572, 0.7412, 0.3472, 0.3969, 0.5178, 0.6229, 0.5239, 0.3129, 0.3334, 0.3859, 0.602, 0.5127, 0.2949, 0.033, -0.0352, 0.0869, -0.1905, 0.1848, -0.0187, 0.1381, -0.0165, 2.0239, 2.0175, 2.0145, 2.0131, 2.0124, 2.0117, 2.0107, 2.0099, 2.0088, 2.0088, 2.0087, 2.008, 2.008, 2.0077, 2.007, 2.0063, 2.0058, 2.0057, 2.0048, 2.0046, 2.0038, 2.0036, 2.0033, 2.0032, 2.0029, 2.0029, 2.0017, 2.0012, 2.0011, 2.0, 1.9879, 1.9977, 1.9659, 1.997, 1.9759, 1.9471, 1.9006, 1.8904, 1.9681, 1.9345, 1.8067, 1.9592, 1.7021, 1.929, 1.9657, 1.8719, 1.8997, 1.8572, 1.7895, 1.8736, 1.7931, 1.8117, 1.6053, 1.6456, 1.8417, 1.6266, 1.606, 1.621, 1.6328, 1.4585, 1.5057, 1.1939, 1.592, 1.3265, 1.4504, 1.3815, 0.7321, 0.9727, 1.2553, 1.049, 1.238, 1.1346, 1.0296, 0.7516, 0.896, 0.6829, 0.4761, 0.6256, 0.3766, 0.4398, 1.132, 0.3135, 0.4414, 0.3783, 0.6812, 0.6549, -0.3025, -0.2425, 0.4811, 0.1769, 0.3165, 0.1188, 0.0043, 2.374, 2.3738, 2.3718, 2.371, 2.3677, 2.3668, 2.3665, 2.3663, 2.3621, 2.3616, 2.3609, 2.3609, 2.3606, 2.3602, 2.3591, 2.359, 2.3588, 2.3588, 2.3585, 2.3583, 2.3582, 2.3577, 2.3568, 2.3563, 2.3561, 2.356, 2.3556, 2.3548, 2.3545, 2.3529, 2.3467, 2.3162, 2.3199, 2.3487, 2.2443, 2.2049, 2.2867, 2.1832, 2.2636, 2.1867, 1.9333, 2.2578, 1.925, 2.1042, 2.0572, 1.2959, 1.1331, 1.9468, 1.9213, 2.0518, 1.6809, 1.8463, 1.8638, 1.6462, 1.4353, 1.4953, 1.808, 1.5781, 0.943, 1.5897, 1.2484, 1.5877, 0.5873, 1.0961, 0.0656, 0.2983, 0.4471, 0.2413, 0.5873, 0.5016, 0.3033, 0.7167, 0.2816, -0.0377, 0.6222, 0.5231, -0.4021, 0.4034, 0.2166, 0.2293, -0.2035, -0.0765, 0.1247, -0.0317, 0.0359, -0.3424, -0.2866, 2.3773, 2.3736, 2.3695, 2.3691, 2.367, 2.3635, 2.3634, 2.3617, 2.3617, 2.361, 2.3608, 2.3605, 2.3603, 2.3594, 2.3593, 2.3581, 2.3581, 2.3574, 2.3555, 2.3547, 2.3525, 2.3517, 2.3517, 2.3513, 2.3508, 2.3506, 2.3504, 2.3502, 2.35, 2.349, 2.3449, 2.3285, 2.3288, 2.3472, 2.2843, 2.335, 2.2795, 2.2928, 2.2908, 2.242, 2.32, 2.2755, 2.258, 2.148, 2.2362, 2.0693, 2.0427, 2.079, 2.0544, 1.8515, 1.8509, 2.0036, 1.6326, 2.1422, 1.5757, 1.7478, 1.6585, 1.5741, 1.503, 1.4531, 1.5482, 1.6927, 1.1817, 1.1526, 1.5697, 1.6558, 1.4417, 1.4181, 0.7626, 1.0614, 0.4939, 0.6971, 0.2896, 0.3591, -0.0148, 0.4768, 0.001, 0.3396, 0.6029, 0.8156, 1.0256, 0.067, 0.6319, 0.2843, 0.5254, -0.3229, 0.6155, -0.1283, 2.476, 2.4759, 2.4748, 2.4748, 2.4746, 2.4745, 2.4731, 2.4721, 2.4716, 2.4692, 2.4692, 2.4688, 2.4686, 2.4685, 2.4681, 2.4679, 2.4678, 2.4676, 2.4675, 2.4668, 2.466, 2.4657, 2.4657, 2.4652, 2.4651, 2.4649, 2.4648, 2.4644, 2.4636, 2.4632, 2.4441, 2.4498, 2.4415, 2.3859, 2.38, 2.4041, 2.4371, 2.4216, 2.1434, 2.3871, 2.2772, 2.3589, 2.3926, 2.2158, 2.0511, 2.1846, 2.1029, 1.8112, 2.0185, 1.7173, 1.9766, 2.1101, 1.779, 0.4392, 0.1703, -0.0225, -0.0767, -0.1568, -0.1429, 0.1964, 0.058, -0.0979, -0.1768, -0.1087, -0.3599, -0.1472, -0.2265, 0.0289, 0.2225, 2.4908, 2.4905, 2.4904, 2.4902, 2.4891, 2.4882, 2.4879, 2.4868, 2.4862, 2.4859, 2.4857, 2.4854, 2.4845, 2.4839, 2.4819, 2.4806, 2.4783, 2.4767, 2.476, 2.4754, 2.474, 2.474, 2.4736, 2.4729, 2.4727, 2.4727, 2.4683, 2.4674, 2.4667, 2.4666, 2.4581, 2.4621, 2.4368, 2.3508, 2.4032, 2.411, 2.416, 2.415, 2.4114, 2.2602, 2.2883, 2.2021, 2.1717, 2.3204, 2.3204, 1.7736, 1.4404, 2.2162, 1.4557, 1.8586, 1.9993, 2.134, 1.7818, 1.566, 1.5651, 1.0444, 1.3854, 1.8672, 1.4268, 1.525, 0.672, 1.6742, 0.5134, 1.0648, 0.5283, 0.3858, 0.3074, 0.6671, 0.6032, 0.2128, 0.2881, 0.7959, 0.9854, 0.3244, 0.3066, 0.124, -0.0277, 0.9825, 0.3011, 0.1259, 0.2696, 0.0828, 0.2251, 0.0391, 2.6494, 2.6494, 2.6485, 2.6458, 2.6455, 2.6445, 2.6426, 2.6425, 2.6424, 2.6412, 2.6406, 2.6405, 2.6404, 2.6393, 2.6392, 2.6383, 2.638, 2.6379, 2.6371, 2.6363, 2.6362, 2.636, 2.6355, 2.6351, 2.6348, 2.6344, 2.634, 2.6335, 2.6304, 2.6299, 2.6197, 2.6282, 2.5566, 2.5079, 2.0291, 2.2631, 2.4327, 2.2613, 2.4014, 2.3712, 2.3534, 1.917, 2.055, 2.3724, 2.1796, 1.0996, 1.6487, 1.5958, 0.6921, 2.0069, 1.3509, 0.624, 1.6565, 1.0038, 0.2858, 0.1131, 0.3203, 0.8354, -0.1334, -0.0932, 0.1056, -0.198, -0.0998, 0.1403, 0.0085, -0.2572, -0.2312, -0.1956, -0.6596, 0.0074, 0.0541, 3.1053, 3.1, 3.0988, 3.0988, 3.0945, 3.0941, 3.0918, 3.0908, 3.0907, 3.0897, 3.0894, 3.089, 3.083, 3.0828, 3.082, 3.0785, 3.0776, 3.0776, 3.0771, 3.0771, 3.0753, 3.0713, 3.0687, 3.0682, 3.0669, 3.0669, 3.0662, 3.0653, 3.0638, 3.0611, 3.0608, 3.0179, 3.0113, 2.9652, 3.0096, 2.8537, 2.8906, 2.5741, 2.7337, 2.5049, 2.6433, 2.4443, 2.6117, 2.7195, 2.8252, 2.6311, 1.3201, 1.5628, 1.2826, 1.6587, 1.7037, 0.5841, 0.9416, 1.8802, 0.8953, 0.7843, 1.8614, 0.3881, 0.4431, 0.3827, 0.5201, 0.1306, 0.4511, -0.083, 0.0536, 0.0317, -0.0251, 0.3256, -0.0851, 0.124, 3.2519, 3.2506, 3.2503, 3.2496, 3.2477, 3.2421, 3.241, 3.2379, 3.2372, 3.237, 3.2362, 3.2356, 3.2356, 3.2339, 3.2333, 3.2316, 3.2288, 3.2284, 3.2278, 3.2264, 3.226, 3.2248, 3.2225, 3.2213, 3.2207, 3.2205, 3.2202, 3.2201, 3.2194, 3.2194, 3.2175, 3.2067, 3.118, 3.1882, 3.1845, 3.1769, 3.1406, 3.0855, 2.9978, 2.7179, 2.8082, 3.037, 2.9935, 2.7234, 2.6356, 2.9547, 2.4007, 2.508, 2.1212, 2.3362, 1.6911, 1.006, 1.8859, 0.3598, 1.6422, 0.6287, 0.4142, 0.2708, 0.2985, 0.5304, -0.2627, 0.4074, 0.1939, 0.2571, -0.4269, 0.3834, 0.542, -0.2535, 0.0559, -0.193, -0.3438, -0.1329, 0.0574, -0.3408, -0.2298]}, \"token.table\": {\"Topic\": [3, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 2, 4, 10, 1, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 6, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 8, 9, 10, 2, 6, 10, 1, 9, 3, 2, 2, 3, 10, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 2, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 6, 8, 3, 5, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 6, 9, 8, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 2, 3, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 6, 3, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 9, 10, 4, 6, 2, 3, 6, 8, 2, 3, 9, 10, 1, 2, 4, 8, 10, 9, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 8, 1, 8, 4, 4, 9, 5, 10, 1, 2, 3, 4, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 8, 3, 3, 10, 2, 3, 1, 1, 3, 4, 5, 5, 1, 4, 5, 7, 9, 2, 3, 5, 7, 9, 4, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 7, 8, 7, 9, 1, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 7, 7, 5, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 2, 5, 6, 9, 7, 7, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 7, 8, 1, 7, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 8, 10, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 2, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 5, 6, 8, 8, 9, 10, 2, 3, 5, 6, 7, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 3, 1, 4, 3, 7, 2, 1, 2, 3, 4, 5, 6, 8, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 5, 3, 3, 4, 5, 7, 4, 1, 2, 4, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 8, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 5, 7, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 8, 10, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 8, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 8, 4, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 6, 7, 10, 1, 2, 7, 1, 2, 4, 6, 8, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 4, 5, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 9, 1, 2, 3, 5, 9, 6, 3, 9, 1, 7, 3, 5, 7, 9, 2, 6, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 7, 9, 2, 4, 5, 6, 9, 2, 3, 9, 3, 8, 2, 4, 8, 4, 1, 6, 7, 6, 1, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 7, 9, 7, 1, 4, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 2, 7, 10, 4, 9, 1, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 6, 1, 2, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 2, 8, 2, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 4, 5, 8, 1, 4, 1, 9, 2, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 10, 2, 2, 7, 2, 6, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 10, 10, 2, 4, 1, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 7, 4, 5, 7, 2, 1, 3, 4, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 4, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 8, 10, 1, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 1, 9, 9, 4, 7, 2, 8, 6, 5, 2, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 9, 10, 7, 4, 4, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 8, 8, 8, 10, 4, 4, 10, 6, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 8, 10, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 3, 7, 1, 4, 5, 7, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 4, 1, 3, 7, 1, 3, 5, 6, 3, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 3, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 3, 5, 7, 3, 5, 6, 9, 1, 4, 10, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 7, 9, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 5, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 10, 8, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 6, 7, 8, 9, 10, 1, 3, 5, 7, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 3, 3, 1, 3, 4, 8, 1, 2, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 8, 10, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 2, 3, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 5, 5, 5, 2, 1, 3, 4, 5, 9, 10, 5, 1, 2, 3, 5, 7, 8, 9, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 7, 5, 10, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 7, 4, 5, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 8, 10, 1, 3, 4, 9, 10, 6, 7, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 4, 10, 2, 3, 5, 8, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 7, 1, 5, 7, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 10, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 2, 9, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 5, 6, 8, 1, 2, 3, 5, 6, 8, 9, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 8, 2], \"Freq\": [0.9940249540768291, 0.9756021925564796, 0.9844990163591341, 0.46885204306348766, 0.24104121790653732, 0.03266253210054279, 0.041758427115883824, 0.011990043429313178, 0.06201746601368884, 0.0483736234906773, 0.05581571941231996, 0.012403493202737769, 0.02522043617890013, 0.9856023992087756, 0.2412717425675334, 0.10851960473561546, 0.13117175523868083, 0.08428707163931298, 0.1564578767304747, 0.052679419774570614, 0.08376027744156728, 0.02739329828277672, 0.07006362830017891, 0.044250712610639314, 0.9463261934797069, 0.0509234152804129, 0.009430262088965352, 0.18860524177930704, 0.05469552011599904, 0.48471547137281906, 0.09996077814303272, 0.005658157253379211, 0.022632629013516845, 0.07166999187613668, 0.011316314506758423, 0.9785734966474436, 0.1543195394682011, 0.005143984648940037, 0.020575938595760148, 0.005143984648940037, 0.005143984648940037, 0.005143984648940037, 0.7253018355005452, 0.01543195394682011, 0.01543195394682011, 0.051439846489400365, 0.9478473590133608, 0.9884742466759459, 1.0013824224729384, 0.08811116140682433, 0.04303103231496072, 0.5245687748871402, 0.11679851628346481, 0.08196387107611565, 0.04303103231496072, 0.028687354876640477, 0.04303103231496072, 0.018441870992126023, 0.014343677438320239, 0.44718623901955623, 0.27699275341568935, 0.018846929613851027, 0.04283393094057052, 0.025700358564342312, 0.030840430277210774, 0.06910540858412044, 0.03883609738611727, 0.023987001326719493, 0.024558120405927097, 0.18850092878201358, 0.08700042866862165, 0.10798737418078914, 0.12286902645305338, 0.05418447750414155, 0.0705924530863816, 0.06372399819149041, 0.2117773592591448, 0.03510543612944382, 0.05838186660657505, 0.02889441570303815, 0.9631471901012717, 0.04699393719884992, 0.1879757487953997, 0.7284060265821738, 0.9780583579825457, 0.9570329872203985, 0.9961527009447133, 0.47168074032086943, 0.2121473999480123, 0.030228961995159648, 0.04575194247916055, 0.026416300121896268, 0.07271290858295158, 0.04275627957873932, 0.05446659818947684, 0.018518643384422127, 0.025054635167159348, 0.06086348544318819, 0.9281681530086199, 0.013861462883391611, 0.11089170306713289, 0.17095804222849653, 0.08778926492814687, 0.43432583701293714, 0.04158438865017483, 0.013861462883391611, 0.023102438138986017, 0.08778926492814687, 0.013861462883391611, 0.08529849999076788, 0.11877586826671442, 0.279283798356869, 0.11648289783685506, 0.18573060481860748, 0.07108208332563991, 0.017426575266931074, 0.04127346773746833, 0.061910201606202496, 0.02338829838456539, 0.9891650409209235, 0.402065897810981, 0.5858674510960009, 0.9927335803722164, 0.006531141976133002, 0.37855853984146276, 0.32841833588895114, 0.020891751646879845, 0.04094783322788449, 0.00668536052700155, 0.03844082303025891, 0.0785529861922682, 0.05766123454538837, 0.03342680263500775, 0.016713401317503877, 0.9814808108918951, 0.99578414467107, 0.9963377199582722, 0.9954630656038131, 0.9962809530518932, 0.14401008710515345, 0.2136823538687698, 0.20435124671292831, 0.05007694173634925, 0.1297023894661965, 0.08211374297140499, 0.03079265361427687, 0.06376256556491675, 0.0510100524519334, 0.030481616709082154, 0.006144683337044385, 0.11674898340384332, 0.7373620004453262, 0.006144683337044385, 0.11060430006679893, 0.01228936667408877, 0.7390037877162855, 0.25368786742499355, 0.005514953639673773, 0.9986113724570586, 0.9591206710788807, 0.9749163856197044, 0.9909781704744214, 0.993550525114708, 0.21713103112901738, 0.7663448157494731, 1.0104113022424535, 0.9775773331367329, 0.5243206950427202, 0.16014816208417812, 0.05374835576797759, 0.028519535713620762, 0.014259767856810381, 0.06800812362478796, 0.07349264972356119, 0.057039071427241524, 0.007678336538282512, 0.013162862637055735, 0.05542787522016589, 0.47113693937141, 0.30683288068306114, 0.01187740183289269, 0.021775236693636596, 0.04355047338727319, 0.013856968805041472, 0.031673071554380504, 0.033652638526529284, 0.009897834860743908, 0.3252864146951048, 0.14119747163377505, 0.08640909572266499, 0.11802981553421993, 0.022854579665777336, 0.06699835682844314, 0.1615474398293302, 0.03662994275199929, 0.024419961834666194, 0.016906127423999672, 0.057781238481569124, 0.08889421304856787, 0.3760225211954421, 0.11822930335459528, 0.16712112053130762, 0.044447106524283936, 0.02844614817554172, 0.04355816439379826, 0.05600335422059776, 0.019556726870684934, 0.9562022171270644, 0.9734164320692313, 0.9737516748348733, 0.9772240425179543, 0.0692316980430013, 0.258977833420116, 0.010256547858222415, 0.046154465362000865, 0.007692410893666811, 0.4666729275491199, 0.023077232681000433, 0.08718065679489052, 0.017948958751889225, 0.010256547858222415, 0.03133950457863359, 0.041786006104844786, 0.041786006104844786, 0.06267900915726718, 0.8043806175182622, 0.9903170475342968, 0.9781457955719928, 0.9880438667877953, 0.9552760042884546, 0.026119585350280493, 0.006529896337570123, 0.026119585350280493, 0.009794844506355186, 0.4277082101108431, 0.009794844506355186, 0.17304225294560827, 0.03917937802542074, 0.029384533519065555, 0.2546659571652348, 1.0061798425191935, 0.026296672551896383, 0.9203835393163734, 0.039445008827844574, 0.1872521173562591, 0.8000772287040161, 0.9671468435196252, 0.0413961404440306, 0.005913734349147229, 0.07687854653891397, 0.005913734349147229, 0.48492621663007274, 0.0029568671745736144, 0.2809023815844934, 0.008870601523720843, 0.09166288241178204, 0.0029568671745736144, 0.22952055645387867, 0.12139930258717549, 0.08725574873453239, 0.2579735179977479, 0.0056905923087738515, 0.011381184617547703, 0.009484320514623085, 0.06259651539651237, 0.0056905923087738515, 0.2086550513217079, 0.9874192769033375, 0.009058978768358105, 0.009058978768358105, 0.06341285137850673, 0.7609542165420808, 0.01811795753671621, 0.009058978768358105, 0.1358846815253716, 0.010025048147244956, 0.12030057776693946, 0.0902254333252046, 0.030075144441734866, 0.010025048147244956, 0.015037572220867433, 0.010025048147244956, 0.02005009629448991, 0.06015028888346973, 0.6416030814236772, 0.08683534609658834, 0.1096867529641116, 0.0365622509880372, 0.08074163759858215, 0.041132532361541845, 0.1675769836951705, 0.3442945301373503, 0.0457028137350465, 0.05179652223305269, 0.03808567811253875, 0.009432393449370602, 0.08960773776902073, 0.004716196724685301, 0.03301337707279711, 0.22637744278489447, 0.6083893774844039, 0.004716196724685301, 0.004716196724685301, 0.004716196724685301, 0.018864786898741204, 0.9575057662002378, 0.9895725234810392, 0.9564454695618639, 0.04250868753608284, 1.006084860305903, 0.1398900992568327, 0.08270232283108349, 0.1570464321845575, 0.1447290649543961, 0.08798119450115265, 0.10205818562133707, 0.11129621104395811, 0.09721921992377368, 0.026394358350345797, 0.04970937489315125, 0.11654012884760026, 0.8687536877730201, 0.01059455716796366, 0.5510698364163183, 0.18445532024490655, 0.023726617956813707, 0.016838245001609728, 0.02143049363841238, 0.030614990912017685, 0.06582223046083803, 0.0635261061424367, 0.015307495456008843, 0.027553491820815918, 0.5754015378603072, 0.20775146803069916, 0.021008575418834746, 0.025677147734131357, 0.025677147734131357, 0.04201715083766949, 0.03968286468002118, 0.022175718497658897, 0.029178576970603814, 0.00933714463059322, 0.006317299260609215, 0.27796116746680544, 0.018951897781827643, 0.6949029186670136, 0.1686150451961091, 0.6284742593673157, 0.18394368566848265, 0.022783986780290828, 0.18796789093739932, 0.13670392068174497, 0.06835196034087249, 0.022783986780290828, 0.051263970255654365, 0.01708799008521812, 0.045567973560581655, 0.022783986780290828, 0.427199752130453, 0.9871706754400956, 0.9894505603961194, 0.011722949803362366, 0.640854589250476, 0.015630599737816487, 0.007815299868908243, 0.1797518969848896, 0.007815299868908243, 0.007815299868908243, 0.011722949803362366, 0.10159889829580718, 0.011722949803362366, 0.13713901950431864, 0.6856950975215933, 0.15999552275503842, 0.9881325460819609, 0.9908119273788883, 0.8467521500115752, 0.06828646371061091, 0.04097187822636654, 0.027314585484244362, 0.9875988055121484, 0.9374805109965336, 0.024670539763066674, 0.024670539763066674, 0.05287961683676218, 0.0031105656962801278, 0.48213768292341985, 0.37015731785733524, 0.08709583949584358, 0.9977604772268909, 0.17969372613871062, 0.8086217676241979, 0.9906089213434615, 0.08590568339733579, 0.016208619508931283, 0.8023266656920984, 0.0032417239017862565, 0.03727982487054195, 0.0032417239017862565, 0.03403810096875569, 0.006483447803572513, 0.009725171705358769, 0.0032417239017862565, 0.05158972209680817, 0.600651764412838, 0.11791936479270439, 0.08106956329498427, 0.003684980149772012, 0.003684980149772012, 0.007369960299544024, 0.11791936479270439, 0.007369960299544024, 0.003684980149772012, 0.015676993140474667, 0.6950133625610435, 0.1672212601650631, 0.06270797256189867, 0.047030979421424, 0.991727232542438, 1.0034226307880265, 1.0020599906106038, 0.9637139283056697, 0.9571882739078011, 0.21394378364794212, 0.7666318914051259, 0.09339416409711168, 0.03113138803237056, 0.00778284700809264, 0.3424452683560762, 0.01556569401618528, 0.00778284700809264, 0.0389142350404632, 0.47475366749365105, 0.0483003251653371, 0.08643216082218218, 0.6838309194460884, 0.05338456991958311, 0.03813183565684508, 0.00508424475424601, 0.002542122377123005, 0.07880579369081317, 0.002542122377123005, 0.002542122377123005, 0.26919838532250573, 0.08884727410315156, 0.1800559375512374, 0.04014361886388243, 0.1322378033163186, 0.05814921261900617, 0.12131637759599764, 0.04014361886388243, 0.043685702881283824, 0.02597528279427687, 0.0719561070839676, 0.015419165803707342, 0.020558887738276455, 0.7298405147088142, 0.005139721934569114, 0.1490519361025043, 0.9747924611863095, 0.9791791028319435, 0.9875716760276474, 0.9972957275526768, 0.9524702388879003, 0.9923445679778576, 0.9777473554602891, 0.9685801937516554, 0.9924737203152708, 0.9393333110345913, 0.959098206937608, 0.39297308194988256, 0.5988161248760115, 0.02032549780746402, 0.9146474013358808, 0.054201327486570715, 0.0038096804873253135, 0.6666940852819299, 0.27048731460009723, 0.026667763411277193, 0.026667763411277193, 0.9588293630859361, 0.8857081186704716, 0.08051891987913379, 0.022740680269963082, 0.10991328797148822, 0.022740680269963082, 0.12886385486312413, 0.034111020404944625, 0.22740680269963082, 0.09096272107985233, 0.034111020404944625, 0.0075802267566543605, 0.3221596371578103, 0.04409793586776559, 0.0035755083136026155, 0.0035755083136026155, 0.0035755083136026155, 0.4159508004824376, 0.0011918361045342052, 0.4862691306499557, 0.017877541568013078, 0.0023836722090684105, 0.022644885986149898, 0.0035875762130374443, 0.5883624989381409, 0.3946333834341189, 0.010762728639112333, 0.9884182118921435, 0.9712156518549273, 0.26227948723792743, 0.7256399146915992, 1.0002259476821034, 0.9597426234307953, 0.10434334479079349, 0.009485758617344861, 0.8442325169436927, 0.028457275852034586, 0.0791522594284063, 0.032380469766166216, 0.043173959688221616, 0.453326576726327, 0.06116310955831396, 0.007195659948036936, 0.03597829974018468, 0.007195659948036936, 0.24465243823325583, 0.03597829974018468, 0.9832530865618165, 0.02129125982527339, 0.9581066921373027, 0.9863386255001562, 0.9895253773333897, 0.06971155702650272, 0.9178688341822859, 0.38170792489411026, 0.20337574368907532, 0.05366477675151514, 0.025869174434063707, 0.053939980734856244, 0.055591204634902865, 0.11228322520317013, 0.04540865725128204, 0.04100539351782439, 0.027520398334110328, 0.3739231420116941, 0.2112306210883368, 0.06696460115353656, 0.02381962322911032, 0.050785234431876713, 0.06876230856705431, 0.10786244481106559, 0.03910013624401128, 0.03190930658994024, 0.02606675749600752, 0.9999852867734267, 0.17334956934448423, 0.053655819082816546, 0.07429267257620753, 0.024764224192069174, 0.06603793117885114, 0.008254741397356392, 0.5324308201294873, 0.02889159489074737, 0.004127370698678196, 0.03301896558942557, 0.9760151797110012, 0.7524011677578237, 0.05714439248793598, 0.14286098121983995, 0.02857219624396799, 0.9912905711956685, 0.9703264175970687, 0.9972116958277795, 0.5504963709368743, 0.2473412386035262, 0.016443097322893598, 0.012737610602241519, 0.035433716766235496, 0.039602389326969085, 0.039139203486887576, 0.023390884924116243, 0.018990619443341898, 0.016443097322893598, 0.5406278806682479, 0.33509607431075017, 0.0074569362850792804, 0.00652481924944437, 0.023768984408690207, 0.03448833031849167, 0.024701101444325115, 0.0074569362850792804, 0.009787228874166555, 0.010253287391984011, 0.9986306741377479, 0.9752523582831041, 0.6338270835995644, 0.2313713261468847, 0.008146877681228334, 0.011405628753719668, 0.011405628753719668, 0.011405628753719668, 0.043993139478633, 0.01629375536245667, 0.014664379826211, 0.017923130898702334, 0.7330009805306383, 0.19586261018227583, 0.0029676153057920577, 0.008902845917376175, 0.0059352306115841155, 0.008902845917376175, 0.02967615305792058, 0.0029676153057920577, 0.008902845917376175, 0.0029676153057920577, 0.00969548167209717, 0.9889391305539114, 0.0282679734743245, 0.07538126259819868, 0.7221794175702426, 0.04509414816142242, 0.042401960211486754, 0.03769063129909934, 0.004711328912387417, 0.015480080712130084, 0.02221055058696925, 0.006730469874839167, 0.980086036927862, 0.09914735087268711, 0.1775127242698765, 0.24635302465746273, 0.10520876096970729, 0.1034769295134158, 0.07143804757202346, 0.020781977475497735, 0.08139607844569946, 0.06580959533907617, 0.029874092621027994, 0.008291944349291494, 0.033167777397165976, 0.18242277568441287, 0.004145972174645747, 0.16583888698582988, 0.004145972174645747, 0.004145972174645747, 0.5514142992278843, 0.004145972174645747, 0.049751666095748964, 0.007467084557699894, 0.16427586026939767, 0.014934169115399788, 0.007467084557699894, 0.007467084557699894, 0.022401253673099683, 0.05226959190389926, 0.08213793013469883, 0.05226959190389926, 0.5898996800582916, 0.992540317101514, 0.005408939057773918, 0.9748975964011255, 0.3636697009337811, 0.026333553046534102, 0.016000133496628315, 0.008666738977340337, 0.005000041717696349, 0.0036666972596439886, 0.34833623966617894, 0.027333561390073372, 0.16733472948557113, 0.03366694756582208, 0.984938837451503, 0.06585854187205517, 0.005066041682465782, 0.045594375142192035, 0.005066041682465782, 0.005066041682465782, 0.7447081273224699, 0.03546229177726047, 0.07599062523698673, 0.005066041682465782, 0.015198125047397346, 0.0035787311301290698, 0.588701270906232, 0.3954497898792622, 0.01073619339038721, 0.9934818035796311, 0.9895888458734362, 0.08290035309371027, 0.9146672291339367, 0.03882637258873152, 0.05823955888309729, 0.6484004222318164, 0.0660048334008436, 0.031061098070985216, 0.011647911776619457, 0.003882637258873152, 0.12424439228394087, 0.011647911776619457, 0.007765274517746304, 0.01084379761970012, 0.14096936905610155, 0.03253139285910036, 0.7590658333790083, 0.0542189880985006, 0.9677863976580762, 0.9929486606679304, 0.10522282483470713, 0.0931003795772524, 0.11055670074798722, 0.09697956205963791, 0.16874443798376995, 0.0737044671653248, 0.08728160585367412, 0.04461059854743344, 0.16147097082929712, 0.057702839425484556, 0.9988907524975225, 0.1140868764601447, 0.1282738455536342, 0.08985080425876682, 0.09457979395659664, 0.30147309323665183, 0.05379225781281435, 0.07684608258973477, 0.046698773266069596, 0.06443248463293147, 0.030147309323665182, 0.9756715611761763, 0.3014381078000325, 0.03907531027037458, 0.008373280772223124, 0.025119842316669375, 0.04465749745185666, 0.12839030517408792, 0.4409927873370845, 0.005582187181482083, 0.005582187181482083, 0.005582187181482083, 0.9693728793554446, 0.04918881544545786, 0.9345874934636994, 0.9693728793554446, 0.05923095133613839, 0.030712345137256944, 0.13601181417928074, 0.06142469027451389, 0.4431352655518502, 0.05045599558263641, 0.057037212397762896, 0.04826225664426091, 0.06800590708964037, 0.04387477876750992, 0.9995157586230516, 0.04319337306505405, 0.03455469845204324, 0.9156995089791459, 0.9907655642481074, 0.05184719798569116, 0.6740135738139851, 0.2592359899284558, 0.9814545226221939, 0.10480539649451318, 0.7860404737088488, 0.026201349123628294, 0.06550337280907073, 0.9771812749910034, 0.9834629516246781, 0.004699042348077153, 0.014097127044231458, 0.18326265157500896, 0.04229138113269437, 0.6860601828192643, 0.03289329643654007, 0.004699042348077153, 0.03289329643654007, 0.004699042348077153, 0.004699042348077153, 0.015466846740792392, 0.007733423370396196, 0.9666779212995246, 0.029840273840284277, 0.03133228753229849, 0.3521152313153545, 0.05222047922049749, 0.44611209391224993, 0.008952082152085284, 0.004476041076042642, 0.016412150612156354, 0.05222047922049749, 0.0059680547680568555, 0.9538062045715997, 0.032046572818421167, 0.0811846511400003, 0.24782682979579038, 0.04806985922763175, 0.3952410647605277, 0.04700164013368438, 0.009613971845526351, 0.054479173791315984, 0.07477533657631606, 0.010682190939473722, 0.9349804188055789, 0.9822543454913032, 0.9479052562261834, 0.9956587483911199, 0.9806101493842776, 0.07041031692506211, 0.9153341200258074, 0.9829320926844693, 0.022225488782626368, 0.0596578909428392, 0.001169762567506651, 0.002339525135013302, 0.001169762567506651, 0.9124148026551877, 0.001169762567506651, 0.9841471805798478, 0.9665263337085297, 0.03956066896453991, 0.05487447630565214, 0.40964434637475206, 0.1544142240228816, 0.10719665138778559, 0.08294978976435789, 0.014037656729352874, 0.03700836774102121, 0.05359832569389279, 0.045941422023336675, 0.9369139808363002, 0.05465331554878418, 0.9634324179892062, 0.963590610474758, 0.8354191307774855, 0.03386834313962779, 0.07902613399246484, 0.045157790852837054, 0.95230868234212, 0.027832406876380483, 0.06096622458635725, 0.0013253527083990707, 0.9078666052533634, 0.969569258770612, 0.0753393572928269, 0.4877904150145741, 0.05235446862721869, 0.12897076417924602, 0.05235446862721869, 0.18643298584326654, 0.005107753036801823, 0.0038308147776013675, 0.0038308147776013675, 0.0038308147776013675, 0.01455781562343169, 0.05823126249372676, 0.2596143786178651, 0.05823126249372676, 0.18197269529289611, 0.10190470936402182, 0.021836723435147535, 0.01455781562343169, 0.08977319634449542, 0.1989568135202331, 0.2715808817006943, 0.3016787629201011, 0.138590243754478, 0.010499260890490757, 0.06229561461691183, 0.08259418567186064, 0.01749876815081793, 0.07909443204169704, 0.02519822613717782, 0.010499260890490757, 0.9476616581523785, 0.0492291770468768, 0.013891718371139445, 0.18753819801038252, 0.006945859185569722, 0.006945859185569722, 0.006945859185569722, 0.006945859185569722, 0.006945859185569722, 0.041675155113418336, 0.1805923388248128, 0.5348311572888687, 0.006021650000033168, 0.01505412500008292, 0.08430310000046434, 0.021075775000116086, 0.09333557500051409, 0.003010825000016584, 0.06021650000033168, 0.6774356250037313, 0.03010825000016584, 0.006021650000033168, 0.1530106960231646, 0.8346037964899887, 0.1530106960231646, 0.8346037964899887, 0.42103385096037366, 0.2622833825654787, 0.0717828204916047, 0.011043510844862261, 0.06626106506917356, 0.1028426947427798, 0.011043510844862261, 0.02622833825654787, 0.012423949700470043, 0.015184827411685609, 0.33948623608085887, 0.36359467893297787, 0.04624884955304454, 0.015252280171748732, 0.028044515154505734, 0.09249769910608908, 0.008364153642571885, 0.08265751835012217, 0.010824198831563617, 0.013284244020555348, 0.038467164762325326, 0.021981237007043044, 0.027476546258803802, 0.7198855119806596, 0.005495309251760761, 0.17584989605634435, 0.9503316270958202, 0.9901804559434573, 0.1307469709196318, 0.09806022818972386, 0.16456084270919175, 0.09355171195111586, 0.10369587348798384, 0.05635645298259992, 0.059737840161555915, 0.19273906920049172, 0.0755176469966839, 0.02592396837199596, 0.010204955200104341, 0.0867421192008869, 0.2602263576026607, 0.07143468640073039, 0.010204955200104341, 0.010204955200104341, 0.0051024776000521705, 0.5255551928053735, 0.015307432800156512, 0.0051024776000521705, 0.9847048796872411, 0.9968663085061888, 0.9051888590681104, 0.08811572964379835, 0.9719916675913437, 1.0007169961289173, 0.9968603159234577, 0.04070410380409261, 0.010176025951023153, 0.06105615570613892, 0.010176025951023153, 0.020352051902046305, 0.050880129755115765, 0.07123218165716207, 0.7428498944246902, 0.010176025951023153, 0.31773570791558403, 0.6787990123651113, 0.058289530496081175, 0.03885968699738745, 0.326774640659849, 0.010598096453832941, 0.3903632193828467, 0.03709333758841529, 0.012364445862805098, 0.08478477163066353, 0.03179428936149882, 0.0070653976358886275, 0.9600607194542862, 0.9852627059545028, 0.9688645900080506, 0.07733207887025693, 0.1075104511123084, 0.020747630916410395, 0.1075104511123084, 0.01697533438615396, 0.27349149844359155, 0.0037722965302564356, 0.36779891170000245, 0.015089186121025742, 0.007544593060512871, 0.11959837107466705, 0.09763132332625882, 0.1936354579304133, 0.18956748612515253, 0.04312050113576431, 0.08542740791047645, 0.17573638198726588, 0.052883633468390194, 0.024407830831564704, 0.01789907594314745, 0.014893801657302745, 0.984136586432543, 0.0645702032067938, 0.007174467022977088, 0.21523401068931264, 0.007174467022977088, 0.0573957361838167, 0.007174467022977088, 0.6241786309990066, 0.007174467022977088, 0.014348934045954175, 0.016717410705974177, 0.10364794637703989, 0.11535013387122181, 0.3895156694491983, 0.14711321421257276, 0.06018267854150703, 0.016717410705974177, 0.023404374988363848, 0.10197620530644247, 0.02674785712955868, 0.018643010477951555, 0.04914975489641774, 0.39319803917134194, 0.05253939316513621, 0.07287722277744699, 0.028811925284106952, 0.00677927653743693, 0.34743792254364264, 0.022032648746670023, 0.008474095671796161, 0.9938748337340587, 0.9986943247885338, 0.06568248308030745, 0.08167473983029537, 0.11194579724991532, 0.10394966887492137, 0.2924298377140645, 0.0902420202320746, 0.06568248308030745, 0.03883833782139919, 0.09823814860706855, 0.0514036824106754, 0.16006610689239342, 0.07760780940237257, 0.11932200695614782, 0.11059112839838091, 0.2580459662628888, 0.05626566181672011, 0.08148819987249119, 0.013581366645415198, 0.09215927366531743, 0.03007302614341937, 0.007631430733722769, 0.02671000756802969, 0.049604299769197994, 0.3319672369169404, 0.011447146100584152, 0.019078576834306922, 0.0038157153668613845, 0.2518372142128514, 0.28617865251460384, 0.011447146100584152, 0.12789470014608445, 0.09233039850118395, 0.1614072151576253, 0.09506611401233014, 0.20859830772489707, 0.05881788348964311, 0.038983946033833226, 0.0800196787010261, 0.10942862044584765, 0.026673226233675365, 0.05666641356990488, 0.8783294103335256, 0.04249981017742866, 0.01416660339247622, 0.9862552369618982, 0.9696686939121656, 0.028788320625723313, 0.4203810049135125, 0.015377612259703136, 0.3386650886032295, 0.09244448300309908, 0.025033322283237663, 0.026642607287160086, 0.013768327255780715, 0.00911928168889372, 0.02968236785012466, 0.9751317003231389, 0.23925184467246352, 0.1738154427107641, 0.25356605760158524, 0.04362426797446628, 0.041579380413163176, 0.05316707659388078, 0.0667996603359015, 0.04635078472287042, 0.051122189032577675, 0.03135494260664764, 0.2493361358888905, 0.42301165123218665, 0.10336463564435996, 0.09897020566317646, 0.06687176058322734, 0.004776554327373382, 0.003821243461898705, 0.036492875061132635, 0.005349740846658187, 0.008215673443082216, 0.9221948786702273, 0.0265761559191669, 0.0265761559191669, 0.09491484256845321, 0.0037965937027381286, 0.7934880838722689, 0.03416934332464316, 0.0037965937027381286, 0.007593187405476257, 0.0037965937027381286, 0.007593187405476257, 0.9648289472791304, 0.9847310002447209, 0.037522964253496605, 0.9380741063374152, 0.25295557363216165, 0.04079928606970349, 0.6935878631849592, 0.007301388398377269, 0.8761666078052723, 0.007301388398377269, 0.0949180491789045, 0.007301388398377269, 0.9296277460494176, 0.05691598445200515, 0.06083314140798245, 0.06989339651129897, 0.10872306123979841, 0.042712631201349376, 0.010354577260933182, 0.1514356924411478, 0.16179026970208096, 0.15014137028353114, 0.23556663268622988, 0.009060255103316534, 0.12160464133851334, 0.8704332222125165, 0.46743973936950434, 0.18399223783693255, 0.038677046992748584, 0.034256813050720175, 0.01823346501086719, 0.033151754565213076, 0.11050584855071025, 0.05912062897462998, 0.03149416683695242, 0.0237587574384027, 0.53327401415429, 0.17292278340149847, 0.03702761587184404, 0.022140223923370665, 0.023667135918085884, 0.0500063678269234, 0.07329177574633047, 0.050388095825602205, 0.012597023956400551, 0.024430591915443493, 0.9894697221913356, 0.9976920971325, 0.07540586492793415, 0.9174380232898656, 0.051553344986956955, 0.9279602097652252, 0.17506393828241096, 0.07932584703421747, 0.40893841833156935, 0.04376598457060274, 0.047869045624096745, 0.042398297552771406, 0.08206122106988013, 0.04376598457060274, 0.04650135860626541, 0.02872142737445805, 0.9963458213516387, 0.96168547942459, 0.10610571816206114, 0.10235741833568397, 0.2739142180814078, 0.06573941233953788, 0.15137364683446222, 0.07784930408629485, 0.031139721634517944, 0.05593616663978223, 0.08015595013329618, 0.0553595051280319, 0.10532916105842278, 0.004388715044100949, 0.8733542937760889, 0.008777430088201898, 0.004388715044100949, 0.004388715044100949, 0.09781512890324622, 0.004657863281106962, 0.8803361601292159, 0.009315726562213925, 0.004657863281106962, 1.001650523218673, 0.9401134255880731, 0.027650394870237443, 0.7858294788516474, 0.20991335393982363, 0.05331589450834905, 0.8797122593877593, 0.026657947254174526, 0.026657947254174526, 0.9935276019309662, 0.9980229485897593, 0.9733940752296383, 0.9956032965509998, 0.327361646942729, 0.30359429449346237, 0.09462096918481619, 0.06995673551104895, 0.06412700755179486, 0.06681765122529675, 0.01210789653075847, 0.026457996122768508, 0.017489183877762236, 0.017937624490012547, 0.9912238445649023, 0.9978237952168937, 0.9664370667731469, 0.9780901561655563, 0.04111986645678028, 0.02990535742311293, 0.20933750196179052, 0.026167187745223815, 0.0037381696778891163, 0.4971765671592525, 0.007476339355778233, 0.0037381696778891163, 0.16821763550501023, 0.014952678711556465, 0.3183812260709205, 0.05814746943211423, 0.09723019478812543, 0.03812948815220605, 0.10008990639954089, 0.035269776540790596, 0.2211510312827951, 0.05624099502450393, 0.05528775782069877, 0.020017981279908177, 0.9660799899484549, 0.5535496273419794, 0.22864784219232373, 0.013955032622066708, 0.01037681912922909, 0.010018997779945329, 0.021111459607741943, 0.09339137216306181, 0.04186509786620012, 0.012165925875647899, 0.01467067532063423, 0.012513464650191281, 0.9854353412025635, 0.07620475741799945, 0.9144570890159934, 0.7337543232897875, 0.05888151977016814, 0.15852716861199115, 0.02264673837314159, 0.013588043023884954, 0.05752980533657581, 0.8629470800486372, 0.05752980533657581, 0.9876405373468332, 0.967721838344434, 0.2534242502481454, 0.6476397506341494, 0.08447475008271513, 0.9818590378715302, 0.01059499539553691, 0.8899796132251004, 0.08475996316429528, 0.98185205098475, 0.10520945604896012, 0.8592105577331742, 0.035069818682986705, 0.02357710058546922, 0.008420393066239006, 0.45470122557690634, 0.0067363144529912055, 0.3822858452072509, 0.010104471679486807, 0.026945257811964822, 0.010104471679486807, 0.03536565087820383, 0.04378604394444283, 0.21966052862280208, 0.174412105123723, 0.11929129831575394, 0.09625573726167731, 0.09872383308889982, 0.07280882690306362, 0.0732201762076007, 0.07116342968491528, 0.04689382071722741, 0.02756040340398453, 0.1018297022696423, 0.014547100324234615, 0.06546195145905577, 0.6327988641042058, 0.13819745308022885, 0.007273550162117308, 0.021820650486351924, 0.014547100324234615, 0.007273550162117308, 0.19737432323139084, 0.26786515295688756, 0.09378345172174782, 0.16672613639421835, 0.05639266378039738, 0.08887974182780023, 0.027583368153455242, 0.04842413520273254, 0.025131513206481444, 0.02819633189019869, 0.15046324369130581, 0.19296698484704192, 0.148338056633519, 0.16661466533048552, 0.09265815571950471, 0.05525486350245693, 0.045904040448194995, 0.043353815978850824, 0.0697061354954072, 0.03442803033614624, 0.1483396055364333, 0.29101739406765925, 0.14267778853122592, 0.13871451662758078, 0.043029809239576076, 0.06907416746353001, 0.02661053992447468, 0.07020653086457149, 0.04416217264061755, 0.02661053992447468, 0.9899573261533583, 0.0026422251007577114, 0.980265512381111, 0.013211125503788558, 0.9949716477363116, 0.1694873540033355, 0.8232242908733438, 0.9903976812763873, 0.9605237927830087, 0.012287189635761515, 0.007372313781456909, 0.162190903192052, 0.6413912989867511, 0.1671057790463566, 0.002457437927152303, 0.002457437927152303, 0.002457437927152303, 0.002457437927152303, 0.002457437927152303, 0.9732259407905611, 0.7147229673609296, 0.002686928448725299, 0.006717321121813247, 0.13972027933371553, 0.12897256553881434, 0.004030392673087948, 0.0013434642243626495, 0.0013434642243626495, 0.0013434642243626495, 0.0013434642243626495, 0.012420439645923242, 0.624127092207643, 0.012420439645923242, 0.021735769380365675, 0.006210219822961621, 0.16457082530848297, 0.012420439645923242, 0.11488906672478999, 0.024840879291846484, 0.006210219822961621, 0.9847323456440273, 0.995454644714307, 0.997946396672858, 0.963793048350605, 0.9911493610571701, 0.9784675576408571, 0.9843325761598726, 0.979000448243334, 0.2899512952543115, 0.04011904714210599, 0.009117965259569543, 0.007294372207655635, 0.44678029771890765, 0.0838852803880398, 0.00820616873361259, 0.10303300743313586, 0.0036471861038278176, 0.00820616873361259, 0.03682773748781579, 0.023259623676515236, 0.16087906376256372, 0.091100192733018, 0.1860769894121219, 0.03488943551477285, 0.3799071867164155, 0.023259623676515236, 0.0426426434069446, 0.0213213217034723, 0.9629574760570275, 0.9862570531249307, 0.9959506946848018, 0.9146486366991624, 0.06692551000237774, 0.9804470699901426, 0.03851309321057085, 0.0038513093210570852, 0.0038513093210570852, 0.0077026186421141705, 0.0077026186421141705, 0.0038513093210570852, 0.4159414066741652, 0.0038513093210570852, 0.5160754490216494, 0.0077026186421141705, 0.9948296857075793, 0.13458447246648889, 0.11963064219243458, 0.009969220182702881, 0.024923050456757204, 0.009969220182702881, 0.633045481601633, 0.004984610091351441, 0.05483071100486585, 0.004984610091351441, 0.009969220182702881, 0.9883189895998581, 0.23318905016586464, 0.7609326900149267, 0.001530529436960132, 0.006122117747840528, 0.9902525457132054, 0.4846986020848708, 0.19653827675346505, 0.010779064538581264, 0.012575575295011474, 0.03054068285931358, 0.014372086051441685, 0.13976853685027038, 0.054973229146764446, 0.02155812907716253, 0.034133704372174, 0.6084119128621706, 0.23319965210441918, 0.005979478259087671, 0.010464086953403425, 0.011958956518175343, 0.016443565212491094, 0.0672691304147363, 0.022423043471578766, 0.0044846086943157535, 0.017938434777263014, 0.9816092293920167, 0.0713611908312276, 0.9158019490007542, 0.9831080001469903, 0.35940264655718784, 0.6346897800903529, 0.9647981306857536, 0.994136836725188, 0.023557655528791792, 0.9776427044448593, 0.9986166557367604, 0.1067454200375666, 0.040664921919072984, 0.0025415576199420615, 0.010166230479768246, 0.007624672859826185, 0.02795713381936268, 0.0025415576199420615, 0.022874018579478555, 0.7751750740823288, 0.0025415576199420615, 0.9232284384354971, 0.2620893468110987, 0.07705426796246301, 0.08386859097955157, 0.11322259782239462, 0.08648948444766257, 0.046651903732375564, 0.16092285894201458, 0.06814323017088565, 0.05241786936221973, 0.04927279720048655, 0.9892018809810864, 0.05790488043341376, 0.14338351345416742, 0.013786876293669944, 0.022059002069871908, 0.03860325362227584, 0.15992776500657135, 0.5294160496769258, 0.01654425155240393, 0.008272125776201966, 0.008272125776201966, 0.9765948517230947, 0.9986592810816407, 0.003831899070891937, 0.18632609232212044, 0.005268861222476414, 0.04119291501208832, 0.0023949369193074607, 0.7160861388729307, 0.02299139442535162, 0.0023949369193074607, 0.014369621515844764, 0.004310886454753429, 0.747198102864495, 0.21348517224699856, 0.9979790780969567, 0.9809451829170918, 0.9962773953635952, 0.0017139737522649948, 0.9975327238182269, 0.02756891245795511, 0.9649119360284288, 0.07978821513285907, 0.058306772597089315, 0.018412665030659782, 0.09206332515329892, 0.006137555010219928, 0.2362958678934672, 0.4910044008175942, 0.006137555010219928, 0.003068777505109964, 0.009206332515329891, 0.9300129582481234, 0.060000836016007954, 0.9990052003807348, 0.9361164470249735, 0.034670979519443465, 0.16013342820471813, 0.8273560457243769, 0.9605330428956903, 0.258814352511185, 0.14531789464767356, 0.013258931993400872, 0.060991087169644013, 0.02916965038548192, 0.031291079504426056, 0.3537483055839353, 0.019092862070497256, 0.031291079504426056, 0.05674822893175573, 0.9988781629528564, 0.9954799855311949, 0.8708049679394093, 0.1182574647818951, 0.9862505367021169, 0.99138171303519, 0.034742420644208065, 0.9033029367494096, 0.017371210322104032, 0.034742420644208065, 0.9849367363187757, 0.3340854677668507, 0.10218039572656339, 0.06130823743593804, 0.040872158290625356, 0.03287543166854648, 0.0506459352731662, 0.23901327348213525, 0.08618694248240565, 0.02487870504646761, 0.02665575540692958, 0.05680724691627567, 0.12822207161102223, 0.058430311113883554, 0.3229897753239674, 0.33759735310243827, 0.003246128395215753, 0.003246128395215753, 0.08115320988039382, 0.003246128395215753, 0.004869192592823629, 0.020373580720504665, 0.9575582938637193, 0.9969550184956518, 0.2828684615970851, 0.16473143872515073, 0.08328293227307175, 0.05686720045077586, 0.12290653000651558, 0.05650031528657731, 0.11410128606575028, 0.0462275306890178, 0.04292556421123081, 0.02971769830008287, 0.24144482769499856, 0.14149789902125498, 0.1081822561300071, 0.07074894951062749, 0.0898399358865111, 0.07299494790779026, 0.11192558679194507, 0.0786099439006972, 0.05053496393616249, 0.034438642089829254, 0.9900332427000683, 0.1549201066747182, 0.19560056634110104, 0.21287583003504446, 0.06798652163422886, 0.11981231271605905, 0.13040037756073403, 0.008916265132357883, 0.07021558791731833, 0.022290662830894706, 0.0172752636939434, 0.9663393115427941, 0.0161056551923799, 0.16776644100032637, 0.4331424476735699, 0.04575448390917992, 0.11489459292749625, 0.02135209249095063, 0.06812334270922343, 0.02846945665460084, 0.06100597854557323, 0.027452690345507954, 0.032536521890972385, 0.9935346799503876, 0.9355304676411734, 0.2461602532774513, 0.09212360993868254, 0.13240437865681093, 0.08988578945434207, 0.0872749988892782, 0.08913984929289524, 0.08951281937361866, 0.09398846034229959, 0.03319433718438359, 0.046621260090426386, 0.08604012936752062, 0.10296605645621319, 0.4964938612683157, 0.03808333594955831, 0.11425000784867492, 0.0465462994939046, 0.026799384557096587, 0.04090432379767374, 0.02256790278492344, 0.025388890633038872, 0.9804225404021647, 0.9760654952905893, 0.9672794732336802, 0.07826008373892193, 0.1481946266545543, 0.20480830425292335, 0.08991584089152732, 0.1981478715942917, 0.0865856245622115, 0.03746493370480305, 0.07035081995679685, 0.04537419748692814, 0.04079515003411888, 0.00887294435040649, 0.6033602158276413, 0.023661184934417306, 0.002957648116802163, 0.002957648116802163, 0.2809765710962055, 0.01774588870081298, 0.053237666102438935, 0.002957648116802163, 0.002957648116802163, 0.9947090064367052, 0.1356999159009869, 0.030840889977497024, 0.5674723755859452, 0.006168177995499405, 0.04934542396399524, 0.006168177995499405, 0.20971805184697975, 0.025130178040678502, 0.0083767260135595, 0.00418836300677975, 0.00418836300677975, 0.7120217111525575, 0.012565089020339251, 0.14659270523729126, 0.00418836300677975, 0.0753905341220355, 0.012565089020339251, 0.8453797274537671, 0.019213175623949252, 0.09606587811974626, 0.02881976343592388, 0.06328791482303256, 0.9240035564162753, 0.9741178629857291, 0.029260935176893793, 0.2633484165920441, 0.007980255048243762, 0.0345811052090563, 0.002660085016081254, 0.6517208289399071, 0.002660085016081254, 0.002660085016081254, 0.002660085016081254, 0.002660085016081254, 0.9718033003901362, 0.9986418640580239, 0.9799986867577489, 0.9967513380647842, 0.9969550184956518, 0.7572131150163047, 0.21473207739268343, 1.0084324427687499, 0.9963329099909007, 0.9718818394133847, 0.9535236758534612, 0.9974602873572859, 1.0010698471358037, 0.9800007793110777, 0.18010802608691437, 0.060036008695638125, 0.0066706676328486805, 0.08671867922703284, 0.008894223510464906, 0.004447111755232453, 0.004447111755232453, 0.015564891143313588, 0.05114178518517321, 0.5847951958130676, 0.2077668475444114, 0.04439462554367765, 0.02042152775009172, 0.0435067330328041, 0.12785652156579164, 0.03906727047843633, 0.1624843294898602, 0.10033185372871149, 0.21309420260965273, 0.04173094801105699, 0.15321173102866506, 0.01056632627783897, 0.7924744708379228, 0.01056632627783897, 0.026415815694597423, 0.9836297004902127, 0.9968844982332989, 0.9995347892230921, 0.9945463887835525, 1.0038199810574917, 0.05093887067054301, 0.008305250652805926, 0.004429467014829827, 0.2380838520471032, 0.004983150391683555, 0.0038757836379760984, 0.0038757836379760984, 0.5370728755481166, 0.04374098677144454, 0.10519984160220838, 0.9939223203912303, 0.9859195089345592, 0.9974273435368967, 0.9796126326376972, 0.9916152120488644, 0.9945310022831493, 0.992038686909926, 0.9724499539756302, 0.9997596547739063, 0.04655219371980586, 0.9543199712560201, 0.09807959770622919, 0.2503610783553745, 0.005162084089801537, 0.08001230339192382, 0.0025810420449007684, 0.5136273669352529, 0.005162084089801537, 0.038715630673511525, 0.0025810420449007684, 0.005162084089801537, 0.013248269494110973, 0.16560336867638714, 0.03312067373527743, 0.31133433311160785, 0.006624134747055486, 0.013248269494110973, 0.006624134747055486, 0.03312067373527743, 0.03312067373527743, 0.39744808482332916, 0.07531830997628763, 0.012553051662714605, 0.02510610332542921, 0.03765915498814382, 0.8410544614018786, 0.9610993702306331, 0.9950599282524264, 0.1800072301923768, 0.12857659299455487, 0.04071592111494237, 0.41358804079915146, 0.006428829649727743, 0.08571772866303658, 0.04071592111494237, 0.04285886433151829, 0.02571531859891097, 0.03428709146521463, 0.022576754800812754, 0.057696151157632596, 0.5945212097547359, 0.04013645297922268, 0.06020467946883401, 0.05518762284643118, 0.025085283112014172, 0.05267909453522976, 0.025085283112014172, 0.06773026440243826, 0.9452011106754701, 0.9713897080855508, 0.9463164768173296, 0.9972617996689084, 0.9625074556941281, 0.9995191072809768, 0.9735019730329806, 0.9698554501744767, 0.9885850981639623, 0.9947340695869706, 0.9976341900925492, 0.24734517570707437, 0.2400164297601981, 0.1771113603828434, 0.053133408114853016, 0.08061620541563906, 0.08244839190235813, 0.023818424327347903, 0.029314983787505113, 0.03542227207656867, 0.03114717027422418, 0.9961596796346724, 0.9922052247628044, 0.9799949481845923, 0.026652579828435684, 0.9061877141668132, 0.03997886974265353, 0.013934142891399643, 0.013934142891399643, 0.8639168592667779, 0.0975390002397975, 0.31858156356198913, 0.010276824631031908, 0.05138412315515954, 0.6063326532308826, 0.2152407932059445, 0.47600710545320607, 0.09732487286217968, 0.06193401000320525, 0.09105103808263422, 0.01656935852033803, 0.0028956160520979077, 0.026704014702680707, 0.004182556519696978, 0.007882510364044306, 0.08744433287417437, 0.16725463668790494, 0.3483893262129804, 0.1429645442228565, 0.0596842271998333, 0.10548840156249606, 0.015268058120887587, 0.013880052837170535, 0.0208200792557558, 0.03817014530221897, 0.9870089717408217, 0.9579271433589853, 0.9032474687504831, 0.056452966796905195, 0.07696610489359737, 0.09154915634712107, 0.23008814515559634, 0.07453559631801009, 0.2673559433146014, 0.03726779815900504, 0.08020678299438042, 0.050230510562137225, 0.06724407059124822, 0.02430508575587285, 0.9874203148115026, 0.9606889236271435, 0.013306782144853885, 0.9647417055019067, 0.013306782144853885, 0.01373636398255226, 0.9066000228484491, 0.061813637921485164, 0.00686818199127613, 0.8110346677113681, 0.1840998938976725, 0.9689068564440281, 0.9484103365657373, 0.9855392344009682, 0.011923422499068375, 0.08743843165983475, 0.08346395749347862, 0.45309005496459825, 0.10731080249161538, 0.14705554415517663, 0.031795793330849004, 0.02384684499813675, 0.039744741663561255, 0.011923422499068375, 0.26236854441371926, 0.1282690661578183, 0.18074277504056216, 0.058304120980826504, 0.08904629386162594, 0.0662546829327574, 0.05406382127313003, 0.07367520742122621, 0.04452314693081297, 0.043463072003888846, 0.9782962603384604, 0.8059968826925972, 0.07383177551382569, 0.11074766327073854, 0.9602345095678669, 0.9383612084047639, 0.032357283048440134, 0.03598192477361323, 0.5360758843175372, 0.015159897239644152, 0.2878553981889058, 0.038356366509943035, 0.022465871812966633, 0.02009143007663683, 0.012785455503314344, 0.006027429022991048, 0.025205612277962565, 0.9789304632593506, 0.09431973538517605, 0.06549981623970559, 0.07597978683805848, 0.028819919145470458, 0.5318585078664094, 0.0995597206843525, 0.010479970598352895, 0.034059904444646905, 0.04977986034217625, 0.00785997794876467, 0.9909243054650249, 0.9788061161366057, 0.9777219342134124, 0.18519196674280475, 0.008547321541975603, 0.011396428722634138, 0.0028491071806585346, 0.0028491071806585346, 0.005698214361317069, 0.13390803749095112, 0.008547321541975603, 0.5869160792156581, 0.05413303643251216, 0.7507594822945104, 0.08917861253774571, 0.053921951767009035, 0.012443527330848239, 0.031108818327120594, 0.010369606109040199, 0.023850094050792456, 0.0031108818327120597, 0.01970225160717638, 0.004147842443616079, 0.025557417318620188, 0.9626627190013605, 0.9714538550821438, 0.9154211519938116, 0.9955864118471711, 0.06301219728651775, 0.013502613704253805, 0.002250435617375634, 0.004500871234751268, 0.002250435617375634, 0.002250435617375634, 0.03150609864325887, 0.009001742469502536, 0.002250435617375634, 0.8709185839243704, 0.9787622456653037, 0.7285173864381719, 0.0030974378675092343, 0.0068143633085203156, 0.028496428381084956, 0.08486979756975302, 0.0018584627205055406, 0.004336413014512928, 0.01920411477855725, 0.11460520109784167, 0.00805333845552401, 0.0810925103469236, 0.07028017563400045, 0.7676757646175434, 0.0594678409210773, 0.010812334712923146, 0.35660544788261084, 0.10850450460485134, 0.06694283763632641, 0.08597871563717752, 0.06440472056954626, 0.07233633640323422, 0.11009082777158893, 0.05805942790259589, 0.04727243036878026, 0.03014014016801426, 0.010275342104093855, 0.0565143815725162, 0.010275342104093855, 0.3031225920707687, 0.6113828551935844, 0.0051376710520469274, 0.0051376710520469274, 0.9549658276939578, 0.09232420772848351, 0.0083931097934985, 0.058751768554489506, 0.8141316499693546, 0.0083931097934985, 0.9368927213699485, 0.19408136930887776, 0.028967368553563844, 0.017380421132138307, 0.12455968478032453, 0.5011354759766545, 0.005793473710712769, 0.03186410540892023, 0.05503800025177131, 0.008690210566069154, 0.03186410540892023, 0.9652709925088511, 0.9914341779843282, 0.9966793083752484, 0.9839533505568759, 0.9811378690392406, 0.0776452175543631, 0.9123313062637664, 1.0020524941398443, 0.9835388200059249, 0.05065822702531721, 0.9371771999683683, 0.012938592392157233, 0.08625728261438155, 0.6728068043921761, 0.008625728261438155, 0.08194441848366248, 0.06469296196078617, 0.0043128641307190775, 0.008625728261438155, 0.047441505437909856, 0.012938592392157233, 0.1256663972835117, 0.7878316445081696, 0.02416661486221379, 0.0579998756693131, 0.9392175078771972, 0.9283458704918363, 0.04641729352459181, 0.047559976543148974, 0.06539496774682983, 0.6688121701380324, 0.008917495601840433, 0.12781743695971287, 0.014862492669734054, 0.014862492669734054, 0.011889994135787244, 0.02972498533946811, 0.011889994135787244, 0.2621693144142039, 0.1498110368081165, 0.10659631465192905, 0.04782429251951412, 0.1740112812155815, 0.0616530036094941, 0.09449619244819657, 0.032843188838702464, 0.05416245176908828, 0.017862085157890815, 0.06278922347660248, 0.005023137878128199, 0.5625914423503583, 0.0025115689390640995, 0.07032393029379479, 0.0025115689390640995, 0.09292805074537168, 0.010046275756256398, 0.025115689390640995, 0.16576354997823056, 0.9828119471362436, 0.024765551700136855, 0.04457799306024634, 0.46229029840255464, 0.0908070229005018, 0.17005678834093974, 0.03797384594020985, 0.05118214018028283, 0.024765551700136855, 0.06604147120036495, 0.029718662040164226, 0.9934671037959453, 0.9688000939847332, 0.019252923833267068, 0.05134113022204551, 0.7893698771639498, 0.0641764127775569, 0.038505847666534136, 0.006417641277755689, 0.019252923833267068, 0.1521902677256327, 0.05073008924187757, 0.06917739442074214, 0.17986122549392958, 0.013835478884148428, 0.009223652589432285, 0.01844730517886457, 0.4796299346504788, 0.01844730517886457, 0.009223652589432285, 0.04297850980293266, 0.9455272156645186, 0.9757206819080467, 0.9779272097597916, 0.9946398084683461, 0.9647976219820694, 0.30861105615997336, 0.035269834989711236, 0.008817458747427809, 0.6260395710673745, 0.008817458747427809, 0.9838984212737302, 0.42495378878190454, 0.0037942302569812904, 0.0037942302569812904, 0.2466249667037839, 0.0037942302569812904, 0.018971151284906455, 0.2921557297875594, 0.9942493770854628, 0.9947824324298006, 0.010750407539448278, 0.154537108379569, 0.06047104240939656, 0.27682299414079314, 0.03225122261834484, 0.0927222650277414, 0.012094208481879313, 0.27279159131350006, 0.030907421675913798, 0.0577834405245345, 0.06624798789278408, 0.9274718304989771, 0.9835947305759211, 0.9577501898097027, 0.9450764114855791, 0.9984359909737961, 0.9975590251894852, 0.21163256369765443, 0.07364241236776488, 0.09080180942433146, 0.17302392032037964, 0.04289849264141644, 0.08150713601869124, 0.1830335686033768, 0.06363276408476772, 0.04504341727348726, 0.03431879411313315, 0.9733533079668413, 0.10566957021221689, 0.07306520468205331, 0.2608349242413086, 0.1257035779476186, 0.09545615450397288, 0.09938439131483595, 0.05106707854122006, 0.13159593316391321, 0.026319186632782644, 0.031033070805818342, 0.1895253584197679, 0.11883123699693424, 0.21208236426850102, 0.08929783758673727, 0.12348216603791012, 0.058601705916296334, 0.033719235547075274, 0.14092314994156976, 0.017440983903659623, 0.016510798095464442, 0.18681640630864743, 0.11330244520544742, 0.19212153752228042, 0.0503987465295134, 0.14892261192555464, 0.06745095400190515, 0.08563997530578969, 0.04850405681035876, 0.06593520222658145, 0.04092529793374021, 0.2703113203055845, 0.10188657457672032, 0.1918170715245398, 0.07563518673935106, 0.09876759780396357, 0.05198294621261241, 0.08031365189848617, 0.05796098502706284, 0.0410665275079638, 0.029890194072252137, 0.08276686243413478, 0.8897437711669488, 0.6123670099392046, 0.2424952041099548, 0.015988694776480537, 0.020252346716875345, 0.015988694776480537, 0.019719390224325995, 0.03997173694120134, 0.012257999328635078, 0.010659129850987024, 0.010126173358437672, 0.3522604183354866, 0.15663007886702887, 0.07831503943351444, 0.06950852897512727, 0.027992122528444918, 0.07516985712694758, 0.09341191450503529, 0.049379362213099465, 0.04623417990653262, 0.0506374351357262, 0.9018224724997602, 0.09749432135132542, 0.06964296603922508, 0.08189496932390357, 0.4346236954670158, 0.04578380174800908, 0.15669667358825642, 0.0786707579331987, 0.0406250635228813, 0.03933537896659935, 0.03224211390704865, 0.01999011062237016, 0.3246146259335529, 0.12361324955549695, 0.11634188193458536, 0.07998504383002744, 0.04882203974040636, 0.1049154471017243, 0.08206257743600218, 0.049860806543393726, 0.03220177089260845, 0.03687622150605161, 0.9963259674552651, 1.0003947006151468, 0.965830953547728, 0.9837633256622776, 0.9644571111646096, 0.9894112881893491, 0.04179522758778534, 0.11177793424640266, 0.3683811919946662, 0.07484261684324352, 0.2284157786774315, 0.06803874258476683, 0.010691802406177646, 0.046655137772411544, 0.027215497033906733, 0.02235558684928053, 0.9884311971327909, 0.016357164669483865, 0.05888579281014191, 0.6575580197132513, 0.0065428658677935455, 0.07851439041352255, 0.009814298801690319, 0.019628597603380638, 0.1341287502897677, 0.016357164669483865, 0.0032714329338967727, 0.9929373019854754, 0.9912811606474987, 0.6113924810012289, 0.08399079875140646, 0.07869408171302947, 0.019673520428257367, 0.0499404749332687, 0.07415403853727777, 0.014376803389880384, 0.04313041016964115, 0.012863455664629816, 0.012106781802004533, 0.04609053925428691, 0.0020039364893168223, 0.9398462134895896, 0.00801574595726729, 0.0020039364893168223, 0.19597248516153204, 0.012248280322595752, 0.7226485390331494, 0.024496560645191505, 0.024496560645191505, 0.9909873283105893, 0.008040465138422631, 0.9974881230857287, 0.9560246581796578, 0.03640258565030571, 0.014561034260122285, 0.17618851454747966, 0.07426127472662365, 0.17036410084343073, 0.005824413704048914, 0.20676668649373645, 0.016017137686134515, 0.2460814789960666, 0.05533193018846468, 0.9689139614565747, 1.0004142720160791, 0.9780223341107972, 0.044114473479741845, 0.16542927554903192, 0.011028618369935461, 0.7830319042654177, 0.9537187540526648, 0.9975695016709085, 0.19311310125063835, 0.1415098758475752, 0.10054649073380344, 0.15321370016579572, 0.018087728491795328, 0.09522657058915775, 0.08618270634326008, 0.07128692993825217, 0.07501087403950416, 0.06543501777914192, 0.21714644081959417, 0.14046861750347636, 0.16237656702236716, 0.07152301166461411, 0.1707531359560607, 0.038661087386277895, 0.061857739818044634, 0.038661087386277895, 0.06507949710023446, 0.03415062719121214, 0.04602376370487712, 0.0862945569466446, 0.8658220546980008, 0.11936262487219029, 0.12413712986707791, 0.7448227792024674, 0.9810756408907636, 0.021965073708270444, 0.010982536854135222, 0.565600647987964, 0.05674310707969865, 0.197685663374434, 0.021965073708270444, 0.027456342135338055, 0.023795496517292982, 0.06589522112481133, 0.007321691236090148, 0.02251536264817626, 0.03403485051468504, 0.10734068239246822, 0.02827510658143065, 0.47282261561170147, 0.015184779460397943, 0.23457866200890615, 0.012566714036191402, 0.05288492156897215, 0.01937368413912841, 0.9600668888395906, 0.9967285064312532, 0.5257974464745455, 0.2729263693972351, 0.01569544616341927, 0.011335600006913917, 0.022671200013827834, 0.054062092340666376, 0.020927261551225693, 0.03226286155813961, 0.029646953864236398, 0.014823476932118199, 0.007019230164361384, 0.007019230164361384, 0.28076920657445537, 0.021057690493084154, 0.12283652787632422, 0.003509615082180692, 0.003509615082180692, 0.007019230164361384, 0.547499952820188, 0.003509615082180692, 0.5992029109540576, 0.1483794684620579, 0.050312578386559864, 0.01051731864577805, 0.0210346372915561, 0.07049446011224207, 0.01733936317276922, 0.0642409192958335, 0.01051731864577805, 0.0076748000928650644, 0.012973364787917076, 0.10378691830333661, 0.3081174137130306, 0.44758108518313916, 0.006486682393958538, 0.029190070772813423, 0.006486682393958538, 0.006486682393958538, 0.055136800348647576, 0.022703388378854883, 0.0006746651987334497, 0.016191964769602794, 0.014167969173402444, 0.9674698949837669, 0.0006746651987334497, 0.03551716228370083, 0.03551716228370083, 0.0050738803262429764, 0.050738803262429764, 0.01522164097872893, 0.8168947325251191, 0.010147760652485953, 0.020295521304971906, 0.0050738803262429764, 0.0050738803262429764, 0.4490589404337568, 0.3098552936051669, 0.016186470561463943, 0.07029552929550055, 0.00832447057446717, 0.04208482345980625, 0.021273647023638324, 0.05225917638415502, 0.0064745882245855774, 0.024510941135931115, 0.9361400169767561, 0.04680700084883781, 0.297360378155851, 0.17632643214219568, 0.10710198100488923, 0.11493871132232016, 0.01697958235443366, 0.065306085978591, 0.10318361584617378, 0.07444893801559374, 0.02351019095229276, 0.02046257360662518, 0.173790678094239, 0.08146438035667453, 0.32246317224517, 0.027833663288530465, 0.10861917380889938, 0.05363071706814407, 0.09368403741017571, 0.06652924395795087, 0.05702506624967217, 0.014256266562418043, 0.9774186009940251, 0.11048857265633347, 0.056236698657415235, 0.2600120302631081, 0.15613953980176465, 0.08005459455937934, 0.06880725482789629, 0.10321088224184444, 0.06946886304739529, 0.029110761657956123, 0.06616082194990028, 0.2548893212474767, 0.14102858253453202, 0.04548324415074734, 0.12484997891044068, 0.08119827479260934, 0.07600891136601401, 0.13797601581300534, 0.07906147808754067, 0.027778357165892668, 0.031746693903877334, 0.564061428151782, 0.1863769404207811, 0.01479182066831596, 0.019722427557754614, 0.006902849645214115, 0.0384587337376215, 0.12918190050329273, 0.022680791691417807, 0.008875092400989576, 0.009861213778877307, 0.4456956464544886, 0.20039321614507488, 0.02075635948771962, 0.02037897113339745, 0.02075635948771962, 0.06943945719528019, 0.07547767086443499, 0.07132639896689107, 0.02377546632229702, 0.05207959289646014, 0.9835260507852635, 0.041521948292123245, 0.09342438365727729, 0.6557007667797795, 0.029411380040253964, 0.03979186711328477, 0.07958373422656954, 0.013840649430707747, 0.029411380040253964, 0.008650405894192342, 0.01211056825186928, 0.17383733447240463, 0.8039976719348714, 0.0802410274543694, 0.9093983111495199, 0.02194340893014052, 0.07523454490333893, 0.17241249873681838, 0.49842885998462044, 0.009404318112917366, 0.02194340893014052, 0.16300818062390102, 0.012539090817223155, 0.009404318112917366, 0.018808636225834733, 0.11486016963004582, 0.02901730601180105, 0.0846338092010864, 0.15475896539627226, 0.018135816257375658, 0.11244206079572908, 0.33007185588423693, 0.0628708296922356, 0.051989339937810214, 0.04352595901770158, 0.991845374755121, 0.004087991770978227, 0.004087991770978227, 0.126727744900325, 0.008175983541956453, 0.04087991770978226, 0.686782617524342, 0.02043995885489113, 0.09811180250347742, 0.008175983541956453, 0.004087991770978227, 0.9736615276860531, 0.9631736070689759, 0.4825984596123847, 0.13873413962090503, 0.04185275720407191, 0.03126039272649815, 0.023768232486263058, 0.07182139816501229, 0.10204838947906422, 0.06174573439366164, 0.018859575777143513, 0.02738513742982483, 0.0189341035534386, 0.9467051776719301, 0.9826271507869864, 0.9575564351894494, 0.045313632358068914, 0.9364817354000908, 0.3382272787786914, 0.5178666633582454, 0.011227461536222122, 0.009824028844194355, 0.00842059615216659, 0.015437759612305417, 0.0028068653840555304, 0.08701282690572144, 0.004210298076083295, 0.005613730768111061, 0.2650825966913715, 0.04938801231132017, 0.018142535134770675, 0.152195711408354, 0.005039593092991854, 0.10583145495282893, 0.22073417747304322, 0.1622748975943377, 0.007055430330188596, 0.01209502342318045, 0.9978647641159168, 0.9004136294645497, 0.05541006950551075, 0.027705034752755375, 0.004246249089032196, 0.004246249089032196, 0.016984996356128785, 0.8704810632516002, 0.09341747995870832, 0.004246249089032196, 0.004246249089032196, 0.9998292405862649, 0.4082468258226607, 0.13094709507519303, 0.01636838688439913, 0.02840396547586908, 0.0481423143658798, 0.07654627984174887, 0.15068544396520375, 0.036588158918068645, 0.03177392748148067, 0.0722134715488197, 0.9443893327266933, 0.026233037020185927, 0.9688680666156773], \"Term\": [\"aberforth\", \"ability\", \"abou\", \"about\", \"about\", \"about\", \"about\", \"about\", \"about\", \"about\", \"about\", \"about\", \"about\", \"advanced_potion\", \"again\", \"again\", \"again\", \"again\", \"again\", \"again\", \"again\", \"again\", \"again\", \"again\", \"aimed\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"ajar\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"albus\", \"alecto\", \"alicia\", \"all_righ\", \"along\", \"along\", \"along\", \"along\", \"along\", \"along\", \"along\", \"along\", \"along\", \"along\", \"am\", \"am\", \"am\", \"am\", \"am\", \"am\", \"am\", \"am\", \"am\", \"am\", \"an\", \"an\", \"an\", \"an\", \"an\", \"an\", \"an\", \"an\", \"an\", \"an\", \"angelina\", \"angelina\", \"antidote\", \"antidote\", \"antidote\", \"apparate\", \"appears\", \"archway\", \"are\", \"are\", \"are\", \"are\", \"are\", \"are\", \"are\", \"are\", \"are\", \"are\", \"ariana\", \"ariana\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"arrow\", \"art\", \"art\", \"arthur\", \"arthur\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"atrium\", \"aunt\", \"aunt_marge\", \"aunt_petunia\", \"auntie_muriel\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"bagman\", \"bagman\", \"bagman\", \"bagshot\", \"bane\", \"baron\", \"barty\", \"barty_crouch\", \"basin\", \"basin\", \"bay\", \"beater\", \"because\", \"because\", \"because\", \"because\", \"because\", \"because\", \"because\", \"because\", \"because\", \"because\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"been\", \"been\", \"been\", \"been\", \"been\", \"been\", \"been\", \"been\", \"been\", \"been\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"bella\", \"bertha_jorkins\", \"bezoar\", \"bidding\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bin\", \"bin\", \"bin\", \"bin\", \"bin\", \"blackness\", \"blasted\", \"blinding\", \"blindly\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"blood\", \"bloodshot\", \"bludger\", \"bludger\", \"bludger\", \"boat\", \"boat\", \"bode\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"borgin\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"broom\", \"bunk\", \"burke\", \"bus\", \"bus\", \"bust\", \"by\", \"by\", \"by\", \"by\", \"by\", \"by\", \"by\", \"by\", \"by\", \"by\", \"cabin\", \"cabin\", \"cabin\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"car\", \"car\", \"car\", \"car\", \"cattermole\", \"cattermole\", \"cattermole\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cauldron\", \"cave\", \"cavern\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"cedric\", \"centaur\", \"centaur\", \"centaur\", \"chang\", \"chaser\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate_frog\", \"circular\", \"circular\", \"circular\", \"class\", \"class\", \"class\", \"class\", \"class\", \"cliff\", \"climbed\", \"climbed\", \"clipboard\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"cloak\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common_room\", \"common_room\", \"common_room\", \"common_room\", \"common_room\", \"companion\", \"confess\", \"confided\", \"confidently\", \"confunded\", \"connection\", \"connection\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"corridor\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"crabbe\", \"crabbe\", \"crabbe\", \"crabbe\", \"crabbe\", \"crabbe\", \"creaked\", \"creaking\", \"create\", \"crouch\", \"crown\", \"cruciatus\", \"cruciatus_curse\", \"cubicle\", \"dagger\", \"dais\", \"dance_floor\", \"dark_art\", \"dark_art\", \"dark_lord\", \"dark_lord\", \"dark_lord\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"davy\", \"dean_thomas\", \"dean_thomas\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death_eater\", \"death_eater\", \"death_eater\", \"death_eater\", \"deathly_hallows\", \"dedalus\", \"defense_against\", \"defense_against\", \"defensive\", \"deny\", \"deserted\", \"deserted\", \"deserted\", \"deserted\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"desperation\", \"destroy\", \"destroy\", \"destroyed\", \"detached\", \"diary\", \"diary\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"did_not\", \"didn\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"diggle\", \"diggory\", \"diggory\", \"diggory\", \"diggory\", \"dippet\", \"dirk\", \"discussed\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"do_not\", \"dobby\", \"dobbys\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"don\", \"don\", \"door\", \"door\", \"door\", \"door\", \"door\", \"door\", \"door\", \"door\", \"door\", \"door\", \"dot\", \"down\", \"down\", \"down\", \"down\", \"down\", \"down\", \"down\", \"down\", \"down\", \"down\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"dragon\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"dudley\", \"dudley\", \"dudleys\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dumbledore\", \"dursley\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"dursleys\", \"eater\", \"eater\", \"eater\", \"eater\", \"elder\", \"elder_wand\", \"elf\", \"elf\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"entrance\", \"ernie\", \"ernie\", \"ernie\", \"ernie\", \"ernie\", \"exchange\", \"expelliarmus\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eyelid\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"faithful\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"felicis\", \"felix\", \"felix\", \"felix_felicis\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fell\", \"fer\", \"field\", \"field\", \"field\", \"fir\", \"firenze\", \"firenze\", \"firenze\", \"firstly\", \"flash\", \"flash\", \"flash\", \"flash\", \"fletcher\", \"fleurs\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flew\", \"flitwick\", \"flitwick\", \"flitwick\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"flustered\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"foot\", \"footprint\", \"for_instance\", \"fragile\", \"fragment\", \"frail\", \"frank\", \"frank\", \"freak\", \"fred\", \"fred\", \"fred\", \"fred\", \"fred\", \"fred\", \"fred\", \"fred_george\", \"freds\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front\", \"front_door\", \"front_door\", \"frustrated\", \"gabrielle\", \"gate\", \"gate\", \"gate\", \"gate\", \"generally\", \"george\", \"george\", \"george\", \"george\", \"gilderoy\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"ginny\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblet\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"goblin\", \"godrics\", \"godrics\", \"godrics_hollow\", \"godrics_hollow\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"goyle\", \"goyle\", \"goyle\", \"goyle\", \"goyle\", \"goyle\", \"gracefully\", \"graf\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"great_hall\", \"green_light\", \"gregorovitch\", \"greyback\", \"greyback\", \"grille\", \"grimy\", \"grindelwald\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"gringotts\", \"griphook\", \"griphook\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"growled_moody\", \"grubbly\", \"grudgingly\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"gryffindor\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"had_been\", \"hagrid\", \"hagrid\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hagrids\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hall\", \"hallows\", \"hallway\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"harrys\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"hat\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"headless\", \"headless\", \"headless\", \"headless\", \"headquarters\", \"heaven_sake\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her\", \"her_husband\", \"here\", \"here\", \"here\", \"here\", \"here\", \"here\", \"here\", \"here\", \"here\", \"here\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hermione\", \"hind\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hoisting\", \"hooch\", \"horace\", \"horace\", \"horcruxes\", \"horcruxes\", \"horcruxes\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital_wing\", \"hospital_wing\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house_elf\", \"house_elf\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"imperius\", \"imperius_curse\", \"in_midair\", \"in_midair\", \"ingredient\", \"ingredient\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"inside\", \"instance\", \"inter\", \"into\", \"into\", \"into\", \"into\", \"into\", \"into\", \"into\", \"into\", \"into\", \"into\", \"invisibility\", \"invisibility\", \"invisibility\", \"invisibility\", \"invisibility\", \"invisibility\", \"invisibility_cloak\", \"invisibility_cloak\", \"invisibility_cloak\", \"invisibility_cloak\", \"invisibility_cloak\", \"invited\", \"iron\", \"iron\", \"james\", \"james\", \"jet\", \"jet\", \"jet\", \"jet\", \"joke_shop\", \"jordan\", \"jorkins\", \"jus\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"katie\", \"katie_bell\", \"kendra\", \"kissing\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knew\", \"knocker\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kreacher\", \"kreacher\", \"kreachers\", \"kreachers\", \"krum\", \"krum\", \"krum\", \"krum\", \"krum\", \"lamp\", \"lamp\", \"lamp\", \"lane\", \"latter\", \"lavender\", \"lavender\", \"lavender\", \"leader\", \"lee\", \"lee\", \"lee\", \"lee_jordan\", \"lift\", \"lift\", \"lift\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"lockhart\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looked\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"lookout\", \"lord\", \"lord\", \"lord\", \"lord_voldemort\", \"lovegood\", \"lovegood\", \"lovegoods\", \"lumos\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna\", \"luna_lovegood\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"lupin\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam_hooch\", \"madam_pomfrey\", \"madness\", \"mafalda\", \"magazine\", \"magical_eye\", \"magical_law\", \"magorian\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"malfoy\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"mangled\", \"marge\", \"marquee\", \"married\", \"married\", \"marvolo\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master_regulus\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"mate\", \"maxime\", \"maxime\", \"mcgonagall\", \"mcgonagall\", \"mcgonagall\", \"me\", \"me\", \"me\", \"me\", \"me\", \"me\", \"me\", \"me\", \"me\", \"me\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"merope\", \"midair\", \"midair\", \"minerva\", \"minister\", \"minister\", \"mission\", \"mistress\", \"molly\", \"molly\", \"montague\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moody\", \"moran\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"morfin\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"motorbike\", \"mound\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr_cattermole\", \"mr_cattermole\", \"mr_crouch\", \"mr_diggory\", \"mr_ollivander\", \"mr_weasley\", \"mr_weasley\", \"mr_weasleys\", \"mr_weasleys\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle\", \"muggle_born\", \"muggle_born\", \"mundungus\", \"mungos\", \"mungos\", \"muriel\", \"muriel\", \"murmuring\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my\", \"my_lord\", \"my_mother\", \"myrtle\", \"myrtle\", \"nagini\", \"narcissa\", \"nearly_headless\", \"nearly_headless\", \"nearly_headless\", \"nearly_headless\", \"necklace\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"neville\", \"nick\", \"nick\", \"nigellus\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"now\", \"now\", \"now\", \"now\", \"now\", \"now\", \"now\", \"now\", \"now\", \"now\", \"occlumency\", \"off\", \"off\", \"off\", \"off\", \"off\", \"off\", \"off\", \"off\", \"off\", \"off\", \"ogden\", \"ogden\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"ollivander\", \"oncoming\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"ornate\", \"orphanage\", \"outta\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owl\", \"owlery\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"parvati\", \"parvati\", \"parvati\", \"parvati\", \"passage\", \"passage\", \"pavement\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"percy\", \"personally\", \"petunia\", \"peverell\", \"phineas\", \"phineas_nigellus\", \"photograph\", \"photograph\", \"pineapple\", \"plank\", \"platform_nine\", \"pod\", \"pomfrey\", \"posse\", \"possessed\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potion\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"potter\", \"power\", \"power\", \"power\", \"power\", \"power\", \"previously\", \"prime\", \"prime_minister\", \"prince\", \"priority\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor_flitwick\", \"professor_grubbly\", \"professor_mcgonagall\", \"professor_sprout\", \"professor_trelawney\", \"professor_umbridge\", \"puffy\", \"pure_blood\", \"quaffle\", \"quibbler\", \"quibbler\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quidditch\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quill\", \"quirrell\", \"quirrell\", \"quirrell\", \"quirrell\", \"quirrell\", \"radish\", \"rampart\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"rather\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reached\", \"reacted\", \"red_light\", \"registered\", \"regulus\", \"remorse\", \"resolved\", \"respond\", \"resurrection\", \"reverse\", \"riddle\", \"righ\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rita\", \"rita_skeeter\", \"river\", \"road\", \"road\", \"road\", \"roar\", \"roar\", \"roar\", \"roar\", \"rock\", \"rock\", \"rock\", \"rock\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"ron\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rucksack\", \"runcorn\", \"rune\", \"rune\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"saw\", \"scabior\", \"scanning\", \"scream\", \"scream\", \"scream\", \"screamed\", \"screamed\", \"screamed\", \"screamed\", \"scrimgeour\", \"scrimgeour\", \"scurried\", \"seared\", \"searing\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seeking\", \"severus\", \"severus\", \"severus\", \"shakily\", \"shattered\", \"shattered\", \"she\", \"she\", \"she\", \"she\", \"she\", \"she\", \"she\", \"she\", \"she\", \"she\", \"shift\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"shouted\", \"sibyll\", \"sidecar\", \"similar\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sir\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"sirius\", \"skeeter\", \"skeeter\", \"skrewts\", \"slanting\", \"slashed\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"slughorn\", \"snakelike\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snape\", \"snitch\", \"snitch\", \"snitch\", \"snitch\", \"snitch\", \"so\", \"so\", \"so\", \"so\", \"so\", \"so\", \"so\", \"so\", \"so\", \"so\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"sorcerer_stone\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soup\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"spell\", \"sphere\", \"spiral\", \"spiral_staircase\", \"spite\", \"sprawled\", \"sprout\", \"sprout\", \"squad\", \"st_mungos\", \"stag\", \"stag\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"staircase\", \"staircase\", \"staircase\", \"staircase\", \"statute\", \"steal\", \"steal\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone\", \"stone_step\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stood\", \"stooped\", \"stowed\", \"street\", \"street\", \"street\", \"street\", \"street\", \"street\", \"street\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"stunning\", \"stunning\", \"stunning_spell\", \"stupefy\", \"succeeded\", \"summon\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surroundings\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"swung_open\", \"sympathy\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"team\", \"team\", \"ted\", \"teenage\", \"temptation\", \"ter\", \"tha\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"thas\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"them\", \"them\", \"them\", \"them\", \"them\", \"them\", \"them\", \"them\", \"them\", \"them\", \"then\", \"then\", \"then\", \"then\", \"then\", \"then\", \"then\", \"then\", \"then\", \"then\", \"there\", \"there\", \"there\", \"there\", \"there\", \"there\", \"there\", \"there\", \"there\", \"there\", \"thief\", \"thief\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"this\", \"this\", \"this\", \"this\", \"this\", \"this\", \"this\", \"this\", \"this\", \"this\", \"thomas\", \"thomas\", \"through\", \"through\", \"through\", \"through\", \"through\", \"through\", \"through\", \"through\", \"through\", \"through\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tom\", \"tom_riddle\", \"tomb\", \"toppled\", \"torture\", \"tortured\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"toward\", \"transform\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"trelawney\", \"trelawneys\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"umbridge\", \"umbridge\", \"umbridge\", \"umbridge\", \"umbridge\", \"umbridges\", \"umbridges\", \"umbridges\", \"umbridges\", \"umbridges\", \"uncle\", \"uncle\", \"uncle_vernon\", \"unexpectedly\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"vain\", \"vane\", \"vapor\", \"vault\", \"vault\", \"vault\", \"vault\", \"vein\", \"vernon\", \"very\", \"very\", \"very\", \"very\", \"very\", \"very\", \"very\", \"very\", \"very\", \"very\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"voldemort\", \"voldemort\", \"voldemort\", \"voldemorts\", \"voldemorts\", \"voldemorts\", \"vos\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wand\", \"wandlight\", \"wandmaker\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"wearing\", \"weasley\", \"weasley\", \"weasley\", \"weasley\", \"weasley\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"weasleys\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"what_dyou\", \"what_dyou\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"whereabouts\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"why\", \"why\", \"why\", \"why\", \"why\", \"why\", \"why\", \"why\", \"why\", \"why\", \"will\", \"will\", \"will\", \"will\", \"will\", \"will\", \"will\", \"will\", \"will\", \"will\", \"winding\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"wine\", \"wine\", \"winky\", \"winky\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"witch\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizard\", \"wizarding_world\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"worker\", \"wormtails\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wound\", \"wound\", \"wow\", \"wrapping\", \"yaxley\", \"yaxley\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yeh\", \"yell\", \"yell\", \"yell\", \"yelled\", \"yelled\", \"yelled\", \"yelled\", \"yelled\", \"yelled\", \"yelled\", \"yer\", \"your\", \"your\", \"your\", \"your\", \"your\", \"your\", \"your\", \"your\", \"your\", \"your\", \"zabini\", \"zabini\", \"zat\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 5, 1, 7, 6, 2, 9, 4, 8, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el631400897199002407734849199\", ldavis_el631400897199002407734849199_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el631400897199002407734849199\", ldavis_el631400897199002407734849199_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el631400897199002407734849199\", ldavis_el631400897199002407734849199_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J88LGvAsQczc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aam57p7mgft-"
      },
      "source": [
        "## Things to experiment with\n",
        "\n",
        "* ``no_above`` and ``no_below`` parameters in ``filter_extremes`` method.\n",
        "* Adding trigrams or even higher order n-grams.\n",
        "* Consider whether using a hold-out set or cross-validation is the way to go for you.\n",
        "* Try other datasets.\n",
        "\n",
        "## Where to go from here\n",
        "\n",
        "* Check out a RaRe blog post on the AKSW topic coherence measure (http://rare-technologies.com/what-is-topic-coherence/).\n",
        "* pyLDAvis (https://pyldavis.readthedocs.io/en/latest/index.html).\n",
        "* Read some more Gensim tutorials (https://github.com/RaRe-Technologies/gensim/blob/develop/tutorials.md#tutorials).\n",
        "* If you haven't already, read [1] and [2] (see references).\n",
        "\n",
        "## References\n",
        "\n",
        "1. \"Latent Dirichlet Allocation\", Blei et al. 2003.\n",
        "2. \"Online Learning for Latent Dirichlet Allocation\", Hoffman et al. 2010.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "nlp_lda_topic_modeling_gensim_kenyon_iphs300_2022spr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}